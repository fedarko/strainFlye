{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349b04fa",
   "metadata": {},
   "source": [
    "# Tutorial: applying strainFlye to the SheepGut dataset\n",
    "\n",
    "This tutorial will walk you through the various commands strainFlye offers.\n",
    "\n",
    "## 0. Following this tutorial\n",
    "\n",
    "Depending on your dataset and goals, you could either walk through the entirety of this document or skip around a bit. You can \"jump to\" many steps of the pipeline without trouble; for example, if you already have a BCF file of single-nucleotide mutations, you may prefer to skip all of the naïve mutation calling / FDR estimation steps and jump to the phasing analyses.\n",
    "\n",
    "Note that many of the steps of this pipeline will take a while (in my experience: for the full SheepGut dataset on our cluster, \"a while\" usually means around a day). Smaller datasets and/or faster machines should of course decrease this duration. Step 5 of this tutorial (\"**Optional: Filter the FASTA file in order to focus on certain contigs**\") discusses how you can subset your dataset, after the `align` step, to certain contigs of interest; this will also speed things up.\n",
    "\n",
    "([Obligatory xkcd link.](https://xkcd.com/1343/))\n",
    "\n",
    "## 1. The two main strainFlye inputs\n",
    "\n",
    "The strainFlye pipeline takes as input two main types of data:\n",
    "\n",
    "1. A __set of reads__ (in FASTA / FASTQ format).\n",
    "\n",
    "2. A __set of contigs__ (in FASTA format) assembled from these reads.\n",
    "\n",
    "This assumes that you're starting the pipeline at the beginning (with `align`). Later pipeline steps will require other inputs that can be produced by intermediate pipeline steps.\n",
    "\n",
    "### 1.1. Details about these types of inputs\n",
    "\n",
    "**Regarding reads:** We designed strainFlye in the context of PacBio Circular Consensus Sequencing (CCS) \"HiFi\" reads ([Wenger & Peluso _et al._, 2019](https://www.nature.com/articles/s41587-019-0217-9)). However, in theory it should still work with other reasonably long and accurate reads.\n",
    "\n",
    "**Regarding contigs:** We don't impose any restriction on the assembler you use to construct these. We have tested strainFlye on [metaFlye](https://github.com/fenderglass/Flye) ([Kolmogorov _et al._, 2020](https://www.nature.com/articles/s41587-019-0217-9)) and [hifiasm-meta](https://github.com/xfengnefx/hifiasm-meta) ([Feng _et al._, 2022](https://www.nature.com/articles/s41592-022-01478-3)) output, but it should in theory work with the outputs of other HiFi assemblers.\n",
    "\n",
    "### 1.2. The SheepGut dataset\n",
    "\n",
    "We'll be applying strainFlye to the SheepGut dataset that is shown in our paper. Please see the paper's \"Data access\" section for details about acquiring reads and contigs for the SheepGut dataset.\n",
    "\n",
    "Note that the \"contigs\" we use for the SheepGut datatset really correspond to edge sequences in the `assembly_graph.gfa` file produced by metaFlye -- in general, these may be slightly different from the file of contigs / scaffolds in the `assembly.fasta` file produced by metaFlye: see [Flye's manual](https://github.com/fenderglass/Flye/blob/flye/docs/USAGE.md#output) for more information. (You could use either type of sequence with strainFlye, although I personally recommend using edges -- it's useful to have context about where exactly in the assembly graph a sequence is, and things like gaps in scaffolds will cause strainFlye to complain.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e5fc0",
   "metadata": {},
   "source": [
    "## 2. Introduction\n",
    "\n",
    "Let's take care of a few things before the tutorial starts.\n",
    "\n",
    "### 2.1. Installing strainFlye\n",
    "\n",
    "Before following along with this tutorial, we assume that you have already installed strainFlye (and have activated the corresponding conda environment). Please see [strainFlye's README](https://github.com/fedarko/strainFlye) for installation instructions.\n",
    "\n",
    "### 2.2. What commands are available through strainFlye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6ff7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!strainFlye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558f6d4",
   "metadata": {},
   "source": [
    "### 2.3. Importing and configuring some utilities\n",
    "\n",
    "You shouldn't need to do much (if any) programming to use strainFlye's commands; that said, we will be using Python to help with a few small tasks throughout this tutorial, and you will probably need to do some programming to plot the results we produce (this philosophy was inspired partially by [Schloss 2020](https://journals.asm.org/doi/full/10.1128/AEM.02343-19)). We'll import some useful Python packages here to reduce clutter in this notebook.\n",
    "\n",
    "(If you prefer, you could of course use another language instead of Python.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a094e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import skbio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee835ce7",
   "metadata": {},
   "source": [
    "## 3. Convert the assembly graph GFA file to a FASTA file of contigs\n",
    "\n",
    "**You can skip this step if:** you already have a FASTA file describing contigs in your assembly graph.\n",
    "\n",
    "Our assembly graph (the GFA file) contains the sequences of the contigs that we will use in many downstream analyses, but we'll need to have a FASTA file that just describes these contigs' sequences (independent of the assembly graph topology).\n",
    "\n",
    "There are some [bash one-liners](https://www.biostars.org/p/169516/#169530) you can use to convert a GFA 1 file to a FASTA file, but strainFlye also provides a utility command (`strainFlye utils gfa-to-fasta`) to do this for you. We'll use this here. (Our solution may be a bit slower than a bash one-liner, but it performs some useful sanity checking on the GFA file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26d90dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye utils gfa-to-fasta @ 0.00 sec: Starting...\n",
      "Input GFA file: /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa\n",
      "Output FASTA file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta\n",
      "--------\n",
      "strainFlye utils gfa-to-fasta @ 14.97 sec: Done.\n",
      "Output FASTA file contains 78,793 sequences.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye utils gfa-to-fasta \\\n",
    "    --graph /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa \\\n",
    "    --output-fasta /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ba35",
   "metadata": {},
   "source": [
    "## 4. Align reads to contigs; filter the resulting alignment\n",
    "\n",
    "**You can skip this step if:** you already have a BAM file representing an alignment of reads to contigs, and this BAM file does not contain secondary alignments / partially-mapped reads / overlapping supplementary alignments (these all may cause problems in downstream analyses).\n",
    "\n",
    "We'll need to align reads back to these contigs. The resulting alignment, and/or the mutations that we call from it, will be used in pretty much all downstream steps—so it's important to make sure that it is of good quality!\n",
    "\n",
    "The `strainFlye align` command uses minimap2 to perform alignment, and then does some extra filtering on the resulting alignment.\n",
    "\n",
    "Note that this command, in particular, may take a while to run. Sequence alignment is computationally expensive! On our cluster, `strainFlye align` ran on the full SheepGut dataset in 62,941.21 seconds (aka about 17.5 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281fd11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye align [OPTIONS] READS...\r\n",
      "\r\n",
      "  Align reads to contigs, and filter the resulting alignment.\r\n",
      "\r\n",
      "  Files of reads should be in the FASTA or FASTQ formats; GZIP'd files are\r\n",
      "  allowed.\r\n",
      "\r\n",
      "  This command involves multiple steps, including:\r\n",
      "\r\n",
      "    1) Align reads to contigs (using minimap2) to generate a SAM file\r\n",
      "    2) Convert this SAM file to a sorted and indexed BAM file\r\n",
      "    3) Filter overlapping supplementary alignments (OSAs) from this BAM file\r\n",
      "    4) Filter partially-mapped reads from this BAM file\r\n",
      "\r\n",
      "  Note that we only sort the alignment file once, although we do re-index it\r\n",
      "  after the two filtering steps. This decision is motivated by\r\n",
      "  https://www.biostars.org/p/131333/#131335.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs to which reads will be\r\n",
      "                                  aligned.  [required]\r\n",
      "  -g, --graph PATH                GFA 1-formatted file describing an assembly\r\n",
      "                                  graph of the contigs. This is used in the\r\n",
      "                                  \"filter partially-mapped reads\" step to make\r\n",
      "                                  the filter less strict for reads mapped to\r\n",
      "                                  adjacent contigs in the graph. This isn't\r\n",
      "                                  required; if it isn't passed, adjacent\r\n",
      "                                  contigs will not be considered in this\r\n",
      "                                  filter.  [default: (no graph)]\r\n",
      "  -p, --minimap2-params TEXT      Additional parameters to pass to minimap2,\r\n",
      "                                  besides the contig and read information.\r\n",
      "                                  Depending on the size of your dataset and\r\n",
      "                                  the amount of memory your system has, you\r\n",
      "                                  may want to adjust the -I parameter; see\r\n",
      "                                  minimap2's documentation for details. Please\r\n",
      "                                  note that we do not perform any validation\r\n",
      "                                  on this string before passing it to minimap2\r\n",
      "                                  (so if you are allowing users to run\r\n",
      "                                  strainFlye through a web server, be careful\r\n",
      "                                  about shell injection).  [default: -ax asm20\r\n",
      "                                  --secondary=no -I 8g --MD]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which an output BAM file\r\n",
      "                                  (final.bam) and BAM index file will be\r\n",
      "                                  written. Some temporary files will also be\r\n",
      "                                  written to this directory.  [required]\r\n",
      "  --rm-tmp-bam / --no-rm-tmp-bam  Remove temporary (before filtering, and\r\n",
      "                                  after just filtering OSAs) BAM files, to\r\n",
      "                                  reduce space requirements.  [default: rm-\r\n",
      "                                  tmp-bam]\r\n",
      "  --verbose / --no-verbose        Display extra details during alignment\r\n",
      "                                  filtering.  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c619f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!strainFlye align \\\n",
    "    # We can use the FASTA file we just generated above.\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta \\\n",
    "    --graph /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/alignment \\\n",
    "    # Reads file(s) are specified here, after all of the other parameters:\n",
    "    /Poppy/mkolmogo/sheep_meta/data/sheep_poop_CCS_dedup.fastq.gz \\\n",
    "    /Poppy/mkolmogo/sheep_meta/data/ccs_sequel_II/*.fasta.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c58de0",
   "metadata": {},
   "source": [
    "This generates a BAM file (`final.bam`) and BAM index file (`final.bam.bai`) in the specified output directory.\n",
    "\n",
    "We can use this BAM file for many analyses downstream—the first of these will be mutation calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf1e5d",
   "metadata": {},
   "source": [
    "## 5. Optional: Filter the FASTA file in order to focus on certain contigs\n",
    "\n",
    "We just aligned our dataset's reads against *all* contigs in the assembly graph. This is standard practice (see, e.g., [this tutorial](https://astrobiomike.github.io/genomics/metagen_anvio#mapping-our-reads-to-the-assembly-they-built)); aligning reads against all contigs probably yields a more accurate alignment than just aligning reads against a subset of these contigs (although proving if this is \"best practice\" or not is a challenging question, and one that I will sidestep right now).\n",
    "\n",
    "However, now that we have this alignment, we don't necessarily need to perform mutation calling, phasing, etc. on all contigs (although, if you want to, we could!). To speed up the rest of this tutorial, **we will focus solely on the \"long\" contigs in this dataset**: here, we will define a contig as \"long\" if its length is at least 1 Mbp (aka 1,000,000 bp). In theory, these long contigs represent putative metagenome-assembled genomes (MAGs).\n",
    "\n",
    "Of course, if you prefer, you could apply more sophisticated criteria to pick which contigs to focus on—maybe you'd like to also focus on contigs with high coverages, or maybe on contigs with good [CheckM](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4484387/) completeness or contamination values. Or maybe you'd like to keep considering all contigs in the full dataset! Your decision should depend on your goals, and your dataset.\n",
    "\n",
    "In any case, how do we \"focus on\" certain contigs? **We can filter our FASTA file to a subset of contigs present in the full dataset**, and use this filtered FASTA file for all downstream analyses. As an example of this, we will use Python (in particular, the [scikit-bio](http://scikit-bio.org/) library) to filter our FASTA file to all long contigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac9fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 contigs with lengths ≥ 1,000,000 bp. Took 12.30 sec.\n"
     ]
    }
   ],
   "source": [
    "# Produce a filtered FASTA file containing only contigs >= 1 Mbp long\n",
    "# (This uses scikit-bio; see http://scikit-bio.org/ for more details.)\n",
    "\n",
    "input_contigs_fp = \"/Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta\"\n",
    "output_contigs_fp = \"/Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\"\n",
    "len_threshold = 1000000\n",
    "\n",
    "t0 = time.time()\n",
    "num_long_contigs = 0\n",
    "with open(output_contigs_fp, \"w\") as of:\n",
    "    for contig in skbio.io.read(input_contigs_fp, format=\"fasta\", constructor=skbio.DNA):\n",
    "        if len(contig) >= len_threshold:\n",
    "            skbio.io.write(contig, format=\"fasta\", into=of)\n",
    "            num_long_contigs += 1\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Found {num_long_contigs:,} contigs with lengths \\u2265 {len_threshold:,} bp. Took {t1 - t0:,.2f} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388366fb",
   "metadata": {},
   "source": [
    "The remainder of this tutorial will focus on these 468 long contigs.\n",
    "\n",
    "In any case, now we can get on to some more interesting stuff!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6400ea",
   "metadata": {},
   "source": [
    "## 6. Perform naïve mutation calling, then estimate and fix mutation calls' FDRs\n",
    "\n",
    "**You can skip this step if:** You already have a BCF file describing single-nucleotide, non-multi-allelic mutations in your contigs.\n",
    "\n",
    "The analyses downstream of this step (hotspot/coldspot identification, phasing) take as input a set of identified single-nucleotide mutations (or, if you prefer to use different terminology, \"called variants\", \"called SNVs\", ...) in which we have some confidence. How does strainFlye identify these mutations?\n",
    "\n",
    "There are a few steps (as our paper describes). First, we will **naïvely call mutations** using a simple threshold-based method (referred to as \"NaiveFreq\" in the paper). We can then **estimate the false-discovery rates (FDRs) of the mutations called for each contig** using the target-decoy approach. If desired, we can then adjust the called mutations to **fix the estimated FDRs of these mutation calls** below a specified threshold.\n",
    "\n",
    "### 6.1. $p$-mutations and $r$-mutations?\n",
    "\n",
    "So, our first step will be performing this simple threshold-based calling. What do we mean by \"threshold\" here?\n",
    "\n",
    "strainFlye supports calling two basic types of mutations: $p$-mutations and $r$-mutations. The docs explain the difference between these two types best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5755853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye call [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Call mutations in contigs naïvely & compute diversity indices.\r\n",
      "\r\n",
      "  Consider a position \"pos\" in a contig. Using the alignment, we can count how\r\n",
      "  many reads have a (mis)match operation to \"pos\" with one of the four\r\n",
      "  nucleotides (A, C, G, T; we ignore degenerate nucleotides in reads). We\r\n",
      "  represent these four nucleotides' counts at pos as follows:\r\n",
      "\r\n",
      "      N1 = # reads of the most-common aligned nucleotide at pos,\r\n",
      "      N2 = # reads of the second-most-common aligned nucleotide at pos,\r\n",
      "      N3 = # reads of the third-most-common aligned nucleotide at pos,\r\n",
      "      N4 = # reads of the fourth-most-common aligned nucleotide at pos.\r\n",
      "\r\n",
      "  (We break ties arbitrarily.)\r\n",
      "\r\n",
      "  strainFlye supports two types of naïve mutation calling based on these\r\n",
      "  counts: p-mutations and r-mutations. These are described below.\r\n",
      "\r\n",
      "  p-mutations (naïve percentage-based mutation calling)\r\n",
      "  -----------------------------------------------------\r\n",
      "\r\n",
      "  This takes as input some percentage p in the range (0%, 50%]. Define\r\n",
      "  freq(pos) = N2 / (N1 + N2 + N3 + N4). This value, which is inherently\r\n",
      "  constrained to the range [0%, 50%], is an estimate of the mutation frequency\r\n",
      "  of this position. We classify pos as a p-mutation if freq(pos) ≥ p, AND if\r\n",
      "  N2 ≥ the --min-alt-pos parameter (an integer representing a minimum number\r\n",
      "  of reads that must support the alternate nucleotide).\r\n",
      "\r\n",
      "  r-mutations (naïve read-count-based mutation calling)\r\n",
      "  -----------------------------------------------------\r\n",
      "\r\n",
      "  This takes as input some integer r > 0. We classify pos as an r-mutation if\r\n",
      "  N2 ≥ r.\r\n",
      "\r\n",
      "  Diversity indices\r\n",
      "  -----------------\r\n",
      "\r\n",
      "  Later on in the pipeline, if we perform FDR estimation on these called\r\n",
      "  mutations using the \"strainFlye fdr\" module, we will need to select a \"decoy\r\n",
      "  contig\" with relatively few mutations. A contig with low diversity indices\r\n",
      "  may represent a promising decoy contig; so, for the sake of convenience,\r\n",
      "  both commands output this information.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  p-mutation  Call p-mutations and compute diversity indices.\r\n",
      "  r-mutation  Call r-mutations and compute diversity indices.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ac637",
   "metadata": {},
   "source": [
    "### 6.2. Understanding these (sub)commands\n",
    "\n",
    "First off, note that `strainFlye call` doesn't do anything besides show help info if you run it by itself. This is because, unlike `strainFlye align`, `strainFlye call` has two subcommands: `p-mutation` and `r-mutation`. Which of these you use will depend on how you want to naïvely call mutations. You can invoke one of these subcommands by writing out the full chain of commands: for example, `strainFlye call p-mutation`.\n",
    "\n",
    "#### 6.2.1. Input and output\n",
    "\n",
    "Probably the most important parameter at this step is the *minimum threshold*. Both of these subcommands, `strainFlye call p-mutation` and `strainFlye call r-mutation`, take as input a minimum version of their corresponding threshold (either `--min-p` or `--min-r`).\n",
    "\n",
    "These commands each output:\n",
    "\n",
    "1. A __BCF (binary [variant call format](https://samtools.github.io/hts-specs/VCFv4.3.pdf)) file__ describing all mutations called naïvely across the contigs, based on the minimum $p$ or $r$ threshold set (`--min-p` or `--min-r`).\n",
    "\n",
    "2. A __TSV ([tab separated values](https://en.wikipedia.org/wiki/Tab-separated_values)) file__ describing the contigs' computed diversity indices, for various values of $p$ or $r$ (configurable using the `--div-index-p-list` or `--div-index-r-list` parameters).\n",
    "  - Long story short, diversity indices indicate how many of a contig's \"sufficiently-covered\" positions have called mutations: in general, higher diversity indices imply higher mutation rates.\n",
    "  - If enough positions in a contig are not \"sufficiently-covered,\" then we will not compute the diversity index for this contig. Please see the Supplemental Material \"Diversity index details\" in the strainFlye paper for details.\n",
    "\n",
    "#### 6.2.2. Interpreting the output\n",
    "\n",
    "The default minimum value of $p$ (or $r$) used in these commands is fairly low. As you might expect, using such a low threshold for calling a position as a mutation may yield many false positives: we will almost certainly identify many real mutations, but also many \"false\" mutations that happen to occur as the result of sequencing errors, alignment errors, etc. Viewed another way, the __[false discovery rate (FDR)](https://en.wikipedia.org/wiki/False_discovery_rate)__ (defined as the ratio of false positives to total true + false positives) of the mutation calls generated at this step will probably be high—although this depends on a variety of factors, including which contig(s) we are focusing on mutations in, what our goals are in the first place, etc.\n",
    "\n",
    "##### FDR estimation and fixing\n",
    "\n",
    "After we run this command, we can use strainFlye's FDR estimation and fixing functionality to attempt to address this problem. This process involves adjusting the \"minimum\" value of $p$ (or $r$) used for each contig to reduce the FDR as needed.\n",
    "\n",
    "Depending on your dataset and your goals, you may or may not want to do this: as of writing, many of the analyses in the strainFlye paper don't perform FDR fixing on their input mutations, and instead just make use of \"un-fixed\" naïvely called $p$-mutations. (That being said, this is mostly a historical artifact of us implementing the FDR fixing code close to the end of the project.)\n",
    "\n",
    "In general, if you are going to perform FDR estimation / fixing, we recommend only doing this for $p$-mutations (and not $r$-mutations); this is discussed in the strainFlye paper, in the Supplemental Material section named \"Identifying mutations based solely on read counts.\"\n",
    "\n",
    "### 6.3. Naïvely call $p$-mutations ($p = 0.15\\%$) and compute diversity indices for various values of $p$\n",
    "\n",
    "Now that we know what we're doing, we're ready to call mutations and compute diversity indices! We'll do $p$-mutation calling at a minimum $p$ of $0.15\\%$, which matches what we used for Figure 2 in the paper. The default diversity index values of $p$ (ranging from $0.5\\%$ to $50\\%$) should be good for us.\n",
    "\n",
    "Like alignment, this command will also take a while—we need to check each position in the alignment for each of the input contigs. If you'd like, you can use the `--verbose` flag to display some extra information while this command is running, to make the wait more tolerable (and assure you that it isn't frozen somewhere)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c394d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye call p-mutation [OPTIONS]\r\n",
      "\r\n",
      "  Call p-mutations and compute diversity indices.\r\n",
      "\r\n",
      "  The primary parameter for this command is the lower bound of p, defined by\r\n",
      "  --min-p. The BCF output will include \"mutations\" for all positions that pass\r\n",
      "  this (likely very low) threshold; this BCF can be filtered using the\r\n",
      "  utilities contained in the \"strainFlye fdr\" module.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs in which to naïvely\r\n",
      "                                  call mutations. All contigs in this FASTA\r\n",
      "                                  file should also be contained in the BAM\r\n",
      "                                  file; it's ok if the BAM file contains\r\n",
      "                                  contigs not in this FASTA file (we'll ignore\r\n",
      "                                  them).  [required]\r\n",
      "  -b, --bam PATH                  Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --min-p INTEGER RANGE           Minimum value of p for which to call\r\n",
      "                                  p-mutations. This is scaled up by 100 (i.e.\r\n",
      "                                  the default of 50 corresponds to 50 / 100 =\r\n",
      "                                  0.5%) in order to bypass floating-point\r\n",
      "                                  precision issues.  [default: 50; 0<x<=5000]\r\n",
      "  --min-alt-pos INTEGER RANGE     In order for us to call a p-mutation at a\r\n",
      "                                  position, this position's alternate\r\n",
      "                                  nucleotide must be supported by at least\r\n",
      "                                  this many reads.  [default: 2; x>=1]\r\n",
      "  --div-index-p-list TEXT         List of values of p for which we'll compute\r\n",
      "                                  diversity indices. These should all be\r\n",
      "                                  separated by commas; and, as with --min-p,\r\n",
      "                                  these are scaled up by 100. Please don't use\r\n",
      "                                  commas as thousands separators.  [default:\r\n",
      "                                  50,100,200,500,1000,2500,5000]\r\n",
      "  -m, --min-read-number FLOAT RANGE\r\n",
      "                                  Parameter that impacts the minimum\r\n",
      "                                  (mis)match coverage needed in order to\r\n",
      "                                  consider \"counting\" a position / mutation\r\n",
      "                                  towards the diversity index. Given a value\r\n",
      "                                  of p (converted to the range (0, 0.5]), a\r\n",
      "                                  position must have a coverage of at least\r\n",
      "                                  (--min-read-number / p) in order to be\r\n",
      "                                  \"sufficiently covered\" and thus counted\r\n",
      "                                  towards the diversity index.  [default: 5;\r\n",
      "                                  x>0]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which an output BCF file\r\n",
      "                                  (describing the called mutations), BCF index\r\n",
      "                                  file, and diversity index TSV file will be\r\n",
      "                                  written. Some temporary files will also be\r\n",
      "                                  written to this directory.  [required]\r\n",
      "  --verbose / --no-verbose        Display extra details while running.\r\n",
      "                                  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye call p-mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye call p-mutation \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sftests/tutorial-output/alignment/final.bam \\\n",
    "    --min-p 15 \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/call-p15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce21462",
   "metadata": {},
   "source": [
    "### 6.4. Estimating FDRs using the target-decoy approach\n",
    "\n",
    "We now have both our initial mutation calls (which, as we've discussed, probably have a high FDR) and information about our contigs' diversity indices. We will use the __target-decoy approach__ to attempt to estimate and thus control the FDR of our mutation calls. This is done by the `strainFlye fdr estimate` and `strainFlye fdr fix` commands.\n",
    "\n",
    "As discussed in our paper, we can select—out of one of our $C$ contigs—a __decoy contig__ (a.k.a. a decoy genome), and compute a mutation rate for it ($\\text{rate}_{\\text{decoy}}$). For each of the other $C - 1$ __target contigs__, we can estimate the FDR of identified mutations in this contig as $\\dfrac{\\text{rate}_{\\text{decoy}}}{\\text{rate}_{\\text{target}}}$.\n",
    "\n",
    "#### 6.4.1. Manually selecting a decoy contig\n",
    "\n",
    "If you'd like, we could go through the diversity indices produced by `strainFlye call p-mutation` ourselves, in an attempt to select a reasonable-seeming decoy contig. **[This notebook](https://nbviewer.org/github/fedarko/strainFlye/blob/main/docs/AnalyzingDiversityIndices.ipynb)** demonstrates this sort of process.\n",
    "\n",
    "#### 6.4.2. Letting `strainFlye fdr estimate` automatically select a decoy contig\n",
    "\n",
    "The optional notebook discussed above shows that `edge_6104` is probably a good decoy contig, so we could if desired just pass it to `strainFlye fdr estimate` using that command's `-dc` or `--decoy-contig` option. However, to illustrate another option, we'll instead pass our diversity index TSV file to `strainFlye fdr estimate` and let it do the job of selecting a decoy contig. (Spoiler alert: it'll select `edge_6104` anyway.)\n",
    "\n",
    "The Methods section of our paper provides details about how the automatic decoy contig selection algorithm works. If you'd prefer, you can also go through the exact source code for it, which is reasonably well-documented: see the `autoselect_decoy()` function in **[this file](https://github.com/fedarko/strainFlye/blob/main/strainflye/fdr_utils.py#L101)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5253166f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Estimate and fix FDRs for contigs' naïve mutation calls.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  estimate  Estimate the FDRs of contigs' mutation calls.\r\n",
      "  fix       Fix contigs' mutation calls' estimated FDRs to an upper limit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001dbf01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr estimate [OPTIONS]\r\n",
      "\r\n",
      "  Estimate the FDRs of contigs' mutation calls.\r\n",
      "\r\n",
      "  We do this using the target-decoy approach (TDA). Given a set of C contigs,\r\n",
      "  we select a \"decoy contig\" with relatively few called mutations. We then\r\n",
      "  compute a mutation rate for this decoy contig, and use this mutation rate\r\n",
      "  (along with the mutation rates of the other C - 1 \"target\" contigs) to\r\n",
      "  estimate the FDRs of all of these target contigs' mutation calls.\r\n",
      "\r\n",
      "  We can produce multiple FDR estimates for a single target contig's calls by\r\n",
      "  varying the p or r threshold used (from the --min-p or --min-r threshold\r\n",
      "  used to generate the input BCF file, up to the --high-p or --high-r\r\n",
      "  threshold given here). Using this information (and information about the\r\n",
      "  numbers of mutations called per megabase), we can plot an FDR curve for a\r\n",
      "  given target contig's mutation calls.\r\n",
      "\r\n",
      "  This command accepts an input BCF file of p- or r-mutations; however, in\r\n",
      "  general we recommend using p-mutations (rather than r-mutations) for FDR\r\n",
      "  estimation / fixing. Please see the Supplemental Material section of the\r\n",
      "  strainFlye paper named \"Identifying mutations based solely on read counts\"\r\n",
      "  for details.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs for which we will\r\n",
      "                                  estimate mutation calls' FDRs. All contigs\r\n",
      "                                  in this FASTA file should also be contained\r\n",
      "                                  in the BAM and BCF files. It's ok if the BAM\r\n",
      "                                  file contains contigs not in this FASTA file\r\n",
      "                                  (we'll ignore them), but all contigs\r\n",
      "                                  described in the BCF file's header must also\r\n",
      "                                  be in this FASTA file.  [required]\r\n",
      "  --bam PATH                      Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --bcf PATH                      Indexed BCF file describing naïvely called\r\n",
      "                                  p- or r-mutations in the FASTA file's\r\n",
      "                                  contigs, produced by \"strainFlye call\".\r\n",
      "                                  [required]\r\n",
      "  -di, --diversity-indices PATH   TSV file describing the diversity indices of\r\n",
      "                                  a set of contigs. Used to automatically\r\n",
      "                                  select a decoy contig. This option is\r\n",
      "                                  mutually exclusive with --decoy-contig.\r\n",
      "                                  [default: (nothing)]\r\n",
      "  -dc, --decoy-contig TEXT        Name of a specific contig to use as the\r\n",
      "                                  decoy contig for FDR estimation. This option\r\n",
      "                                  is mutually exclusive with --diversity-\r\n",
      "                                  indices.  [default: (nothing)]\r\n",
      "  -dctx, --decoy-contexts [Full|CP2|Tv|Nonsyn|Nonsense|CP2Tv|CP2Nonsyn|CP2Nonsense|TvNonsyn|TvNonsense|CP2TvNonsense|Everything]\r\n",
      "                                  \"Context-dependent\" types of positions\r\n",
      "                                  and/or mutations to which the computation of\r\n",
      "                                  mutation rates in the decoy contig will be\r\n",
      "                                  limited. The \"Full\" option will consider the\r\n",
      "                                  entire decoy contig; all other options will\r\n",
      "                                  limit the computation to certain types of\r\n",
      "                                  positions and/or potential mutations. (CP2\r\n",
      "                                  will focus on positions in the second codon\r\n",
      "                                  position of genes predicted in the decoy\r\n",
      "                                  contig using Prodigal; Nonsyn will focus on\r\n",
      "                                  potential nonsynonymous mutations in these\r\n",
      "                                  genes; Nonsense will focus on potential\r\n",
      "                                  nonsense mutations in these genes; and Tv\r\n",
      "                                  will focus on potential transversion\r\n",
      "                                  mutations.) You can specify this option\r\n",
      "                                  multiple times to generate multiple sets of\r\n",
      "                                  FDR estimates. (You can also specify\r\n",
      "                                  \"Everything\" to use all available contexts.)\r\n",
      "                                  [default: CP2; required]\r\n",
      "  -hp, --high-p INTEGER RANGE     (Only applies if the input BCF file\r\n",
      "                                  describes p-mutations.) p-mutations with a\r\n",
      "                                  mutation rate (freq(pos)) greater than or\r\n",
      "                                  equal to this are considered \"indisputable,\"\r\n",
      "                                  and will not be included in FDR estimation.\r\n",
      "                                  Like the values of p used as parameters to\r\n",
      "                                  \"strainFlye call p-mutation\", this is in the\r\n",
      "                                  range (0, 5000], such that h = N corresponds\r\n",
      "                                  to (N / 100)%. Corresponds to the\r\n",
      "                                  \"highFrequency\" threshold mentioned in the\r\n",
      "                                  paper.  [default: 500; 0<x<=5000]\r\n",
      "  -hr, --high-r INTEGER RANGE     (Only applies if the input BCF file\r\n",
      "                                  describes r-mutations.) r-mutations with an\r\n",
      "                                  alternate nucleotide read coverage greater\r\n",
      "                                  than or equal to this are considered\r\n",
      "                                  indisputable, and will not be included in\r\n",
      "                                  FDR estimation.  [default: 100; x>0]\r\n",
      "  -dml, --decoy-min-length INTEGER RANGE\r\n",
      "                                  Minimum length of a potential decoy contig\r\n",
      "                                  (in bp). Only used if --diversity-indices is\r\n",
      "                                  specified.  [default: 1000000; x>0]\r\n",
      "  -dmac, --decoy-min-average-coverage FLOAT RANGE\r\n",
      "                                  Minimum average (mis)match coverage of a\r\n",
      "                                  potential decoy contig. Only used if\r\n",
      "                                  --diversity-indices is specified.  [default:\r\n",
      "                                  500; x>0]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which TSV files describing the\r\n",
      "                                  estimated FDRs and numbers of naïvely called\r\n",
      "                                  mutations per megabase will be written. In\r\n",
      "                                  all TSV files, rows correspond to target\r\n",
      "                                  contigs and columns correspond to p or r\r\n",
      "                                  values. We will generate one estimated FDR\r\n",
      "                                  TSV file for every time --decoy-context is\r\n",
      "                                  specified, and just one number-of-naïvely-\r\n",
      "                                  called-mutations-per-megabase file.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a481c482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye fdr estimate @ 0.00 sec: Starting...\n",
      "Input contig file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\n",
      "Input BAM file: /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf\n",
      "Input diversity indices file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv\n",
      "Input manually-set decoy contig: None\n",
      "Input decoy contig context-dependent position / mutation type(s): ('Full', 'CP2', 'Tv', 'Nonsyn', 'Nonsense', 'CP2Tv', 'CP2Nonsyn', 'CP2Nonsense', 'TvNonsyn', 'TvNonsense', 'CP2TvNonsense')\n",
      "Input high p threshold (only used if the BCF describes p-mutations): 500\n",
      "Input high r threshold (only used if the BCF describes r-mutations): 100\n",
      "Input min length of a potential decoy contig (only used if diversity indices are specified): 1000000\n",
      "Input min average coverage of a potential decoy contig (only used if diversity indices are specified): 500.0\n",
      "Output directory: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info\n",
      "--------\n",
      "strainFlye fdr estimate @ 0.00 sec: Loading and checking FASTA, BAM, and BCF files...\n",
      "strainFlye fdr estimate @ 4.80 sec: The FASTA file describes 468 contig(s).\n",
      "strainFlye fdr estimate @ 4.88 sec: All FASTA contig(s) are included in the BAM file (this BAM file has 78,793 reference(s)).\n",
      "strainFlye fdr estimate @ 19.59 sec: The FASTA file's contig(s) and BCF file's contig(s) match.\n",
      "strainFlye fdr estimate @ 19.59 sec: Also, the input BCF file describes p-mutations (minimum p = 15).\n",
      "strainFlye fdr estimate @ 19.60 sec: The lengths of all contig(s) in the FASTA file match the corresponding lengths in the BAM and BCF files.\n",
      "strainFlye fdr estimate @ 19.60 sec: So far, these files seem good.\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.60 sec: Selecting a decoy contig based on the diversity indices...\n",
      "strainFlye fdr estimate @ 19.61 sec: Selected edge_6104 as the decoy contig.\n",
      "strainFlye fdr estimate @ 19.61 sec: Verified that this decoy contig is present in the FASTA, BAM, and BCF files.\n",
      "strainFlye fdr estimate @ 19.61 sec: (Sorry for doubting you.)\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.61 sec: Determining range of value(s) of p to consider...\n",
      "strainFlye fdr estimate @ 19.61 sec: We'll consider 485 value(s) of p: from 15 to 499.\n",
      "strainFlye fdr estimate @ 19.61 sec: p-mutations for p ≥ 500 will be considered \"indisputable.\"\n",
      "strainFlye fdr estimate @ 19.61 sec: These \"indisputable\" mutations won't be included in the FDR estimation results.\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.61 sec: Computing mutation rates for edge_6104 at these threshold values, for each of the 11 decoy context(s)...\n",
      "strainFlye fdr estimate @ 21.45 sec: At least one of the decoy context(s) requires us to have gene predictions for edge_6104; running Prodigal...\n",
      "-------------------------------------\n",
      "PRODIGAL v2.6.3 [February, 2016]         \n",
      "Univ of Tenn / Oak Ridge National Lab\n",
      "Doug Hyatt, Loren Hauser, et al.     \n",
      "-------------------------------------\n",
      "Request:  Single Genome, Phase:  Training\n",
      "Reading in the sequence(s) to train...1289244 bp seq created, 32.65 pct GC\n",
      "Locating all potential starts and stops...30910 nodes\n",
      "Looking for GC bias in different frames...frame bias scores: 2.68 0.19 0.12\n",
      "Building initial set of genes to train from...done!\n",
      "Creating coding model and scoring nodes...done!\n",
      "Examining upstream regions and training starts...done!\n",
      "-------------------------------------\n",
      "Request:  Single Genome, Phase:  Gene Finding\n",
      "Finding genes in sequence #1 (1289244 bp)...done!\n",
      "strainFlye fdr estimate @ 26.66 sec: Finished running Prodigal! It predicted 1,297 gene(s) in edge_6104.\n",
      "strainFlye fdr estimate @ 27.41 sec: At least one of the decoy context(s) requires us to know \"unreasonable\" positions (where reference and consensus disagree) in edge_6104; going through alignment...\n",
      "strainFlye fdr estimate @ 27.66 sec: Done: identified 0 unreasonable position(s) in edge_6104.\n",
      "strainFlye fdr estimate @ 27.66 sec: Computing mutation rates for decoy context \"CP2\" (1 / 11)...\n",
      "strainFlye fdr estimate @ 27.67 sec: Done computing \"CP2\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 27.67 sec: Computing mutation rates for decoy context \"CP2Nonsense\" (2 / 11)...\n",
      "strainFlye fdr estimate @ 34.47 sec: Done computing \"CP2Nonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 34.47 sec: Computing mutation rates for decoy context \"CP2Nonsyn\" (3 / 11)...\n",
      "strainFlye fdr estimate @ 41.87 sec: Done computing \"CP2Nonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 41.87 sec: Computing mutation rates for decoy context \"CP2Tv\" (4 / 11)...\n",
      "strainFlye fdr estimate @ 41.88 sec: Done computing \"CP2Tv\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 41.88 sec: Computing mutation rates for decoy context \"CP2TvNonsense\" (5 / 11)...\n",
      "strainFlye fdr estimate @ 48.67 sec: Done computing \"CP2TvNonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 48.67 sec: Computing mutation rates for decoy context \"Full\" (6 / 11)...\n",
      "strainFlye fdr estimate @ 48.69 sec: Done computing \"Full\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 48.69 sec: Computing mutation rates for decoy context \"Nonsense\" (7 / 11)...\n",
      "strainFlye fdr estimate @ 68.39 sec: Done computing \"Nonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 68.39 sec: Computing mutation rates for decoy context \"Nonsyn\" (8 / 11)...\n",
      "strainFlye fdr estimate @ 89.12 sec: Done computing \"Nonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 89.12 sec: Computing mutation rates for decoy context \"Tv\" (9 / 11)...\n",
      "strainFlye fdr estimate @ 89.24 sec: Done computing \"Tv\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 89.24 sec: Computing mutation rates for decoy context \"TvNonsense\" (10 / 11)...\n",
      "strainFlye fdr estimate @ 108.39 sec: Done computing \"TvNonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 108.39 sec: Computing mutation rates for decoy context \"TvNonsyn\" (11 / 11)...\n",
      "strainFlye fdr estimate @ 128.86 sec: Done computing \"TvNonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 128.89 sec: Done computing mutation rates for all decoy context(s) for edge_6104.\n",
      "--------\n",
      "strainFlye fdr estimate @ 128.89 sec: Computing mutation rates and FDR estimates for the 467 target contig(s)...\n",
      "strainFlye fdr estimate @ 161.04 sec: Done.\n",
      "--------\n",
      "strainFlye fdr estimate @ 161.09 sec: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr estimate \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf \\\n",
    "    --diversity-indices /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv \\\n",
    "    --decoy-contexts Everything\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02706f7e",
   "metadata": {},
   "source": [
    "Let's check on the TSV files that got written to the output directory. We should see one file for every decoy context, indicating the FDR estimates for each target contig for this context; and one lone \"number of mutations per Mb\" file, indicating the number of mutations per megabase for each target contig.\n",
    "\n",
    "In general, we can plot these as FDR curves by using the FDR estimates as x-axis values and the \"number of mutations per Mb\" values as y-axis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24598a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fdr-CP2Nonsense.tsv    fdr-CP2Tv.tsv\t fdr-TvNonsense.tsv\r\n",
      "fdr-CP2Nonsyn.tsv      fdr-Full.tsv\t fdr-TvNonsyn.tsv\r\n",
      "fdr-CP2.tsv\t       fdr-Nonsense.tsv  fdr-Tv.tsv\r\n",
      "fdr-CP2TvNonsense.tsv  fdr-Nonsyn.tsv\t num-mutations-per-mb.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e9bd",
   "metadata": {},
   "source": [
    "### 6.5. Plotting FDR curves\n",
    "\n",
    "**[This notebook (in the analysis code repository)](https://nbviewer.org/github/fedarko/sheepgut/blob/main/sf-analyses/sheep/3-PlotFDRCurves.ipynb)** demonstrates how we can plot some or all of these FDR estimates for our target contigs. (I put a decent amount of work into making those plots look fancy for the paper, but you don't nee to make things that complicated unless you want to!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbee72",
   "metadata": {},
   "source": [
    "### 6.6. Fixing mutation calls' FDRs to an upper limit of $1\\%$\n",
    "\n",
    "FDR estimates are nice, but we can take things a step further. strainFlye has the ability to _fix_ the estimated FDR for each target contig's mutation calls to a specified upper limit.\n",
    "\n",
    "Since we already have FDR curves showing how, as $p$ varies, the estimated FDR for each target contig varies, fixing the estimated FDR to an upper limit $F$ amounts to choosing (for each target contig) a value of $p$ that yields a FDR ≤ $F$. The `strainFlye fdr fix` command takes care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c92390b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr fix [OPTIONS]\r\n",
      "\r\n",
      "  Fix contigs' mutation calls' estimated FDRs to an upper limit.\r\n",
      "\r\n",
      "  This takes as input the estimated FDRs from \"strainFlye fdr estimate\" (if\r\n",
      "  you used multiple decoy contexts, then you will need to choose which set of\r\n",
      "  FDR estimates to use here) to guide us on how to fix the FDR for each\r\n",
      "  contig. Note that mutations that passed the \"high\" p or r threshold\r\n",
      "  specified for \"strainFlye fdr estimate\", and thus were not used for FDR\r\n",
      "  estimation, will all be included in the output BCF file from this command;\r\n",
      "  these mutations are considered \"indisputable.\"\r\n",
      "\r\n",
      "  We include indisputable mutations from the decoy contig and from all target\r\n",
      "  contigs in our output BCF file. We will only consider including non-\r\n",
      "  indisputable mutations from the target contigs: the decision of which non-\r\n",
      "  indisputable mutations will be included is based on the lowest p or r\r\n",
      "  parameter for a target contig that yields an estimated FDR ≤ the fixed FDR\r\n",
      "  given here.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH            Indexed BCF file describing naïvely called p- or\r\n",
      "                            r-mutations, produced by \"strainFlye call\".\r\n",
      "                            [required]\r\n",
      "  -fi, --fdr-info FILE      One of the estimated FDR TSV files produced by\r\n",
      "                            \"strainFlye fdr estimate\".  [required]\r\n",
      "  --fdr FLOAT RANGE         False discovery rate at which identified mutations\r\n",
      "                            will be fixed. This is interpreted as a\r\n",
      "                            percentage: the default of 1 corresponds to an FDR\r\n",
      "                            of 1%. We do not restrict this to an upper limit,\r\n",
      "                            since estimated FDRs can technically exceed 100%.\r\n",
      "                            [default: 1; x>0]\r\n",
      "  -o, --output-bcf FILE     Filepath to which an output indexed BCF file\r\n",
      "                            (describing the called mutations at the optimal p\r\n",
      "                            or r value for each contig, along with any\r\n",
      "                            \"indisputable\" mutations relative to the --high-p\r\n",
      "                            or --high-r parameter used for strainFlye fdr\r\n",
      "                            estimate) will be written.  [required]\r\n",
      "  --verbose / --no-verbose  Display extra details while writing the filtered\r\n",
      "                            BCF.  [default: no-verbose]\r\n",
      "  -h, --help                Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a0e7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye fdr fix @ 0.00 sec: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf\n",
      "Input FDR estimate file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info.tsv\n",
      "Input FDR to fix mutation calls at: 1.0\n",
      "Verbose?: No\n",
      "Output BCF file with mutation calls at the fixed FDR: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "--------\n",
      "strainFlye fdr fix @ 0.00 sec: Loading and checking BCF and TSV files...\n",
      "strainFlye fdr fix @ 14.93 sec: Looks good so far; decoy contig seems to be edge_6104.\n",
      "strainFlye fdr fix @ 14.93 sec: Looks like the cutoff for \"indisputable\" mutations was p = 500.\n",
      "strainFlye fdr fix @ 14.93 sec: All mutations passing this cutoff will be included in the output BCF file.\n",
      "--------\n",
      "strainFlye fdr fix @ 14.93 sec: Based on the FDR information, finding optimal values of p for each contig...\n",
      "strainFlye fdr fix @ 14.95 sec: Done.\n",
      "strainFlye fdr fix @ 14.95 sec: For 155 / 467 contigs, there exist values of p (at least, considering the range from p = 15 to p = 499) that yield estimated FDRs ≤ 1.0%.\n",
      "strainFlye fdr fix @ 14.95 sec: These values range from p = 42 (edge_1300) to p = 496 (edge_58801).\n",
      "strainFlye fdr fix @ 14.95 sec: The mean of these values is p = 220.91.\n",
      "--------\n",
      "strainFlye fdr fix @ 14.95 sec: Writing a filtered BCF file (to a temporary location, for now) including both (1) indisputable mutations from all contigs and (2) non-indisputable mutations from the target contigs that result in a FDR ≤ 1.0%...\n",
      "strainFlye fdr fix @ 30.59 sec: Done.\n",
      "--------\n",
      "strainFlye fdr fix @ 30.59 sec: Updating the filtered BCF file's header to indicate that FDR fixing was done...\n",
      "strainFlye fdr fix @ 34.12 sec: Done.\n",
      "--------\n",
      "strainFlye fdr fix @ 34.12 sec: Indexing the BCF file...\n",
      "strainFlye fdr fix @ 35.04 sec: Done indexing the BCF file.\n",
      "--------\n",
      "strainFlye fdr fix @ 35.05 sec: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr fix \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf \\\n",
    "    --fdr-info /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info.tsv \\\n",
    "    --fdr 1 \\\n",
    "    --output-bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278b5d1",
   "metadata": {},
   "source": [
    "It took us a few steps, but we have now generated a file (`p15-fdr1pct.bcf`) of $p$-mutation calls at a fixed (estimated) FDR of 1%.\n",
    "\n",
    "Although our methodology has a few limitations (e.g. we don't support calling multi-allelic mutations yet), this BCF file can be used downstream for many types of analyses. In the next sections of the tutorial we'll demonstrate the additional commands supported by strainFlye, most of which make use of these mutation calls in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68353631",
   "metadata": {},
   "source": [
    "## 7. Identifying hotspots and coldspots\n",
    "\n",
    "We've called mutations and estimated these calls' FDRs. Now we can get to the fun part: what's going on with these mutations?\n",
    "\n",
    "Often, we're interested in analyzing mutations' locations in the contigs. Are there any particular \"hotspot\" regions where there are surprisingly many mutations? Are there any \"coldspot\" regions where there are, surprisingly, no or few mutations?\n",
    "\n",
    "We've kept strainFlye's functionality for identifying these types of regions fairly minimal at the moment. Here we'll demonstrate identifying very basic hotspots and coldspots using `strainFlye spot`'s commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Identify putative mutational hotspots or coldspots in contigs.\r\n",
      "\r\n",
      "  Many methods exist for identifying these sorts of hotspots or coldspots;\r\n",
      "  strainFlye's implementations of these methods are intended mostly as a quick\r\n",
      "  proof-of-concept for replicating the results shown in our paper, and are not\r\n",
      "  extremely \"feature-rich\" quite yet.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  hot-features  Identify hotspot features (for example, genes).\r\n",
      "  cold-gaps     Identify long coldspot \"gaps\" without any mutations.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8f4b9",
   "metadata": {},
   "source": [
    "### 7.1. Identifying hotspot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d78739dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot hot-features [OPTIONS]\r\n",
      "\r\n",
      "  Identify hotspot features (for example, genes).\r\n",
      "\r\n",
      "  By \"feature\", we refer to a single continuous region within a contig, as\r\n",
      "  described in the file given for --features. These regions could describe\r\n",
      "  anything: predicted protein-coding genes, introns or exons, intergenic\r\n",
      "  regions of interest, etc. For now, we treat each feature independently (e.g.\r\n",
      "  we don't lump together exons from the same \"Parent\" gene; each feature is\r\n",
      "  considered separately as a potential \"hotspot\").\r\n",
      "\r\n",
      "  You can configure whether or not we classify a feature as a hotspot by\r\n",
      "  adjusting the --min-num-mutations and --min-perc-mutations parameters; at\r\n",
      "  least one of these parameters must be specified. If both parameters are\r\n",
      "  specified, then both checks (number of mutations in a feature, and\r\n",
      "  percentage of mutations in a feature) will need to pass in order for us to\r\n",
      "  label a feature as a hotspot.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH                  Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -f, --features PATH             Generic Feature Format version 3 (GFF3) file\r\n",
      "                                  describing \"features\" (e.g. predicted\r\n",
      "                                  protein-coding genes) in the contigs. We\r\n",
      "                                  will ignore features located on contigs that\r\n",
      "                                  are not described in the BCF file's header.\r\n",
      "                                  [required]\r\n",
      "  -mn, --min-num-mutations INTEGER RANGE\r\n",
      "                                  Label a feature as a \"hotspot\" if it\r\n",
      "                                  contains at least this many mutations.\r\n",
      "                                  [default: (no check); x>0]\r\n",
      "  -mp, --min-perc-mutations FLOAT RANGE\r\n",
      "                                  Label a feature as a \"hotspot\" if its\r\n",
      "                                  percentage of mutations ((# mutations /\r\n",
      "                                  feature length) × 100) is at least this\r\n",
      "                                  value.  [default: (no check); 0<x<=100]\r\n",
      "  -o, --output-hotspots FILE      Filepath to which an output tab-separated\r\n",
      "                                  values (TSV) file describing hotspot\r\n",
      "                                  features across all contigs will be written.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot hot-features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf53d31",
   "metadata": {},
   "source": [
    "#### 7.1.1. A note about \"features\"\n",
    "\n",
    "Although we should be familiar with the FASTA and BCF input files by this point, the `-f` / `--features` input (a GFF3 file) may be surprising. strainFlye leaves the task of creating this file up to the user.\n",
    "\n",
    "Predicted genes' coordinates are probably the most obvious type of \"feature\" for which we could look for hotspots. If you don't have gene predictions for your contigs yet, [Prodigal](https://github.com/hyattpd/Prodigal) is good (and should have been installed along with strainFlye, since other parts of strainFlye make use of it internally). Here, we'll use it to predict protein-coding genes across all contigs.\n",
    "\n",
    "It's important to note that Prodigal does not predict eukaryotic genes (i.e. genes that are split up into introns and exons). These genes will thus not be a perfect representation of all protein-coding genes in all contigs in the dataset, since we know that this sample does contain at least some eukaryotic genomes. (However, if you use another tool for predicting eukaryotic genes that produces GFF3 output, then these should also be usable as \"features\" for this command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/hyattpd/Prodigal/wiki/cheat-sheet for details about these options.\n",
    "#\n",
    "# Note that, for the paper, I ran Prodigal in \"normal\" mode on certain contigs individually\n",
    "# (https://github.com/fedarko/sheepgut/blob/main/inspect-seqs/prodigal.py), but here we just\n",
    "# run Prodigal in \"anonymous\" mode on all contigs at once. The results should be fairly similar,\n",
    "# although there'll probably be some differences.\n",
    "!prodigal \\\n",
    "    -i /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    -f gff \\\n",
    "    -c \\\n",
    "    -p meta \\\n",
    "    -o /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287432e8",
   "metadata": {},
   "source": [
    "#### 7.1.2. Running the command to identify hotspot features (hotspot predicted genes)\n",
    "\n",
    "Now that we have our gene predictions, let's move see if any of them have a lot of mutations. (Based on our findings in the paper, we know that these sorts of hotspots do exist in this dataset.)\n",
    "\n",
    "`strainFlye spot hot-features` supports two types of basic thresholds for labelling a feature as a hotspot, `--min-num-mutations` and `--min-perc-mutations`. We'll use both here, and label a feature a \"hotspot\" if it meets both of the following criteria:\n",
    "\n",
    "1. it contains at least 5 mutations, and\n",
    "2. at least 2% of its positions have mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "901b5606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "spot hot-features @ 0.00s: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "Input feature file: /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff\n",
      "Input minimum number of mutations needed to call a feature a hotspot: 5\n",
      "Input minimum % of mutations needed to call a feature a hotspot: 2.0\n",
      "Output file describing hotspot features: /Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv\n",
      "--------\n",
      "spot hot-features @ 0.00s: Loading and checking the BCF file...\n",
      "spot hot-features @ 12.20s: Looks good so far.\n",
      "--------\n",
      "spot hot-features @ 12.20s: Going through features in the GFF3 file and identifying hotspot features...\n",
      "spot hot-features @ 100.13s: Identified 57,188 hotspot feature(s) across all 468 contigs in the BCF file.\n",
      "--------\n",
      "spot hot-features @ 100.13s: Writing out this information to a TSV file...\n",
      "spot hot-features @ 100.29s: Done.\n",
      "--------\n",
      "spot hot-features @ 100.30s: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot hot-features \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --features /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff \\\n",
    "    --min-num-mutations 5 \\\n",
    "    --min-perc-mutations 2 \\\n",
    "    --output-hotspots /Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5a443",
   "metadata": {},
   "source": [
    "The output of this command isn't anything special: it's a TSV file in which each row describes an identified hotspot feature, defining \"hotspots\" based on the `--min-num-mutations` and `--min-perc-mutations` options we set earlier. Let's load this file using `pandas.read_csv()` and get a brief sense of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e01d9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>FeatureStart_1IndexedInclusive</th>\n",
       "      <th>FeatureEnd_1IndexedInclusive</th>\n",
       "      <th>NumberMutatedPositions</th>\n",
       "      <th>PercentMutatedPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_765</td>\n",
       "      <td>865350</td>\n",
       "      <td>866369</td>\n",
       "      <td>32</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_781</td>\n",
       "      <td>873414</td>\n",
       "      <td>873626</td>\n",
       "      <td>5</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_787</td>\n",
       "      <td>878293</td>\n",
       "      <td>879429</td>\n",
       "      <td>48</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_788</td>\n",
       "      <td>879444</td>\n",
       "      <td>881552</td>\n",
       "      <td>101</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_789</td>\n",
       "      <td>881718</td>\n",
       "      <td>882956</td>\n",
       "      <td>42</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contig FeatureID  FeatureStart_1IndexedInclusive  \\\n",
       "0  edge_8     8_765                          865350   \n",
       "1  edge_8     8_781                          873414   \n",
       "2  edge_8     8_787                          878293   \n",
       "3  edge_8     8_788                          879444   \n",
       "4  edge_8     8_789                          881718   \n",
       "\n",
       "   FeatureEnd_1IndexedInclusive  NumberMutatedPositions  \\\n",
       "0                        866369                      32   \n",
       "1                        873626                       5   \n",
       "2                        879429                      48   \n",
       "3                        881552                     101   \n",
       "4                        882956                      42   \n",
       "\n",
       "   PercentMutatedPositions  \n",
       "0                     3.14  \n",
       "1                     2.35  \n",
       "2                     4.22  \n",
       "3                     4.79  \n",
       "4                     3.39  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotspots = pd.read_csv(\"/Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv\", sep=\"\\t\")\n",
    "hotspots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6d03c",
   "metadata": {},
   "source": [
    "Depending on your goals, we could focus on—for example—the hotspot genes with the highest mutation rates in a contig. We can compute this for `edge_1671` (\"BACT1\", as we name it in our paper) by filtering and then sorting the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc09e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>FeatureStart_1IndexedInclusive</th>\n",
       "      <th>FeatureEnd_1IndexedInclusive</th>\n",
       "      <th>NumberMutatedPositions</th>\n",
       "      <th>PercentMutatedPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12437</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_860</td>\n",
       "      <td>1041656</td>\n",
       "      <td>1042084</td>\n",
       "      <td>86</td>\n",
       "      <td>20.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1217</td>\n",
       "      <td>1460034</td>\n",
       "      <td>1460204</td>\n",
       "      <td>34</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12373</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_183</td>\n",
       "      <td>206606</td>\n",
       "      <td>207304</td>\n",
       "      <td>131</td>\n",
       "      <td>18.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12467</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1168</td>\n",
       "      <td>1402353</td>\n",
       "      <td>1402718</td>\n",
       "      <td>61</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1102</td>\n",
       "      <td>1326288</td>\n",
       "      <td>1327073</td>\n",
       "      <td>120</td>\n",
       "      <td>15.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12422</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_751</td>\n",
       "      <td>916664</td>\n",
       "      <td>918493</td>\n",
       "      <td>37</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12375</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_248</td>\n",
       "      <td>272253</td>\n",
       "      <td>273047</td>\n",
       "      <td>16</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1131</td>\n",
       "      <td>1361175</td>\n",
       "      <td>1361672</td>\n",
       "      <td>10</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12421</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_750</td>\n",
       "      <td>914486</td>\n",
       "      <td>916576</td>\n",
       "      <td>42</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_585</td>\n",
       "      <td>727563</td>\n",
       "      <td>728657</td>\n",
       "      <td>22</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Contig  FeatureID  FeatureStart_1IndexedInclusive  \\\n",
       "12437  edge_1671   1671_860                         1041656   \n",
       "12473  edge_1671  1671_1217                         1460034   \n",
       "12373  edge_1671   1671_183                          206606   \n",
       "12467  edge_1671  1671_1168                         1402353   \n",
       "12456  edge_1671  1671_1102                         1326288   \n",
       "...          ...        ...                             ...   \n",
       "12422  edge_1671   1671_751                          916664   \n",
       "12375  edge_1671   1671_248                          272253   \n",
       "12461  edge_1671  1671_1131                         1361175   \n",
       "12421  edge_1671   1671_750                          914486   \n",
       "12405  edge_1671   1671_585                          727563   \n",
       "\n",
       "       FeatureEnd_1IndexedInclusive  NumberMutatedPositions  \\\n",
       "12437                       1042084                      86   \n",
       "12473                       1460204                      34   \n",
       "12373                        207304                     131   \n",
       "12467                       1402718                      61   \n",
       "12456                       1327073                     120   \n",
       "...                             ...                     ...   \n",
       "12422                        918493                      37   \n",
       "12375                        273047                      16   \n",
       "12461                       1361672                      10   \n",
       "12421                        916576                      42   \n",
       "12405                        728657                      22   \n",
       "\n",
       "       PercentMutatedPositions  \n",
       "12437                    20.05  \n",
       "12473                    19.88  \n",
       "12373                    18.74  \n",
       "12467                    16.67  \n",
       "12456                    15.27  \n",
       "...                        ...  \n",
       "12422                     2.02  \n",
       "12375                     2.01  \n",
       "12461                     2.01  \n",
       "12421                     2.01  \n",
       "12405                     2.01  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bact1_hotspots = hotspots[hotspots[\"Contig\"] == \"edge_1671\"]\n",
    "\n",
    "# Sort all the \"hotspot genes\" in BACT1 from high to low mutation rates (% of positions mutated).\n",
    "# This is similar to the table of highly-mutated genes in the Supplemental Material of our paper,\n",
    "# although unlike that table this uses FDR-fixed mutations (and it also uses different gene\n",
    "# predictions, as discussed above).\n",
    "bact1_hotspots.sort_values([\"PercentMutatedPositions\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b73a9",
   "metadata": {},
   "source": [
    "### 7.2. Identifying coldspot gaps\n",
    "\n",
    "Similarly, strainFlye supports the identification of basic \"coldspots\"—here, defined as long gaps without any mutations. The main parameter is the minimum length needed to define a gap as a \"coldspot.\" Let's test this out on the SheepGut dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cd7c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot cold-gaps [OPTIONS]\r\n",
      "\r\n",
      "  Identify long coldspot \"gaps\" without any mutations.\r\n",
      "\r\n",
      "  To clarify, we define a \"gap\" of length L on a contig as a collection of\r\n",
      "  continuous positions [N, N + 1, ... N + L - 2, N + L - 1] in which no\r\n",
      "  positions are mutations (based on the input BCF file).\r\n",
      "\r\n",
      "  If the --circular flag is specified, then we can loop around the contig from\r\n",
      "  right to left; otherwise, the left and right sides of the contig are hard\r\n",
      "  boundaries. To give an example of this, consider a 9-nucleotide contig that\r\n",
      "  has mutations at positions 4 and 6:\r\n",
      "\r\n",
      "                             Mut.    Mut.\r\n",
      "                  1   2   3   4   5   6   7   8   9\r\n",
      "\r\n",
      "  If --circular is specified, then this contig has two gaps: one gap of length\r\n",
      "  1 (covering just position 5, between the two mutations), and another gap of\r\n",
      "  length 6 (starting at position 7 and looping around to position 3: [7, 8, 9,\r\n",
      "  1, 2, 3]).\r\n",
      "\r\n",
      "  If --circular is not specified, then this contig has three gaps: [1, 2, 3],\r\n",
      "  [5], and [7, 8, 9].\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH                  Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -l, --min-length INTEGER RANGE  Label a gap between mutations in a contig as\r\n",
      "                                  a \"coldspot\" if the gap is at least this\r\n",
      "                                  long (in bp).  [default: 5000; x>0;\r\n",
      "                                  required]\r\n",
      "  --circular / --no-circular      If --circular is specified, we'll assume\r\n",
      "                                  that all contigs are circular: we'll\r\n",
      "                                  consider the gap \"looping around\" from the\r\n",
      "                                  rightmost mutation in each contig to the\r\n",
      "                                  leftmost mutation in the contig as a\r\n",
      "                                  potential coldspot. Otherwise, we will\r\n",
      "                                  assume all contigs are linear.  [default:\r\n",
      "                                  no-circular]\r\n",
      "  --exact-pvals / --no-exact-pvals\r\n",
      "                                  If --exact-pvals is specified, we'll use the\r\n",
      "                                  method for computing exact longest-gap\r\n",
      "                                  p-values given in equation (3.1) of (Naus\r\n",
      "                                  1982). We use Python's decimal library with\r\n",
      "                                  default parameters to try to deal with large\r\n",
      "                                  numbers, but we can't guarantee that this\r\n",
      "                                  won't cause the program to fail in certain\r\n",
      "                                  cases. If --exact-pvals is not specified,\r\n",
      "                                  we'll use equation (3.3) of (Naus 1982),\r\n",
      "                                  which gives an approximation of the p-value.\r\n",
      "                                  [default: exact-pvals]\r\n",
      "  -o, --output-coldspots FILE     Filepath to which an output tab-separated\r\n",
      "                                  values (TSV) file describing coldspots will\r\n",
      "                                  be written. The longest gap in each contig\r\n",
      "                                  will also be given a p-value, indicating the\r\n",
      "                                  probability of the longest gap being at\r\n",
      "                                  least this long (given the length of and\r\n",
      "                                  number of mutated positions in this contig,\r\n",
      "                                  and assuming that mutations occur with a\r\n",
      "                                  constant probability at any position in the\r\n",
      "                                  contig). See (Naus 1982) for details.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot cold-gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a221ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "spot cold-gaps @ 0.00s: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "Minimum coldspot gap length: 5,000 bp\n",
      "Check for circular coldspot gaps?: No\n",
      "Compute exact longest-gap p-values?: Yes\n",
      "Output file describing coldspot gaps: /Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv\n",
      "--------\n",
      "spot cold-gaps @ 0.00s: Loading and checking the BCF file...\n",
      "spot cold-gaps @ 12.10s: Looks good so far.\n",
      "--------\n",
      "spot cold-gaps @ 12.10s: Going through contigs and identifying coldspot gaps...\n",
      "spot cold-gaps @ 15.71s: Identified 15,258 coldspot gap(s) across all 468 contigs in the BCF file.\n",
      "--------\n",
      "spot cold-gaps @ 15.71s: Writing out this information to a TSV file...\n",
      "spot cold-gaps @ 15.72s: Done.\n",
      "--------\n",
      "spot cold-gaps @ 15.72s: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot cold-gaps \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --output-coldspots /Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3a8c2",
   "metadata": {},
   "source": [
    "Again, `cold-gaps` will output a simple TSV file describing its identified coldspots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0c1feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Start_1IndexedInclusive</th>\n",
       "      <th>End_1IndexedInclusive</th>\n",
       "      <th>Length</th>\n",
       "      <th>LongestGap_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>383672</td>\n",
       "      <td>681281</td>\n",
       "      <td>297610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>681283</td>\n",
       "      <td>715603</td>\n",
       "      <td>34321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>717621</td>\n",
       "      <td>865477</td>\n",
       "      <td>147857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>885778</td>\n",
       "      <td>906394</td>\n",
       "      <td>20617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>913216</td>\n",
       "      <td>920714</td>\n",
       "      <td>7499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contig  Start_1IndexedInclusive  End_1IndexedInclusive  Length  \\\n",
       "0  edge_8                   383672                 681281  297610   \n",
       "1  edge_8                   681283                 715603   34321   \n",
       "2  edge_8                   717621                 865477  147857   \n",
       "3  edge_8                   885778                 906394   20617   \n",
       "4  edge_8                   913216                 920714    7499   \n",
       "\n",
       "   LongestGap_P_Value  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldspots = pd.read_csv(\"/Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv\", sep=\"\\t\")\n",
    "coldspots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b28dcf",
   "metadata": {},
   "source": [
    "There are many ways we could make use of this information—similarly to the hotspot example, we could try sorting these gaps from longest to shortest for the BACT1 contig. This is shown below. (Of the gaps that we identify, the longest one in each contig is assigned a _p_-value; please see the Supplemental Material of our paper for details on how we compute this, and the assumptions made.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62a1e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Start_1IndexedInclusive</th>\n",
       "      <th>End_1IndexedInclusive</th>\n",
       "      <th>Length</th>\n",
       "      <th>LongestGap_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1216892</td>\n",
       "      <td>1239536</td>\n",
       "      <td>22645</td>\n",
       "      <td>1.168921e-103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1618448</td>\n",
       "      <td>1637614</td>\n",
       "      <td>19167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1797824</td>\n",
       "      <td>1813581</td>\n",
       "      <td>15758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1194740</td>\n",
       "      <td>1207381</td>\n",
       "      <td>12642</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>2140896</td>\n",
       "      <td>2153394</td>\n",
       "      <td>12499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>979572</td>\n",
       "      <td>990495</td>\n",
       "      <td>10924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>740701</td>\n",
       "      <td>750399</td>\n",
       "      <td>9699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1207881</td>\n",
       "      <td>1216890</td>\n",
       "      <td>9010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1183003</td>\n",
       "      <td>1191716</td>\n",
       "      <td>8714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>972772</td>\n",
       "      <td>979570</td>\n",
       "      <td>6799</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>332394</td>\n",
       "      <td>338967</td>\n",
       "      <td>6574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>541117</td>\n",
       "      <td>546507</td>\n",
       "      <td>5391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>941510</td>\n",
       "      <td>946720</td>\n",
       "      <td>5211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Contig  Start_1IndexedInclusive  End_1IndexedInclusive  Length  \\\n",
       "2387  edge_1671                  1216892                1239536   22645   \n",
       "2388  edge_1671                  1618448                1637614   19167   \n",
       "2389  edge_1671                  1797824                1813581   15758   \n",
       "2385  edge_1671                  1194740                1207381   12642   \n",
       "2390  edge_1671                  2140896                2153394   12499   \n",
       "2383  edge_1671                   979572                 990495   10924   \n",
       "2380  edge_1671                   740701                 750399    9699   \n",
       "2386  edge_1671                  1207881                1216890    9010   \n",
       "2384  edge_1671                  1183003                1191716    8714   \n",
       "2382  edge_1671                   972772                 979570    6799   \n",
       "2378  edge_1671                   332394                 338967    6574   \n",
       "2379  edge_1671                   541117                 546507    5391   \n",
       "2381  edge_1671                   941510                 946720    5211   \n",
       "\n",
       "      LongestGap_P_Value  \n",
       "2387       1.168921e-103  \n",
       "2388                 NaN  \n",
       "2389                 NaN  \n",
       "2385                 NaN  \n",
       "2390                 NaN  \n",
       "2383                 NaN  \n",
       "2380                 NaN  \n",
       "2386                 NaN  \n",
       "2384                 NaN  \n",
       "2382                 NaN  \n",
       "2378                 NaN  \n",
       "2379                 NaN  \n",
       "2381                 NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldspots[coldspots[\"Contig\"] == \"edge_1671\"].sort_values([\"Length\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60dad6b",
   "metadata": {},
   "source": [
    "## 8. Phasing analyses\n",
    "\n",
    "### 8.1. Generating \"smoothed haplotypes\"\n",
    "\n",
    "Given our called mutations, we can attempt to generate haplotypes that respect these mutations using strainFlye's `smooth` module.\n",
    "\n",
    "The details and motivation for this are explained in depth in our paper. To briefly summarize, we will convert the reads aligned to each contig into \"smoothed reads,\" which only contain our called mutations with no other variations. We will then (optionally, depending on the `--virtual-reads` parameter) construct \"virtual reads\" to fill in low-coverage regions. We will then assemble these reads using [LJA](https://github.com/AntonBankevich/LJA/) to construct \"smoothed haplotypes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "591b2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Create and assemble smoothed and virtual reads.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  create    Create smoothed and virtual reads for each contig.\r\n",
      "  assemble  Assemble contigs' smoothed and virtual reads using LJA.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdadda6",
   "metadata": {},
   "source": [
    "#### 8.1.1. Create smoothed and virtual reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c81a60e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth create [OPTIONS]\r\n",
      "\r\n",
      "  Create smoothed and virtual reads for each contig.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs for which we will\r\n",
      "                                  create smoothed and virtual reads. All\r\n",
      "                                  contigs in this FASTA file should also be\r\n",
      "                                  contained in the BAM and BCF files; it's ok\r\n",
      "                                  if the BAM or BCF files contain contigs not\r\n",
      "                                  in this FASTA file (we'll ignore them).\r\n",
      "                                  [required]\r\n",
      "  --bam PATH                      Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --bcf PATH                      Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -di, --diversity-indices PATH   TSV file describing the diversity indices of\r\n",
      "                                  a set of contigs, produced by one of the\r\n",
      "                                  \"strainFlye call\" commands. Only used if\r\n",
      "                                  --virtual-reads is specified. Along with\r\n",
      "                                  diversity indices, these files list contigs'\r\n",
      "                                  average coverages. If --virtual-reads is\r\n",
      "                                  specified, we will need to know contigs'\r\n",
      "                                  average coverages. So, if a diversity\r\n",
      "                                  indices file is provided here, then we can\r\n",
      "                                  avoid re-computing average coverages.\r\n",
      "                                  (Otherwise, if --virtual-reads is specified\r\n",
      "                                  but no diversity indices file is provided,\r\n",
      "                                  we'll need to compute average coverages;\r\n",
      "                                  this will take some extra time.)  [default:\r\n",
      "                                  (nothing)]\r\n",
      "  --virtual-reads / --no-virtual-reads\r\n",
      "                                  If --virtual-reads is specified, we'll\r\n",
      "                                  create virtual reads covering \"low-coverage\"\r\n",
      "                                  regions in contigs.  [default: virtual-\r\n",
      "                                  reads]\r\n",
      "  -vrp, --virtual-read-well-covered-perc FLOAT RANGE\r\n",
      "                                  Only used if --virtual-reads is specified.\r\n",
      "                                  In a contig with average coverage (based on\r\n",
      "                                  the BAM file, and only considering match +\r\n",
      "                                  mismatch counts) C, we will define a\r\n",
      "                                  position in this contig (with coverage P,\r\n",
      "                                  based only on the smoothed reads) as low-\r\n",
      "                                  coverage if ((P / C) × 100) is less than\r\n",
      "                                  this percentage.  [default: 95; 0<=x<=100;\r\n",
      "                                  required]\r\n",
      "  -vrf, --virtual-read-flank INTEGER RANGE\r\n",
      "                                  Only used if --virtual-reads is specified.\r\n",
      "                                  When we add virtual reads spanning a single\r\n",
      "                                  continuous low-coverage region, these reads\r\n",
      "                                  will start and end this many positions\r\n",
      "                                  before and after the region. (For example,\r\n",
      "                                  the default of 100 means that the virtual\r\n",
      "                                  reads created for a low-coverage region of\r\n",
      "                                  5,000 bp will all be 5,200 bp.)  [default:\r\n",
      "                                  100; x>=0; required]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which smoothed reads (and\r\n",
      "                                  virtual reads, if --virtual-reads is\r\n",
      "                                  specified) will be written. Each contig's\r\n",
      "                                  reads will be written to a gzipped FASTA\r\n",
      "                                  file in this directory named\r\n",
      "                                  [contig].fasta.gz.  [required]\r\n",
      "  --verbose / --no-verbose        Display extra details while running.\r\n",
      "                                  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye smooth create \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --diversity-indices /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24302a1b",
   "metadata": {},
   "source": [
    "#### 8.1.2. Assemble these reads using LJA\n",
    "\n",
    "This step assumes that we have already installed [LJA](https://github.com/AntonBankevich/LJA/), in particular the `simple_ec` branch of it. Please see [LJA's manual](https://github.com/AntonBankevich/LJA/blob/main/docs/lja_manual.md) for installation instructions.\n",
    "\n",
    "I have installed LJA into a specific location on our cluster. So that strainFlye can easily run LJA for each contig's reads files, we pass the location of LJA's binary executable to strainFlye below using the `--lja-bin` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89064151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth assemble [OPTIONS]\r\n",
      "\r\n",
      "  Assemble contigs' smoothed and virtual reads using LJA.\r\n",
      "\r\n",
      "  Please note that this command relies on the \"simple_ec\" branch of LJA being\r\n",
      "  installed on your system. See strainFlye's README (and/or LJA's manual) for\r\n",
      "  details on installing LJA.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -r, --reads-dir DIRECTORY   Directory produced by \"strainFlye smooth create\"\r\n",
      "                              containing smoothed (and optionally virtual)\r\n",
      "                              reads. We will use LJA to assemble each\r\n",
      "                              *.fasta.gz file in this directory (representing\r\n",
      "                              reads from different contigs) independently.\r\n",
      "                              [required]\r\n",
      "  -p, --lja-params TEXT       Additional parameters to pass to LJA, besides\r\n",
      "                              the --reads and --output-dir parameters. To\r\n",
      "                              explain our defaults: the --simpleec flag is\r\n",
      "                              currently only available on the simple_ec branch\r\n",
      "                              of LJA. This flag tells LJA to perform \"simple\"\r\n",
      "                              error correction by removing all edges in the de\r\n",
      "                              Bruijn graph with k-mer coverage less than\r\n",
      "                              --Cov-threshold (10), as well as reads passing\r\n",
      "                              through these edges. This \"simple\" error\r\n",
      "                              correction is done instead of running the\r\n",
      "                              default LJA error correction module, mowerDBG.\r\n",
      "                              Please note that we do not perform any\r\n",
      "                              validation on this string before passing it to\r\n",
      "                              LJA (so if you are allowing users to run\r\n",
      "                              strainFlye through a web server, be careful\r\n",
      "                              about shell injection).  [default: --simpleec\r\n",
      "                              --Cov-threshold 10]\r\n",
      "  -b, --lja-bin FILE          Location of LJA's \"lja\" binary file, which can\r\n",
      "                              be used to run LJA. This should be located in\r\n",
      "                              the bin/ directory constructed when you compiled\r\n",
      "                              LJA. If this is not provided, we will check to\r\n",
      "                              see if LJA is available in your $PATH.\r\n",
      "                              [default: (Look for LJA's bin in the $PATH\r\n",
      "                              environment variable)]\r\n",
      "  -o, --output-dir DIRECTORY  Directory to which output LJA assemblies (one\r\n",
      "                              top-level directory  per *.fasta.gz file in the\r\n",
      "                              input --reads-dir) will be written.  [required]\r\n",
      "  --verbose / --no-verbose    Display extra details while running.  [default:\r\n",
      "                              no-verbose]\r\n",
      "  -h, --help                  Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye smooth assemble \\\n",
    "    --reads-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/reads \\\n",
    "    --lja-bin /home/mfedarko/software/LJA-branch/bin/lja \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/assemblies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c59705",
   "metadata": {},
   "source": [
    "Once you've created these assemblies, you can then analyze them like you would any other assembly of a MAG. You may want to visualize the assembly graphs, for example—[Bandage](https://github.com/rrwick/Bandage), [AGB](https://github.com/almiheenko/AGB/), and [MetagenomeScope](https://github.com/marbl/MetagenomeScope) are a few tools that can do this.\n",
    "\n",
    "For information about LJA-specific details of the outputs (e.g. what files mean what), please see [LJA's manual](https://github.com/AntonBankevich/LJA/blob/main/docs/lja_manual.md#output-of-la-jolla-assembler)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfb60a",
   "metadata": {},
   "source": [
    "### 8.2. Constructing link graphs\n",
    "\n",
    "As a related analysis, we can construct _link graphs_ showing \"how much\" of a contig we can potentially phase. These graphs are described in detail in the Supplemental Material of our paper.\n",
    "\n",
    "Long story short, creating link graphs in strainFlye has two steps (like performing smoothed-read assembly above). First, we'll compute nucleotide (co-)occurrence data for each contig; then, we'll convert this data into link graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93a656fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye link [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Create link graphs showing co-occurring alleles.\r\n",
      "\r\n",
      "  The \"nt\" command should be run first; this generates information about the\r\n",
      "  counts and co-occurrences of nucleotides at mutated positions in a contig.\r\n",
      "\r\n",
      "  The \"graph\" command takes as input the information produced by \"nt\" and\r\n",
      "  creates link graphs (one link graph per contig) from it. There are many\r\n",
      "  parameters that impact the graph creation, so we have split this into two\r\n",
      "  steps in order to make it easy to rerun the \"graph\" step with different\r\n",
      "  parameter settings if needed (the \"nt\" command will likely take longer to\r\n",
      "  run).\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  nt     Compute (co-)occurrence information for mutations' nucleotides.\r\n",
      "  graph  Convert (co-)occurrence information into a link graph structure.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d77da2b",
   "metadata": {},
   "source": [
    "#### 8.2.1. Compute nucleotide (co-)occurrence information\n",
    "\n",
    "##### A brief note about filtering\n",
    "Note that, in the paper's Supplemental Material, we limited our focus to mutated positions with coverages of at least 1,000x. We do not do this here. If you'd to only consider mutations occurring at positions with at least a certain coverage, you'll need to filter the BCF file yourself. (You can probably use [bcftools](https://samtools.github.io/bcftools/howtos/filtering.html) to do this; if you are using a BCF file produced by strainFlye, then you can filter based on the `MDP` info tag, which describes the number of matching + mismatching reads at a mutated position.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37e6bde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye link nt [OPTIONS]\r\n",
      "\r\n",
      "  Compute (co-)occurrence information for mutations' nucleotides.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH          FASTA file of contigs for which we will create\r\n",
      "                              link graphs. All contigs in this FASTA file\r\n",
      "                              should also be contained in the BAM and BCF\r\n",
      "                              files; it's ok if the BAM or BCF files contain\r\n",
      "                              contigs not in this FASTA file (we'll ignore\r\n",
      "                              them).  [required]\r\n",
      "  --bam PATH                  Sorted and indexed BAM file representing an\r\n",
      "                              alignment of reads to contigs.  [required]\r\n",
      "  --bcf PATH                  Indexed BCF file describing single-nucleotide\r\n",
      "                              mutations in a set of contigs.  [required]\r\n",
      "  -o, --output-dir DIRECTORY  Directory to which information about nucleotide\r\n",
      "                              frequencies at the mutated positions in each\r\n",
      "                              contig, as well as co-occurrence information\r\n",
      "                              between pairs of mutated positions, will be\r\n",
      "                              written. Each contig will be represented by two\r\n",
      "                              \"pickle\" files within this directory, one\r\n",
      "                              describing nucleotide frequencies at each\r\n",
      "                              position and one describing nucleotide pair\r\n",
      "                              frequencies at pairs of positions; each file's\r\n",
      "                              name will be prefixed with the corresponding\r\n",
      "                              contig name.  [required]\r\n",
      "  --verbose / --no-verbose    Display extra details while running.  [default:\r\n",
      "                              no-verbose]\r\n",
      "  -h, --help                  Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye link nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5b5fbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "link nt @ 0.00s: Starting...\n",
      "Input contig file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\n",
      "Input BAM file: /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "Verbose?: Yes\n",
      "Output directory: /Poppy/mfedarko/sftests/tutorial-output/link/nt\n",
      "--------\n",
      "link nt @ 0.00s: Loading and checking FASTA, BAM, and BCF files...\n",
      "link nt @ 5.38s: The FASTA file describes 468 contig(s).\n",
      "link nt @ 5.68s: All FASTA contig(s) are included in the BAM file (this BAM file has 78,793 reference(s)).\n",
      "link nt @ 18.47s: All FASTA contig(s) are included in the BCF file (the header of this BCF file describes 468 contig(s)).\n",
      "link nt @ 18.48s: The lengths of all contig(s) in the FASTA file match the corresponding lengths in the BAM and BCF files.\n",
      "link nt @ 18.48s: So far, these files seem good.\n",
      "--------\n",
      "link nt @ 18.48s: Going through contigs and computing nucleotide (co-)occurrence information...\n",
      "link nt @ 18.49s: On contig edge_8 (1,710,962 bp) (1 / 468 contigs = 0.21%).\n",
      "link nt @ 18.49s: Contig edge_8 has 2,460 mutated position(s). Going through alignments to this contig...\n",
      "link nt @ 48.38s: Found 2,360 read(s) spanning ≥ 1 mutated position in contig edge_8. Computing (co-)occurrence info...\n",
      "link nt @ 69.98s: Wrote out (co-)occurrence info for contig edge_8.\n",
      "link nt @ 69.98s: On contig edge_10 (1,556,982 bp) (2 / 468 contigs = 0.43%).\n",
      "link nt @ 69.98s: Contig edge_10 has 2,096 mutated position(s). Going through alignments to this contig...\n",
      "link nt @ 73.86s: Found 517 read(s) spanning ≥ 1 mutated position in contig edge_10. Computing (co-)occurrence info...\n",
      "link nt @ 84.35s: Wrote out (co-)occurrence info for contig edge_10.\n",
      "link nt @ 84.35s: On contig edge_15 (3,930,935 bp) (3 / 468 contigs = 0.64%).\n",
      "link nt @ 84.36s: Contig edge_15 has 6,910 mutated position(s). Going through alignments to this contig...\n",
      "^C\n",
      "\n",
      "Aborted!\n"
     ]
    }
   ],
   "source": [
    "!strainFlye link nt \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/link/nt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3835b734",
   "metadata": {},
   "source": [
    "#### 8.2.2. Convert this information to create link graphs\n",
    "\n",
    "This next command directly takes as input the information we just computed. You can experiment with various parameters of graph construction here, if you'd like; the defaults match what we have set in the paper. (The help text for this command, shown below, explains these parameters in detail.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08a29184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye link graph [OPTIONS]\r\n",
      "\r\n",
      "  Convert (co-)occurrence information into a link graph structure.\r\n",
      "\r\n",
      "  We create one link graph per contig. These graphs are undirected. A node (i,\r\n",
      "  Ni) in the graph represents an allele: in other words, the occurrence of\r\n",
      "  nucleotide Ni (one of {A, C, G, T}) at position i (1-indexed).\r\n",
      "\r\n",
      "  What do edges between nodes represent? To answer that, let's define reads(i,\r\n",
      "  Ni) as the number of reads at which Ni is aligned to i. Let's also define\r\n",
      "  reads(i, j, Ni, Nj) as the number of reads at which Ni is aligned to i, and\r\n",
      "  Nj is aligned to j.\r\n",
      "\r\n",
      "  Given these definitions, we define the link weight between two alleles (i,\r\n",
      "  Ni) and (j, Nj) as\r\n",
      "\r\n",
      "                               reads(i, j, Ni, Nj)\r\n",
      "   link(i, j, Ni, Nj) = -----------------------------------\r\n",
      "                          max(reads(i, Ni), reads(j, Nj))\r\n",
      "\r\n",
      "  We create an edge between nodes (i, Ni) and (j, Nj) if both of the following\r\n",
      "  conditions hold:\r\n",
      "\r\n",
      "  1. The number of reads spanning both i and j with any (non-degenerate)\r\n",
      "  nucleotides aligned to either position is ≥ the --min-span parameter.\r\n",
      "\r\n",
      "  2. link(i, j, Ni, Nj) > the --low-link parameter.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -n, --nt-dir DIRECTORY        Directory produced by \"strainFlye link nt\"\r\n",
      "                                containing \"pickle\" files describing\r\n",
      "                                nucleotide (co-)occurrence information for\r\n",
      "                                certain contigs.  [required]\r\n",
      "  --min-nt-count INTEGER RANGE  We will only create a node representing a\r\n",
      "                                given nucleotide at a mutated position if this\r\n",
      "                                nucleotide is supported by at least this many\r\n",
      "                                reads at this position.  [default: 2; x>=1]\r\n",
      "  --min-span INTEGER RANGE      One of the prerequisites for creating an edge\r\n",
      "                                between two nodes (representing nucleotides\r\n",
      "                                Ni, Nj at mutated positions i and j) is that\r\n",
      "                                the total number of reads spanning both i and\r\n",
      "                                j, across all combinations of (non-degenerate)\r\n",
      "                                nucleotides at both i and j, is at least this\r\n",
      "                                parameter.  [default: 501; x>=1]\r\n",
      "  --low-link FLOAT RANGE        The other prerequisite for creating an edge\r\n",
      "                                between two nodes (representing nucleotides\r\n",
      "                                Ni, Nj at mutated positions i and j) is that\r\n",
      "                                link(i, j, Ni, Nj) > this parameter. Note this\r\n",
      "                                check is not inclusive (i.e. the default of 0\r\n",
      "                                means that, if reads(i, j, Ni, Nj) = 0, we\r\n",
      "                                will never create an edge between (i, Ni) and\r\n",
      "                                (j, Nj).  [default: 0; 0<=x<1]\r\n",
      "  -f, --output-format [dot|nx]  Format in which to write out each contig's\r\n",
      "                                link graph. \"dot\" will write out graphs in\r\n",
      "                                Graphviz' DOT language; \"nx\" will write out\r\n",
      "                                graphs to \"pickle\" files, in which each link\r\n",
      "                                graph is a NetworkX object.  [default: dot]\r\n",
      "  -o, --output-dir DIRECTORY    Directory to which graphs will be written.\r\n",
      "                                We'll write one graph file per contig; each\r\n",
      "                                file's name will be prefixed with the\r\n",
      "                                corresponding contig name.  [required]\r\n",
      "  --verbose / --no-verbose      Display extra details while running.\r\n",
      "                                [default: no-verbose]\r\n",
      "  -h, --help                    Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye link graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye link graph \\\n",
    "    --nt-dir /Poppy/mfedarko/sftests/tutorial-output/link/nt \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/link/graph \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea8804",
   "metadata": {},
   "source": [
    "## 9. Growth dynamics analyses\n",
    "\n",
    "One of the nice things of having complete or nearly-complete MAGs is that we can take a look at both their GC skews and coverages.\n",
    "\n",
    "GC skews can sometimes be indicative of where the origin and terminus of replication are in a genome (this is discussed extensively in [Chapter 1 of the _Bioinformatics Algorithms_ textbook](https://www.bioinformaticsalgorithms.org/bioinformatics-chapter-1)). Similarly, we know from ([Korem, Zeevi, Suez _et al._, 2015](https://www.science.org/doi/full/10.1126/science.aac4812)) that the coverage throughout a MAG can also be indicative of the origin of replication.\n",
    "\n",
    "In our paper, we demonstrate the easy applicability of HiFi reads to this sort of analysis by showing plots of coverage vs. skew for three MAGs in the SheepGut dataset, demonstrating that—as we might expect—these values are anti-correlated. (Why are they _anti-correlated_, specifically? The skew minimum indicates the origin of replication, and coverage for a genome undergoing replication should be at its maximum near the origin of replication.)\n",
    "\n",
    "The `strainFlye dynam covskew` command can help us ~~replicate~~ reproduce this sort of analysis. Rather than plotting coverage and skew for each position within a MAG, we usually want to create \"bins\" of positions within a MAG and then plot coverage and skew for these bins: strainFlye can give us this sort of information for a contig in an easy-to-read TSV file that we can use as input for plotting coverage and skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57ec389",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye dynam covskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99690c24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "dynam covskew @ 0.00s: Starting...\n",
      "Input contig file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\n",
      "Input BAM file: /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam\n",
      "Bin length: 10,000 bp\n",
      "Normalized coverage epsilon: 0.3\n",
      "Output directory: /Poppy/mfedarko/sftests/tutorial-output/covskew\n",
      "--------\n",
      "dynam covskew @ 0.00s: Loading and checking FASTA and BAM files...\n",
      "dynam covskew @ 4.73s: The FASTA file describes 468 contig(s).\n",
      "dynam covskew @ 4.73s: All of these are included in the BAM file (which has 78,793 reference(s)), with the same lengths.\n",
      "--------\n",
      "dynam covskew @ 4.73s: Going through contigs and computing coverage/skew information...\n",
      "dynam covskew @ 4.73s: On contig edge_8 (1,710,962 bp) (1 / 468 contigs = 0.21%).\n",
      "dynam covskew @ 4.73s: Creating 171 bins of length 10,000 bp and 1 smaller bin of length 962 bp for contig edge_8...\n",
      "dynam covskew @ 25.45s: On contig edge_10 (1,556,982 bp) (2 / 468 contigs = 0.43%).\n",
      "dynam covskew @ 25.45s: Creating 155 bins of length 10,000 bp and 1 smaller bin of length 6,982 bp for contig edge_10...\n",
      "dynam covskew @ 38.23s: On contig edge_15 (3,930,935 bp) (3 / 468 contigs = 0.64%).\n",
      "dynam covskew @ 38.23s: Creating 393 bins of length 10,000 bp and 1 smaller bin of length 935 bp for contig edge_15...\n",
      "dynam covskew @ 114.65s: On contig edge_17 (1,273,557 bp) (4 / 468 contigs = 0.85%).\n",
      "dynam covskew @ 114.65s: Creating 127 bins of length 10,000 bp and 1 smaller bin of length 3,557 bp for contig edge_17...\n",
      "dynam covskew @ 125.58s: On contig edge_28 (1,624,431 bp) (5 / 468 contigs = 1.07%).\n",
      "dynam covskew @ 125.58s: Creating 162 bins of length 10,000 bp and 1 smaller bin of length 4,431 bp for contig edge_28...\n",
      "dynam covskew @ 139.98s: On contig edge_32 (1,292,787 bp) (6 / 468 contigs = 1.28%).\n",
      "dynam covskew @ 139.98s: Creating 129 bins of length 10,000 bp and 1 smaller bin of length 2,787 bp for contig edge_32...\n",
      "dynam covskew @ 150.67s: On contig edge_37 (1,458,661 bp) (7 / 468 contigs = 1.50%).\n",
      "dynam covskew @ 150.67s: Creating 145 bins of length 10,000 bp and 1 smaller bin of length 8,661 bp for contig edge_37...\n",
      "dynam covskew @ 164.52s: On contig edge_60 (1,726,090 bp) (8 / 468 contigs = 1.71%).\n",
      "dynam covskew @ 164.52s: Creating 172 bins of length 10,000 bp and 1 smaller bin of length 6,090 bp for contig edge_60...\n",
      "dynam covskew @ 195.90s: On contig edge_75 (1,684,271 bp) (9 / 468 contigs = 1.92%).\n",
      "dynam covskew @ 195.90s: Creating 168 bins of length 10,000 bp and 1 smaller bin of length 4,271 bp for contig edge_75...\n",
      "dynam covskew @ 212.55s: On contig edge_81 (3,441,581 bp) (10 / 468 contigs = 2.14%).\n",
      "dynam covskew @ 212.55s: Creating 344 bins of length 10,000 bp and 1 smaller bin of length 1,581 bp for contig edge_81...\n",
      "dynam covskew @ 257.37s: On contig edge_91 (1,872,789 bp) (11 / 468 contigs = 2.35%).\n",
      "dynam covskew @ 257.37s: Creating 187 bins of length 10,000 bp and 1 smaller bin of length 2,789 bp for contig edge_91...\n",
      "dynam covskew @ 272.16s: On contig edge_106 (2,349,908 bp) (12 / 468 contigs = 2.56%).\n",
      "dynam covskew @ 272.16s: Creating 234 bins of length 10,000 bp and 1 smaller bin of length 9,908 bp for contig edge_106...\n",
      "dynam covskew @ 294.76s: On contig edge_657 (3,014,550 bp) (13 / 468 contigs = 2.78%).\n",
      "dynam covskew @ 294.76s: Creating 301 bins of length 10,000 bp and 1 smaller bin of length 4,550 bp for contig edge_657...\n",
      "dynam covskew @ 326.96s: On contig edge_694 (1,125,410 bp) (14 / 468 contigs = 2.99%).\n",
      "dynam covskew @ 326.96s: Creating 112 bins of length 10,000 bp and 1 smaller bin of length 5,410 bp for contig edge_694...\n",
      "dynam covskew @ 351.26s: On contig edge_747 (1,117,401 bp) (15 / 468 contigs = 3.21%).\n",
      "dynam covskew @ 351.26s: Creating 111 bins of length 10,000 bp and 1 smaller bin of length 7,401 bp for contig edge_747...\n",
      "dynam covskew @ 360.62s: On contig edge_772 (1,729,248 bp) (16 / 468 contigs = 3.42%).\n",
      "dynam covskew @ 360.62s: Creating 172 bins of length 10,000 bp and 1 smaller bin of length 9,248 bp for contig edge_772...\n",
      "dynam covskew @ 376.22s: On contig edge_839 (2,214,398 bp) (17 / 468 contigs = 3.63%).\n",
      "dynam covskew @ 376.22s: Creating 221 bins of length 10,000 bp and 1 smaller bin of length 4,398 bp for contig edge_839...\n",
      "dynam covskew @ 394.32s: On contig edge_860 (1,113,135 bp) (18 / 468 contigs = 3.85%).\n",
      "dynam covskew @ 394.32s: Creating 111 bins of length 10,000 bp and 1 smaller bin of length 3,135 bp for contig edge_860...\n",
      "dynam covskew @ 406.14s: On contig edge_882 (2,000,256 bp) (19 / 468 contigs = 4.06%).\n",
      "dynam covskew @ 406.14s: Creating 200 bins of length 10,000 bp and 1 smaller bin of length 256 bp for contig edge_882...\n",
      "dynam covskew @ 473.89s: On contig edge_921 (1,675,967 bp) (20 / 468 contigs = 4.27%).\n",
      "dynam covskew @ 473.89s: Creating 167 bins of length 10,000 bp and 1 smaller bin of length 5,967 bp for contig edge_921...\n",
      "dynam covskew @ 488.42s: On contig edge_960 (2,087,411 bp) (21 / 468 contigs = 4.49%).\n",
      "dynam covskew @ 488.42s: Creating 208 bins of length 10,000 bp and 1 smaller bin of length 7,411 bp for contig edge_960...\n",
      "dynam covskew @ 505.85s: On contig edge_972 (1,664,327 bp) (22 / 468 contigs = 4.70%).\n",
      "dynam covskew @ 505.85s: Creating 166 bins of length 10,000 bp and 1 smaller bin of length 4,327 bp for contig edge_972...\n",
      "dynam covskew @ 549.18s: On contig edge_1001 (1,489,937 bp) (23 / 468 contigs = 4.91%).\n",
      "dynam covskew @ 549.18s: Creating 148 bins of length 10,000 bp and 1 smaller bin of length 9,937 bp for contig edge_1001...\n",
      "dynam covskew @ 561.50s: On contig edge_1016 (2,125,735 bp) (24 / 468 contigs = 5.13%).\n",
      "dynam covskew @ 561.50s: Creating 212 bins of length 10,000 bp and 1 smaller bin of length 5,735 bp for contig edge_1016...\n",
      "dynam covskew @ 593.38s: On contig edge_1076 (2,313,017 bp) (25 / 468 contigs = 5.34%).\n",
      "dynam covskew @ 593.38s: Creating 231 bins of length 10,000 bp and 1 smaller bin of length 3,017 bp for contig edge_1076...\n",
      "dynam covskew @ 647.19s: On contig edge_1143 (1,818,152 bp) (26 / 468 contigs = 5.56%).\n",
      "dynam covskew @ 647.19s: Creating 181 bins of length 10,000 bp and 1 smaller bin of length 8,152 bp for contig edge_1143...\n",
      "dynam covskew @ 663.28s: On contig edge_1146 (3,309,271 bp) (27 / 468 contigs = 5.77%).\n",
      "dynam covskew @ 663.28s: Creating 330 bins of length 10,000 bp and 1 smaller bin of length 9,271 bp for contig edge_1146...\n",
      "dynam covskew @ 689.99s: On contig edge_1152 (1,761,831 bp) (28 / 468 contigs = 5.98%).\n",
      "dynam covskew @ 690.00s: Creating 176 bins of length 10,000 bp and 1 smaller bin of length 1,831 bp for contig edge_1152...\n",
      "dynam covskew @ 718.33s: On contig edge_1241 (3,332,097 bp) (29 / 468 contigs = 6.20%).\n",
      "dynam covskew @ 718.33s: Creating 333 bins of length 10,000 bp and 1 smaller bin of length 2,097 bp for contig edge_1241...\n",
      "dynam covskew @ 787.70s: On contig edge_1253 (1,143,368 bp) (30 / 468 contigs = 6.41%).\n",
      "dynam covskew @ 787.70s: Creating 114 bins of length 10,000 bp and 1 smaller bin of length 3,368 bp for contig edge_1253...\n",
      "dynam covskew @ 800.48s: On contig edge_1255 (1,945,007 bp) (31 / 468 contigs = 6.62%).\n",
      "dynam covskew @ 800.48s: Creating 194 bins of length 10,000 bp and 1 smaller bin of length 5,007 bp for contig edge_1255...\n",
      "dynam covskew @ 818.21s: On contig edge_1282 (2,191,745 bp) (32 / 468 contigs = 6.84%).\n",
      "dynam covskew @ 818.21s: Creating 219 bins of length 10,000 bp and 1 smaller bin of length 1,745 bp for contig edge_1282...\n",
      "dynam covskew @ 836.37s: On contig edge_1288 (3,430,435 bp) (33 / 468 contigs = 7.05%).\n",
      "dynam covskew @ 836.37s: Creating 343 bins of length 10,000 bp and 1 smaller bin of length 435 bp for contig edge_1288...\n",
      "dynam covskew @ 949.43s: On contig edge_1296 (1,725,481 bp) (34 / 468 contigs = 7.26%).\n",
      "dynam covskew @ 949.43s: Creating 172 bins of length 10,000 bp and 1 smaller bin of length 5,481 bp for contig edge_1296...\n",
      "dynam covskew @ 970.32s: On contig edge_1300 (1,440,404 bp) (35 / 468 contigs = 7.48%).\n",
      "dynam covskew @ 970.32s: Creating 144 bins of length 10,000 bp and 1 smaller bin of length 404 bp for contig edge_1300...\n",
      "dynam covskew @ 993.98s: On contig edge_1312 (3,299,580 bp) (36 / 468 contigs = 7.69%).\n",
      "dynam covskew @ 993.98s: Creating 329 bins of length 10,000 bp and 1 smaller bin of length 9,580 bp for contig edge_1312...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynam covskew @ 1,020.13s: On contig edge_1343 (1,150,856 bp) (37 / 468 contigs = 7.91%).\n",
      "dynam covskew @ 1,020.13s: Creating 115 bins of length 10,000 bp and 1 smaller bin of length 856 bp for contig edge_1343...\n",
      "dynam covskew @ 1,029.61s: On contig edge_1345 (1,148,683 bp) (38 / 468 contigs = 8.12%).\n",
      "dynam covskew @ 1,029.61s: Creating 114 bins of length 10,000 bp and 1 smaller bin of length 8,683 bp for contig edge_1345...\n",
      "dynam covskew @ 1,039.21s: On contig edge_1349 (1,008,193 bp) (39 / 468 contigs = 8.33%).\n",
      "dynam covskew @ 1,039.21s: Creating 100 bins of length 10,000 bp and 1 smaller bin of length 8,193 bp for contig edge_1349...\n",
      "dynam covskew @ 1,048.51s: On contig edge_1350 (2,038,177 bp) (40 / 468 contigs = 8.55%).\n",
      "dynam covskew @ 1,048.51s: Creating 203 bins of length 10,000 bp and 1 smaller bin of length 8,177 bp for contig edge_1350...\n",
      "dynam covskew @ 1,089.87s: On contig edge_1371 (1,634,973 bp) (41 / 468 contigs = 8.76%).\n",
      "dynam covskew @ 1,089.87s: Creating 163 bins of length 10,000 bp and 1 smaller bin of length 4,973 bp for contig edge_1371...\n",
      "dynam covskew @ 1,371.28s: On contig edge_1387 (2,893,861 bp) (42 / 468 contigs = 8.97%).\n",
      "dynam covskew @ 1,371.28s: Creating 289 bins of length 10,000 bp and 1 smaller bin of length 3,861 bp for contig edge_1387...\n",
      "dynam covskew @ 1,505.09s: On contig edge_1399 (2,921,795 bp) (43 / 468 contigs = 9.19%).\n",
      "dynam covskew @ 1,505.09s: Creating 292 bins of length 10,000 bp and 1 smaller bin of length 1,795 bp for contig edge_1399...\n",
      "dynam covskew @ 1,556.79s: On contig edge_1410 (3,211,899 bp) (44 / 468 contigs = 9.40%).\n",
      "dynam covskew @ 1,556.79s: Creating 321 bins of length 10,000 bp and 1 smaller bin of length 1,899 bp for contig edge_1410...\n",
      "dynam covskew @ 1,595.15s: On contig edge_1415 (1,112,951 bp) (45 / 468 contigs = 9.62%).\n",
      "dynam covskew @ 1,595.15s: Creating 111 bins of length 10,000 bp and 1 smaller bin of length 2,951 bp for contig edge_1415...\n",
      "dynam covskew @ 1,604.58s: On contig edge_1421 (2,324,663 bp) (46 / 468 contigs = 9.83%).\n",
      "dynam covskew @ 1,604.58s: Creating 232 bins of length 10,000 bp and 1 smaller bin of length 4,663 bp for contig edge_1421...\n",
      "dynam covskew @ 1,633.48s: On contig edge_1458 (2,293,715 bp) (47 / 468 contigs = 10.04%).\n",
      "dynam covskew @ 1,633.48s: Creating 229 bins of length 10,000 bp and 1 smaller bin of length 3,715 bp for contig edge_1458...\n",
      "dynam covskew @ 1,655.95s: On contig edge_1463 (1,141,536 bp) (48 / 468 contigs = 10.26%).\n",
      "dynam covskew @ 1,655.95s: Creating 114 bins of length 10,000 bp and 1 smaller bin of length 1,536 bp for contig edge_1463...\n",
      "dynam covskew @ 1,666.29s: On contig edge_1465 (2,960,507 bp) (49 / 468 contigs = 10.47%).\n",
      "dynam covskew @ 1,666.29s: Creating 296 bins of length 10,000 bp and 1 smaller bin of length 507 bp for contig edge_1465...\n",
      "dynam covskew @ 1,694.43s: On contig edge_1488 (1,897,256 bp) (50 / 468 contigs = 10.68%).\n",
      "dynam covskew @ 1,694.43s: Creating 189 bins of length 10,000 bp and 1 smaller bin of length 7,256 bp for contig edge_1488...\n",
      "dynam covskew @ 1,732.27s: On contig edge_1497 (1,586,259 bp) (51 / 468 contigs = 10.90%).\n",
      "dynam covskew @ 1,732.27s: Creating 158 bins of length 10,000 bp and 1 smaller bin of length 6,259 bp for contig edge_1497...\n",
      "dynam covskew @ 1,746.45s: On contig edge_1511 (2,641,139 bp) (52 / 468 contigs = 11.11%).\n",
      "dynam covskew @ 1,746.45s: Creating 264 bins of length 10,000 bp and 1 smaller bin of length 1,139 bp for contig edge_1511...\n",
      "dynam covskew @ 1,770.12s: On contig edge_1522 (1,872,920 bp) (53 / 468 contigs = 11.32%).\n",
      "dynam covskew @ 1,770.12s: Creating 187 bins of length 10,000 bp and 1 smaller bin of length 2,920 bp for contig edge_1522...\n",
      "dynam covskew @ 1,786.05s: On contig edge_1526 (2,338,731 bp) (54 / 468 contigs = 11.54%).\n",
      "dynam covskew @ 1,786.05s: Creating 233 bins of length 10,000 bp and 1 smaller bin of length 8,731 bp for contig edge_1526...\n",
      "dynam covskew @ 1,856.57s: On contig edge_1527 (1,581,694 bp) (55 / 468 contigs = 11.75%).\n",
      "dynam covskew @ 1,856.57s: Creating 158 bins of length 10,000 bp and 1 smaller bin of length 1,694 bp for contig edge_1527...\n",
      "dynam covskew @ 1,870.51s: On contig edge_1530 (2,378,270 bp) (56 / 468 contigs = 11.97%).\n",
      "dynam covskew @ 1,870.51s: Creating 237 bins of length 10,000 bp and 1 smaller bin of length 8,270 bp for contig edge_1530...\n",
      "dynam covskew @ 1,892.78s: On contig edge_1535 (2,013,601 bp) (57 / 468 contigs = 12.18%).\n",
      "dynam covskew @ 1,892.78s: Creating 201 bins of length 10,000 bp and 1 smaller bin of length 3,601 bp for contig edge_1535...\n",
      "dynam covskew @ 1,910.38s: On contig edge_1569 (1,390,944 bp) (58 / 468 contigs = 12.39%).\n",
      "dynam covskew @ 1,910.38s: Creating 139 bins of length 10,000 bp and 1 smaller bin of length 944 bp for contig edge_1569...\n",
      "dynam covskew @ 1,921.80s: On contig edge_1583 (1,545,525 bp) (59 / 468 contigs = 12.61%).\n",
      "dynam covskew @ 1,921.80s: Creating 154 bins of length 10,000 bp and 1 smaller bin of length 5,525 bp for contig edge_1583...\n",
      "dynam covskew @ 1,943.06s: On contig edge_1585 (1,026,123 bp) (60 / 468 contigs = 12.82%).\n",
      "dynam covskew @ 1,943.06s: Creating 102 bins of length 10,000 bp and 1 smaller bin of length 6,123 bp for contig edge_1585...\n",
      "dynam covskew @ 1,951.71s: On contig edge_1588 (2,415,238 bp) (61 / 468 contigs = 13.03%).\n",
      "dynam covskew @ 1,951.71s: Creating 241 bins of length 10,000 bp and 1 smaller bin of length 5,238 bp for contig edge_1588...\n",
      "dynam covskew @ 1,996.17s: On contig edge_1595 (1,224,116 bp) (62 / 468 contigs = 13.25%).\n",
      "dynam covskew @ 1,996.17s: Creating 122 bins of length 10,000 bp and 1 smaller bin of length 4,116 bp for contig edge_1595...\n",
      "dynam covskew @ 2,006.75s: On contig edge_1620 (1,737,772 bp) (63 / 468 contigs = 13.46%).\n",
      "dynam covskew @ 2,006.75s: Creating 173 bins of length 10,000 bp and 1 smaller bin of length 7,772 bp for contig edge_1620...\n",
      "dynam covskew @ 2,023.00s: On contig edge_1623 (4,011,798 bp) (64 / 468 contigs = 13.68%).\n",
      "dynam covskew @ 2,023.00s: Creating 401 bins of length 10,000 bp and 1 smaller bin of length 1,798 bp for contig edge_1623...\n",
      "dynam covskew @ 2,059.92s: On contig edge_1628 (1,498,844 bp) (65 / 468 contigs = 13.89%).\n",
      "dynam covskew @ 2,059.92s: Creating 149 bins of length 10,000 bp and 1 smaller bin of length 8,844 bp for contig edge_1628...\n",
      "dynam covskew @ 2,074.38s: On contig edge_1631 (2,887,470 bp) (66 / 468 contigs = 14.10%).\n",
      "dynam covskew @ 2,074.38s: Creating 288 bins of length 10,000 bp and 1 smaller bin of length 7,470 bp for contig edge_1631...\n",
      "dynam covskew @ 2,123.03s: On contig edge_1636 (1,166,269 bp) (67 / 468 contigs = 14.32%).\n",
      "dynam covskew @ 2,123.03s: Creating 116 bins of length 10,000 bp and 1 smaller bin of length 6,269 bp for contig edge_1636...\n",
      "dynam covskew @ 2,135.34s: On contig edge_1650 (1,766,870 bp) (68 / 468 contigs = 14.53%).\n",
      "dynam covskew @ 2,135.34s: Creating 176 bins of length 10,000 bp and 1 smaller bin of length 6,870 bp for contig edge_1650...\n",
      "dynam covskew @ 2,149.53s: On contig edge_1657 (1,374,426 bp) (69 / 468 contigs = 14.74%).\n",
      "dynam covskew @ 2,149.53s: Creating 137 bins of length 10,000 bp and 1 smaller bin of length 4,426 bp for contig edge_1657...\n",
      "dynam covskew @ 2,162.00s: On contig edge_1667 (1,054,121 bp) (70 / 468 contigs = 14.96%).\n",
      "dynam covskew @ 2,162.00s: Creating 105 bins of length 10,000 bp and 1 smaller bin of length 4,121 bp for contig edge_1667...\n",
      "dynam covskew @ 2,174.63s: On contig edge_1671 (2,153,394 bp) (71 / 468 contigs = 15.17%).\n",
      "dynam covskew @ 2,174.63s: Creating 215 bins of length 10,000 bp and 1 smaller bin of length 3,394 bp for contig edge_1671...\n",
      "dynam covskew @ 2,384.47s: On contig edge_1696 (1,652,202 bp) (72 / 468 contigs = 15.38%).\n",
      "dynam covskew @ 2,384.47s: Creating 165 bins of length 10,000 bp and 1 smaller bin of length 2,202 bp for contig edge_1696...\n",
      "dynam covskew @ 2,398.79s: On contig edge_1717 (2,679,593 bp) (73 / 468 contigs = 15.60%).\n",
      "dynam covskew @ 2,398.79s: Creating 267 bins of length 10,000 bp and 1 smaller bin of length 9,593 bp for contig edge_1717...\n",
      "dynam covskew @ 2,493.34s: On contig edge_1719 (1,504,657 bp) (74 / 468 contigs = 15.81%).\n",
      "dynam covskew @ 2,493.34s: Creating 150 bins of length 10,000 bp and 1 smaller bin of length 4,657 bp for contig edge_1719...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynam covskew @ 2,537.11s: On contig edge_1736 (1,047,335 bp) (75 / 468 contigs = 16.03%).\n",
      "dynam covskew @ 2,537.11s: Creating 104 bins of length 10,000 bp and 1 smaller bin of length 7,335 bp for contig edge_1736...\n",
      "dynam covskew @ 2,545.87s: On contig edge_1738 (2,962,047 bp) (76 / 468 contigs = 16.24%).\n",
      "dynam covskew @ 2,545.87s: Creating 296 bins of length 10,000 bp and 1 smaller bin of length 2,047 bp for contig edge_1738...\n",
      "dynam covskew @ 2,586.47s: On contig edge_1749 (2,138,318 bp) (77 / 468 contigs = 16.45%).\n",
      "dynam covskew @ 2,586.47s: Creating 213 bins of length 10,000 bp and 1 smaller bin of length 8,318 bp for contig edge_1749...\n",
      "dynam covskew @ 2,605.98s: On contig edge_1770 (1,048,294 bp) (78 / 468 contigs = 16.67%).\n",
      "dynam covskew @ 2,605.98s: Creating 104 bins of length 10,000 bp and 1 smaller bin of length 8,294 bp for contig edge_1770...\n",
      "dynam covskew @ 2,615.29s: On contig edge_1778 (1,708,996 bp) (79 / 468 contigs = 16.88%).\n",
      "dynam covskew @ 2,615.29s: Creating 170 bins of length 10,000 bp and 1 smaller bin of length 8,996 bp for contig edge_1778...\n",
      "dynam covskew @ 2,629.70s: On contig edge_1799 (2,095,591 bp) (80 / 468 contigs = 17.09%).\n",
      "dynam covskew @ 2,629.70s: Creating 209 bins of length 10,000 bp and 1 smaller bin of length 5,591 bp for contig edge_1799...\n",
      "dynam covskew @ 2,647.79s: On contig edge_1806 (1,645,963 bp) (81 / 468 contigs = 17.31%).\n",
      "dynam covskew @ 2,647.79s: Creating 164 bins of length 10,000 bp and 1 smaller bin of length 5,963 bp for contig edge_1806...\n",
      "dynam covskew @ 2,661.48s: On contig edge_1819 (2,612,985 bp) (82 / 468 contigs = 17.52%).\n",
      "dynam covskew @ 2,661.48s: Creating 261 bins of length 10,000 bp and 1 smaller bin of length 2,985 bp for contig edge_1819...\n",
      "dynam covskew @ 2,705.29s: On contig edge_1840 (1,016,577 bp) (83 / 468 contigs = 17.74%).\n",
      "dynam covskew @ 2,705.29s: Creating 101 bins of length 10,000 bp and 1 smaller bin of length 6,577 bp for contig edge_1840...\n",
      "dynam covskew @ 2,715.06s: On contig edge_1845 (4,278,601 bp) (84 / 468 contigs = 17.95%).\n",
      "dynam covskew @ 2,715.06s: Creating 427 bins of length 10,000 bp and 1 smaller bin of length 8,601 bp for contig edge_1845...\n",
      "dynam covskew @ 2,752.10s: On contig edge_1888 (2,124,688 bp) (85 / 468 contigs = 18.16%).\n",
      "dynam covskew @ 2,752.10s: Creating 212 bins of length 10,000 bp and 1 smaller bin of length 4,688 bp for contig edge_1888...\n",
      "dynam covskew @ 2,778.02s: On contig edge_1902 (1,319,888 bp) (86 / 468 contigs = 18.38%).\n",
      "dynam covskew @ 2,778.02s: Creating 131 bins of length 10,000 bp and 1 smaller bin of length 9,888 bp for contig edge_1902...\n",
      "dynam covskew @ 2,789.50s: On contig edge_1910 (1,391,383 bp) (87 / 468 contigs = 18.59%).\n",
      "dynam covskew @ 2,789.50s: Creating 139 bins of length 10,000 bp and 1 smaller bin of length 1,383 bp for contig edge_1910...\n",
      "dynam covskew @ 2,801.25s: On contig edge_1920 (1,053,664 bp) (88 / 468 contigs = 18.80%).\n",
      "dynam covskew @ 2,801.25s: Creating 105 bins of length 10,000 bp and 1 smaller bin of length 3,664 bp for contig edge_1920...\n",
      "dynam covskew @ 2,811.70s: On contig edge_1956 (1,382,648 bp) (89 / 468 contigs = 19.02%).\n",
      "dynam covskew @ 2,811.70s: Creating 138 bins of length 10,000 bp and 1 smaller bin of length 2,648 bp for contig edge_1956...\n",
      "dynam covskew @ 2,823.77s: On contig edge_1965 (1,966,583 bp) (90 / 468 contigs = 19.23%).\n",
      "dynam covskew @ 2,823.77s: Creating 196 bins of length 10,000 bp and 1 smaller bin of length 6,583 bp for contig edge_1965...\n",
      "dynam covskew @ 2,843.48s: On contig edge_1970 (2,883,435 bp) (91 / 468 contigs = 19.44%).\n",
      "dynam covskew @ 2,843.48s: Creating 288 bins of length 10,000 bp and 1 smaller bin of length 3,435 bp for contig edge_1970...\n",
      "dynam covskew @ 2,869.82s: On contig edge_1977 (2,365,945 bp) (92 / 468 contigs = 19.66%).\n",
      "dynam covskew @ 2,869.82s: Creating 236 bins of length 10,000 bp and 1 smaller bin of length 5,945 bp for contig edge_1977...\n",
      "dynam covskew @ 2,891.35s: On contig edge_2008 (2,665,015 bp) (93 / 468 contigs = 19.87%).\n",
      "dynam covskew @ 2,891.35s: Creating 266 bins of length 10,000 bp and 1 smaller bin of length 5,015 bp for contig edge_2008...\n",
      "dynam covskew @ 2,957.66s: On contig edge_2021 (3,332,645 bp) (94 / 468 contigs = 20.09%).\n",
      "dynam covskew @ 2,957.66s: Creating 333 bins of length 10,000 bp and 1 smaller bin of length 2,645 bp for contig edge_2021...\n",
      "dynam covskew @ 2,985.63s: On contig edge_2031 (2,655,168 bp) (95 / 468 contigs = 20.30%).\n",
      "dynam covskew @ 2,985.63s: Creating 265 bins of length 10,000 bp and 1 smaller bin of length 5,168 bp for contig edge_2031...\n",
      "dynam covskew @ 3,008.35s: On contig edge_2043 (1,223,608 bp) (96 / 468 contigs = 20.51%).\n",
      "dynam covskew @ 3,008.35s: Creating 122 bins of length 10,000 bp and 1 smaller bin of length 3,608 bp for contig edge_2043...\n",
      "dynam covskew @ 3,021.23s: On contig edge_2045 (1,460,535 bp) (97 / 468 contigs = 20.73%).\n",
      "dynam covskew @ 3,021.23s: Creating 146 bins of length 10,000 bp and 1 smaller bin of length 535 bp for contig edge_2045...\n",
      "dynam covskew @ 3,040.12s: On contig edge_2050 (1,635,687 bp) (98 / 468 contigs = 20.94%).\n",
      "dynam covskew @ 3,040.12s: Creating 163 bins of length 10,000 bp and 1 smaller bin of length 5,687 bp for contig edge_2050...\n",
      "dynam covskew @ 3,062.29s: On contig edge_2052 (2,975,706 bp) (99 / 468 contigs = 21.15%).\n",
      "dynam covskew @ 3,062.29s: Creating 297 bins of length 10,000 bp and 1 smaller bin of length 5,706 bp for contig edge_2052...\n",
      "dynam covskew @ 3,092.62s: On contig edge_2054 (1,748,819 bp) (100 / 468 contigs = 21.37%).\n",
      "dynam covskew @ 3,092.62s: Creating 174 bins of length 10,000 bp and 1 smaller bin of length 8,819 bp for contig edge_2054...\n",
      "dynam covskew @ 3,107.38s: On contig edge_2055 (1,031,045 bp) (101 / 468 contigs = 21.58%).\n",
      "dynam covskew @ 3,107.38s: Creating 103 bins of length 10,000 bp and 1 smaller bin of length 1,045 bp for contig edge_2055...\n",
      "dynam covskew @ 3,116.30s: On contig edge_2061 (2,372,549 bp) (102 / 468 contigs = 21.79%).\n",
      "dynam covskew @ 3,116.30s: Creating 237 bins of length 10,000 bp and 1 smaller bin of length 2,549 bp for contig edge_2061...\n",
      "dynam covskew @ 3,149.40s: On contig edge_2065 (1,299,300 bp) (103 / 468 contigs = 22.01%).\n",
      "dynam covskew @ 3,149.40s: Creating 129 bins of length 10,000 bp and 1 smaller bin of length 9,300 bp for contig edge_2065...\n",
      "dynam covskew @ 3,161.92s: On contig edge_2075 (1,853,046 bp) (104 / 468 contigs = 22.22%).\n",
      "dynam covskew @ 3,161.92s: Creating 185 bins of length 10,000 bp and 1 smaller bin of length 3,046 bp for contig edge_2075...\n",
      "dynam covskew @ 3,224.26s: On contig edge_2125 (2,279,210 bp) (105 / 468 contigs = 22.44%).\n",
      "dynam covskew @ 3,224.26s: Creating 227 bins of length 10,000 bp and 1 smaller bin of length 9,210 bp for contig edge_2125...\n",
      "dynam covskew @ 3,257.93s: On contig edge_2140 (1,348,456 bp) (106 / 468 contigs = 22.65%).\n",
      "dynam covskew @ 3,257.93s: Creating 134 bins of length 10,000 bp and 1 smaller bin of length 8,456 bp for contig edge_2140...\n",
      "dynam covskew @ 3,271.40s: On contig edge_2142 (3,105,662 bp) (107 / 468 contigs = 22.86%).\n",
      "dynam covskew @ 3,271.40s: Creating 310 bins of length 10,000 bp and 1 smaller bin of length 5,662 bp for contig edge_2142...\n",
      "dynam covskew @ 3,302.20s: On contig edge_2146 (1,059,380 bp) (108 / 468 contigs = 23.08%).\n",
      "dynam covskew @ 3,302.20s: Creating 105 bins of length 10,000 bp and 1 smaller bin of length 9,380 bp for contig edge_2146...\n",
      "dynam covskew @ 3,311.70s: On contig edge_2151 (2,265,899 bp) (109 / 468 contigs = 23.29%).\n",
      "dynam covskew @ 3,311.70s: Creating 226 bins of length 10,000 bp and 1 smaller bin of length 5,899 bp for contig edge_2151...\n",
      "dynam covskew @ 3,334.30s: On contig edge_2156 (2,403,328 bp) (110 / 468 contigs = 23.50%).\n",
      "dynam covskew @ 3,334.30s: Creating 240 bins of length 10,000 bp and 1 smaller bin of length 3,328 bp for contig edge_2156...\n",
      "dynam covskew @ 3,357.96s: On contig edge_2173 (1,846,534 bp) (111 / 468 contigs = 23.72%).\n",
      "dynam covskew @ 3,357.96s: Creating 184 bins of length 10,000 bp and 1 smaller bin of length 6,534 bp for contig edge_2173...\n",
      "dynam covskew @ 3,374.21s: On contig edge_2174 (2,403,010 bp) (112 / 468 contigs = 23.93%).\n",
      "dynam covskew @ 3,374.21s: Creating 240 bins of length 10,000 bp and 1 smaller bin of length 3,010 bp for contig edge_2174...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dynam covskew @ 3,411.11s: On contig edge_2195 (1,213,600 bp) (113 / 468 contigs = 24.15%).\n",
      "dynam covskew @ 3,411.11s: Creating 121 bins of length 10,000 bp and 1 smaller bin of length 3,600 bp for contig edge_2195...\n",
      "dynam covskew @ 3,422.92s: On contig edge_2209 (1,741,203 bp) (114 / 468 contigs = 24.36%).\n",
      "dynam covskew @ 3,422.92s: Creating 174 bins of length 10,000 bp and 1 smaller bin of length 1,203 bp for contig edge_2209...\n",
      "dynam covskew @ 3,440.86s: On contig edge_2214 (1,382,691 bp) (115 / 468 contigs = 24.57%).\n",
      "dynam covskew @ 3,440.86s: Creating 138 bins of length 10,000 bp and 1 smaller bin of length 2,691 bp for contig edge_2214...\n",
      "dynam covskew @ 3,453.07s: On contig edge_2218 (3,016,620 bp) (116 / 468 contigs = 24.79%).\n",
      "dynam covskew @ 3,453.07s: Creating 301 bins of length 10,000 bp and 1 smaller bin of length 6,620 bp for contig edge_2218...\n",
      "dynam covskew @ 3,488.47s: On contig edge_2289 (2,279,686 bp) (117 / 468 contigs = 25.00%).\n",
      "dynam covskew @ 3,488.47s: Creating 227 bins of length 10,000 bp and 1 smaller bin of length 9,686 bp for contig edge_2289...\n",
      "dynam covskew @ 3,509.30s: On contig edge_2298 (1,018,142 bp) (118 / 468 contigs = 25.21%).\n",
      "dynam covskew @ 3,509.30s: Creating 101 bins of length 10,000 bp and 1 smaller bin of length 8,142 bp for contig edge_2298...\n",
      "dynam covskew @ 3,535.53s: On contig edge_2309 (1,440,607 bp) (119 / 468 contigs = 25.43%).\n",
      "dynam covskew @ 3,535.53s: Creating 144 bins of length 10,000 bp and 1 smaller bin of length 607 bp for contig edge_2309...\n",
      "dynam covskew @ 3,548.49s: On contig edge_2310 (2,286,549 bp) (120 / 468 contigs = 25.64%).\n",
      "dynam covskew @ 3,548.49s: Creating 228 bins of length 10,000 bp and 1 smaller bin of length 6,549 bp for contig edge_2310...\n",
      "dynam covskew @ 3,567.89s: On contig edge_2319 (1,767,894 bp) (121 / 468 contigs = 25.85%).\n",
      "dynam covskew @ 3,567.89s: Creating 176 bins of length 10,000 bp and 1 smaller bin of length 7,894 bp for contig edge_2319...\n",
      "dynam covskew @ 3,582.81s: On contig edge_2331 (1,015,611 bp) (122 / 468 contigs = 26.07%).\n",
      "dynam covskew @ 3,582.81s: Creating 101 bins of length 10,000 bp and 1 smaller bin of length 5,611 bp for contig edge_2331...\n",
      "dynam covskew @ 3,593.57s: On contig edge_2337 (1,457,784 bp) (123 / 468 contigs = 26.28%).\n",
      "dynam covskew @ 3,593.57s: Creating 145 bins of length 10,000 bp and 1 smaller bin of length 7,784 bp for contig edge_2337...\n",
      "dynam covskew @ 3,606.00s: On contig edge_2358 (2,806,161 bp) (124 / 468 contigs = 26.50%).\n",
      "dynam covskew @ 3,606.00s: Creating 280 bins of length 10,000 bp and 1 smaller bin of length 6,161 bp for contig edge_2358...\n",
      "dynam covskew @ 4,497.43s: On contig edge_2362 (2,071,753 bp) (125 / 468 contigs = 26.71%).\n",
      "dynam covskew @ 4,497.43s: Creating 207 bins of length 10,000 bp and 1 smaller bin of length 1,753 bp for contig edge_2362...\n",
      "dynam covskew @ 4,515.15s: On contig edge_2380 (1,114,870 bp) (126 / 468 contigs = 26.92%).\n",
      "dynam covskew @ 4,515.15s: Creating 111 bins of length 10,000 bp and 1 smaller bin of length 4,870 bp for contig edge_2380...\n",
      "dynam covskew @ 4,526.63s: On contig edge_2388 (2,758,097 bp) (127 / 468 contigs = 27.14%).\n",
      "dynam covskew @ 4,526.63s: Creating 275 bins of length 10,000 bp and 1 smaller bin of length 8,097 bp for contig edge_2388...\n"
     ]
    }
   ],
   "source": [
    "!strainFlye dynam covskew \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/covskew \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c441ae",
   "metadata": {},
   "source": [
    "## 10. Create codon/amino acid mutation matrices\n",
    "\n",
    "_(This part of the pipeline is not finished yet, sorry. See [the README](https://github.com/fedarko/strainFlye) for information on the ad hoc code from the other repository you can use to create/visualize these matrices.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9015d59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
