{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "349b04fa",
   "metadata": {},
   "source": [
    "# Tutorial: applying strainFlye to the SheepGut dataset\n",
    "\n",
    "This tutorial will walk you through some of the analyses that strainFlye can perform.\n",
    "\n",
    "Here we will be using the same SheepGut dataset that is used in our paper, but feel free to follow along with another dataset.\n",
    "\n",
    "The pipeline takes as input two primary types of data:\n",
    "\n",
    "1. A __set of reads__ (in FASTA / FASTQ format).\n",
    "\n",
    "2. A __set of contigs__ (in FASTA format) assembled from these reads.\n",
    "\n",
    "## Details about the inputs\n",
    "\n",
    "**Regarding reads:** We designed strainFlye in the context of PacBio Circular Consensus Sequencing (CCS) \"HiFi\" reads ([Wenger & Peluso _et al._, 2019](https://www.nature.com/articles/s41587-019-0217-9)). However, in theory it should still work with other reasonably long and accurate reads.\n",
    "\n",
    "**Regarding contigs:** We don't impose any restriction on the assembler you use to construct these. We designed strainFlye in the context of [metaFlye](https://github.com/fenderglass/Flye) ([Kolmogorov _et al._, 2020](https://www.nature.com/articles/s41587-019-0217-9)) output, but it should work with the outputs of other HiFi assemblers.\n",
    "\n",
    "## The SheepGut dataset\n",
    "\n",
    "Please see the paper's \"Data access\" section for details about acquiring both of these types of data for the SheepGut dataset.\n",
    "\n",
    "Note that the \"contigs\" we use for the SheepGut datatset really correspond to edge sequences in the `assembly_graph.gfa` file produced by metaFlye -- in general, these may be slightly different from the file of contigs / scaffolds in the `assembly.fasta` file produced by metaFlye: see [Flye's manual](https://github.com/fenderglass/Flye/blob/flye/docs/USAGE.md#output) for more information. (You could use either type of sequence with strainFlye, although I personally recommend using edges -- it's useful to have context about where exactly in the assembly graph a sequence is, and things like gaps in scaffolds will cause strainFlye to complain.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0e5fc0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Let's take care of a few things before the tutorial starts.\n",
    "\n",
    "### Installing strainFlye\n",
    "\n",
    "Before following along with this tutorial, we assume that you have already installed strainFlye (and have activated the corresponding conda environment). Please see [strainFlye's README](https://github.com/fedarko/strainFlye) for installation instructions.\n",
    "\n",
    "### What commands are available through strainFlye?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12d6ff7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  Pipeline for the analysis of rare mutations in metagenomes.\r\n",
      "\r\n",
      "  Please consult https://github.com/fedarko/strainFlye if you have any\r\n",
      "  questions, comments, etc. about strainFlye. Thank you for using this tool!\r\n",
      "\r\n",
      "Options:\r\n",
      "  -v, --version  Show the version and exit.\r\n",
      "  -h, --help     Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  align   Align reads to contigs, and filter the resulting alignment.\r\n",
      "  call    [+] Call mutations in contigs naïvely & compute diversity indices.\r\n",
      "  fdr     [+] Estimate and fix FDRs for contigs' naïve mutation calls.\r\n",
      "  spot    [+] Identify putative mutational hotspots or coldspots in contigs.\r\n",
      "  smooth  [+] Create and assemble smoothed and virtual reads.\r\n",
      "  utils   [+] Various utility commands provided with strainFlye.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558f6d4",
   "metadata": {},
   "source": [
    "### Importing and configuring some utilities\n",
    "\n",
    "You shouldn't need to actually do any programming to use strainFlye's commands; that said, we'll be using Python to help with a few small tasks throughout this tutorial. We'll import some useful packages here to reduce clutter in this notebook.\n",
    "\n",
    "(If you prefer, you could of course use another language instead of Python.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a094e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import skbio\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee835ce7",
   "metadata": {},
   "source": [
    "## 0. Convert the assembly graph GFA file to a FASTA file of contigs\n",
    "\n",
    "**You can skip this step if:** you already have a FASTA file describing contigs in your assembly graph.\n",
    "\n",
    "Our assembly graph (the GFA file) contains the sequences of the contigs that we will use in many downstream analyses, but we'll need to have a FASTA file that just describes these contigs' sequences (independent of the assembly graph topology).\n",
    "\n",
    "There are some [bash one-liners](https://www.biostars.org/p/169516/#169530) you can use to convert a GFA 1 file to a FASTA file, but strainFlye also provides a utility command (`strainFlye utils gfa-to-fasta`) to do this for you. We'll use this here. (Our solution may be a bit slower than a bash one-liner, but it performs some useful sanity checking on the GFA file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26d90dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye utils gfa-to-fasta @ 0.00 sec: Starting...\n",
      "Input GFA file: /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa\n",
      "Output FASTA file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta\n",
      "--------\n",
      "strainFlye utils gfa-to-fasta @ 14.97 sec: Done.\n",
      "Output FASTA file contains 78,793 sequences.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye utils gfa-to-fasta \\\n",
    "    --graph /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa \\\n",
    "    --output-fasta /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ba35",
   "metadata": {},
   "source": [
    "## 1. Align reads to contigs; filter the resulting alignment\n",
    "\n",
    "**You can skip this step if:** you already have a BAM file representing an alignment of reads to contigs, and this BAM file does not contain secondary alignments / partially-mapped reads / overlapping supplementary alignments (these all may cause problems in downstream analyses).\n",
    "\n",
    "We'll need to align reads back to these contigs. The resulting alignment, and/or the mutations that we call from it, will be used in pretty much all downstream steps—so it's important to make sure that it is of good quality!\n",
    "\n",
    "The `strainFlye align` command uses minimap2 to perform alignment, and then does some extra filtering on the resulting alignment.\n",
    "\n",
    "Note that this command, in particular, may take a while to run. Sequence alignment is computationally expensive! On our cluster, `strainFlye align` ran on the full SheepGut dataset in 62,941.21 seconds (aka about 17.5 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281fd11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye align [OPTIONS] READS...\r\n",
      "\r\n",
      "  Align reads to contigs, and filter the resulting alignment.\r\n",
      "\r\n",
      "  Files of reads should be in the FASTA or FASTQ formats; GZIP'd files are\r\n",
      "  allowed.\r\n",
      "\r\n",
      "  This command involves multiple steps, including:\r\n",
      "\r\n",
      "    1) Align reads to contigs (using minimap2) to generate a SAM file\r\n",
      "    2) Convert this SAM file to a sorted and indexed BAM file\r\n",
      "    3) Filter overlapping supplementary alignments (OSAs) from this BAM file\r\n",
      "    4) Filter partially-mapped reads from this BAM file\r\n",
      "\r\n",
      "  Note that we only sort the alignment file once, although we do re-index it\r\n",
      "  after the two filtering steps. This decision is motivated by\r\n",
      "  https://www.biostars.org/p/131333/#131335.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs to which reads will be\r\n",
      "                                  aligned.  [required]\r\n",
      "  -g, --graph PATH                GFA 1-formatted file describing an assembly\r\n",
      "                                  graph of the contigs. This is used in the\r\n",
      "                                  \"filter partially-mapped reads\" step to make\r\n",
      "                                  the filter less strict for reads mapped to\r\n",
      "                                  adjacent contigs in the graph. This isn't\r\n",
      "                                  required; if it isn't passed, adjacent\r\n",
      "                                  contigs will not be considered in this\r\n",
      "                                  filter.  [default: (no graph)]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which an output BAM file\r\n",
      "                                  (final.bam) and BAM index file will be\r\n",
      "                                  written. Some temporary files will also be\r\n",
      "                                  written to this directory.  [required]\r\n",
      "  --rm-tmp-bam / --no-rm-tmp-bam  Remove temporary (before filtering, and\r\n",
      "                                  after just filtering OSAs) BAM files, to\r\n",
      "                                  reduce space requirements.  [default: rm-\r\n",
      "                                  tmp-bam]\r\n",
      "  --verbose / --no-verbose        Display extra details for each contig during\r\n",
      "                                  alignment filtering.  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c619f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!strainFlye align \\\n",
    "    # We can use the FASTA file we just generated above.\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta \\\n",
    "    --graph /Poppy/mfedarko/misc-data/sheepgut_flye_big_2.8_graph.gfa \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/alignment \\\n",
    "    # Reads file(s) are specified here, after all of the other parameters:\n",
    "    /Poppy/mkolmogo/sheep_meta/data/sheep_poop_CCS_dedup.fastq.gz \\\n",
    "    /Poppy/mkolmogo/sheep_meta/data/ccs_sequel_II/*.fasta.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c58de0",
   "metadata": {},
   "source": [
    "This generates a BAM file (`final.bam`) and BAM index file (`final.bam.bai`) in the specified output directory.\n",
    "\n",
    "We can use this BAM file for many analyses downstream—the first of these will be mutation calling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf1e5d",
   "metadata": {},
   "source": [
    "## 1.5. Optional: filter the FASTA file in order to focus on \"long\" contigs\n",
    "\n",
    "We just aligned our dataset's reads against *all* contigs in the assembly graph. This is standard practice (see, e.g., [this tutorial](https://astrobiomike.github.io/genomics/metagen_anvio#mapping-our-reads-to-the-assembly-they-built)); aligning reads against all contigs probably yields a more accurate alignment than just aligning reads against a subset of these contigs (although proving if this is \"best practice\" or not is a challenging question, and one that I will sidestep right now).\n",
    "\n",
    "However, now that we have this alignment, we don't necessarily need to perform mutation calling, phasing, etc. on all contigs (although, if you want to, we could!). To speed up the rest of this tutorial, we will focus solely on the \"long\" contigs in this dataset: here, we will define a contig as \"long\" if its length is **at least 1 Mbp**. In theory, these long contigs represent putative metagenome-assembled genomes (MAGs).\n",
    "\n",
    "Of course, if you prefer, you could apply more sophisticated criteria to pick which contigs to focus on—maybe you'd like to also focus on contigs with high coverages, or maybe on contigs with good [CheckM](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4484387/) completeness or contamination values. Or maybe you'd like to keep considering all contigs in the full dataset! Your decision should depend on your goals, and your dataset.\n",
    "\n",
    "In any case, how do we \"focus on\" certain contigs? **We can filter our FASTA file to a subset of contigs present in the full dataset**, and use this filtered FASTA file for all downstream analyses. As an example of this, we will use Python (in particular, with the [scikit-bio](http://scikit-bio.org/) library) to filter our FASTA file to all long contigs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac9fae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 contigs with lengths ≥ 1,000,000 bp. Took 12.30 sec.\n"
     ]
    }
   ],
   "source": [
    "# Produce a filtered FASTA file containing only contigs >= 1 Mbp long\n",
    "# (This uses scikit-bio; see http://scikit-bio.org/ for more details.)\n",
    "\n",
    "input_contigs_fp = \"/Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs.fasta\"\n",
    "output_contigs_fp = \"/Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\"\n",
    "len_threshold = 1000000\n",
    "\n",
    "t0 = time.time()\n",
    "num_long_contigs = 0\n",
    "with open(output_contigs_fp, \"w\") as of:\n",
    "    for contig in skbio.io.read(input_contigs_fp, format=\"fasta\", constructor=skbio.DNA):\n",
    "        if len(contig) >= len_threshold:\n",
    "            skbio.io.write(contig, format=\"fasta\", into=of)\n",
    "            num_long_contigs += 1\n",
    "t1 = time.time()\n",
    "\n",
    "print(f\"Found {num_long_contigs:,} contigs with lengths \\u2265 {len_threshold:,} bp. Took {t1 - t0:,.2f} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388366fb",
   "metadata": {},
   "source": [
    "The remainder of this tutorial will focus on these 468 long contigs.\n",
    "\n",
    "In any case, now we can get on to some more interesting stuff!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6400ea",
   "metadata": {},
   "source": [
    "## 2. Perform naïve mutation calling, then estimate and fix mutation calls' FDRs\n",
    "\n",
    "**You can skip this step if:** You already have a BCF file describing single-nucleotide, non-multi-allelic mutations in your contigs.\n",
    "\n",
    "The analyses downstream of this step (hotspot/coldspot identification, phasing) take as input a set of identified single-nucleotide mutations (or, if you prefer to use different terminology, \"called variants\", \"called SNVs\", ...) in which we have some confidence. How does strainFlye identify these mutations?\n",
    "\n",
    "There are a few steps (as our paper describes). First, we will **naïvely call mutations** using a simple threshold-based method (referred to as \"NaiveFreq\" in the paper). We'll then **estimate the false-discovery rates of the mutations called for each contig** using the target-decoy approach, and then adjust the called mutations to **fix the estimated false-discovery rates of these mutation calls** below a specified threshold.\n",
    "\n",
    "### 2.1. $p$-mutations and $r$-mutations?\n",
    "\n",
    "So, our first step will be performing this simple threshold-based calling. What do we mean by \"threshold\" here?\n",
    "\n",
    "strainFlye supports calling two basic types of mutations: $p$-mutations and $r$-mutations. The docs explain the difference between these two types best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5755853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye call [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Call mutations in contigs naïvely & compute diversity indices.\r\n",
      "\r\n",
      "  Consider a position \"pos\" in a contig. Using the alignment, we can count how\r\n",
      "  many reads have a (mis)match operation to \"pos\" with one of the four\r\n",
      "  nucleotides (A, C, G, T; we ignore degenerate nucleotides in reads). We\r\n",
      "  represent these four nucleotides' counts at pos as follows:\r\n",
      "\r\n",
      "      N1 = # reads of the most-common aligned nucleotide at pos,\r\n",
      "      N2 = # reads of the second-most-common aligned nucleotide at pos,\r\n",
      "      N3 = # reads of the third-most-common aligned nucleotide at pos,\r\n",
      "      N4 = # reads of the fourth-most-common aligned nucleotide at pos.\r\n",
      "\r\n",
      "  (We break ties arbitrarily.)\r\n",
      "\r\n",
      "  strainFlye supports two types of naïve mutation calling based on these\r\n",
      "  counts: p-mutations and r-mutations. These are described below.\r\n",
      "\r\n",
      "  p-mutations (naïve percentage-based mutation calling)\r\n",
      "  -----------------------------------------------------\r\n",
      "\r\n",
      "  This takes as input some percentage p in the range (0%, 50%]. Define\r\n",
      "  freq(pos) = N2 / (N1 + N2 + N3 + N4). This value, which is inherently\r\n",
      "  constrained to the range [0%, 50%], is an estimate of the mutation frequency\r\n",
      "  of this position. We classify pos as a p-mutation if freq(pos) ≥ p, AND if\r\n",
      "  N2 ≥ the --min-alt-pos parameter (an integer representing a minimum number\r\n",
      "  of reads that must support the alternate nucleotide).\r\n",
      "\r\n",
      "  r-mutations (naïve read-count-based mutation calling)\r\n",
      "  -----------------------------------------------------\r\n",
      "\r\n",
      "  This takes as input some integer r > 0. We classify pos as an r-mutation if\r\n",
      "  N2 ≥ r.\r\n",
      "\r\n",
      "  Diversity indices\r\n",
      "  -----------------\r\n",
      "\r\n",
      "  Later on in the pipeline, we'll need to select a decoy contig in order to\r\n",
      "  perform FDR estimation for our called mutations. Contigs with low diversity\r\n",
      "  indices may indicate promising decoy contigs; so, for the sake of\r\n",
      "  convenience, both commands output this information.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  p-mutation  Call p-mutations and compute diversity indices.\r\n",
      "  r-mutation  Call r-mutations and compute diversity indices.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ac637",
   "metadata": {},
   "source": [
    "### 2.2. Understanding these (sub)commands\n",
    "\n",
    "First off, note that `strainFlye call` doesn't do anything besides show help info if you run it by itself. This is because, unlike `strainFlye align`, `strainFlye call` has two subcommands: `p-mutation` and `r-mutation`. Which of these you use will depend on how you want to naïvely call mutations. You can invoke one of these subcommands by writing out the full chain of commands: for example, `strainFlye call p-mutation`.\n",
    "\n",
    "#### 2.2.1. Input and output\n",
    "\n",
    "Probably the most important parameter at this step is the *minimum threshold*. Both of these subcommands, `strainFlye call p-mutation` and `strainFlye call r-mutation`, take as input a minimum version of their corresponding threshold (either `--min-p` or `--min-r`).\n",
    "\n",
    "These commands each output:\n",
    "\n",
    "1. A __BCF (binary [variant call format](https://samtools.github.io/hts-specs/VCFv4.3.pdf)) file__ describing all mutations called naïvely across the contigs, based on the minimum $p$ or $r$ threshold set (`--min-p` or `--min-r`).\n",
    "\n",
    "2. A __TSV ([tab separated values](https://en.wikipedia.org/wiki/Tab-separated_values)) file__ describing the contigs' computed diversity indices, for various values of $p$ or $r$ (configurable using the `--div-index-p-list` or `--div-index-r-list` parameters). Long story short, diversity indices indicate how many of a contig's \"sufficiently-covered\" positions have called mutations: in general, higher diversity indices imply higher mutation rates.\n",
    "\n",
    "#### 2.2.2. Interpreting the output\n",
    "\n",
    "The default minimum value of $p$ (or $r$) used in these commands is fairly low. As you might expect, using such a low threshold for calling a position as a mutation will yield many false positives: we will almost certainly identify many real mutations, but also many \"false\" mutations that occur as the result of sequencing errors, alignment errors, etc. Viewed another way, the __false discovery rate (FDR)__ (defined as the ratio of false positives to total true + false positives) of the mutation calls generated at this step will probably be unacceptably high.\n",
    "\n",
    "So, after we run this command, we'll use strainFlye's FDR estimation and fixing functionality to attempt to address this problem. This will involve adjusting the \"minimum\" value of $p$ or $r$ used for each contig to reduce the FDR as needed. Depending on your dataset and your goals, you may or may not want to do this: as of writing, many of the analyses in our paper don't use FDR fixing on their input mutations (although this is mostly an artifact of us implementing the FDR fixing code near the end of the project).\n",
    "\n",
    "### 2.3. Naïvely call $p$-mutations ($p = 0.15\\%$) and compute diversity indices for various values of $p$\n",
    "\n",
    "Now that we know what we're doing, we're ready to call mutations and compute diversity indices! We'll do $p$-mutation calling at a minimum $p$ of $0.15\\%$, which matches what we used for Figure 2 in the paper. The default diversity index values of $p$ (ranging from $0.5\\%$ to $50\\%$) should be good for us.\n",
    "\n",
    "Note that this command will take a while—we need to check each position in the alignment for each of the input contigs. We will use the `--verbose` flag to display some extra information about the status of each contig while this command is running, to make the wait more tolerable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c394d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye call p-mutation [OPTIONS]\r\n",
      "\r\n",
      "  Call p-mutations and compute diversity indices.\r\n",
      "\r\n",
      "  The primary parameter for this command is the lower bound of p, defined by\r\n",
      "  --min-p. The BCF output will include \"mutations\" for all positions that pass\r\n",
      "  this (likely very low) threshold; this BCF can be filtered using the\r\n",
      "  utilities contained in the \"strainFlye fdr\" module.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs in which to naïvely\r\n",
      "                                  call mutations. All contigs in this FASTA\r\n",
      "                                  file should also be contained in the BAM\r\n",
      "                                  file; however, if some contigs in the BAM\r\n",
      "                                  file are not included in this FASTA file, we\r\n",
      "                                  won't perform any calling on these absent\r\n",
      "                                  contigs.  [required]\r\n",
      "  -b, --bam PATH                  Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --min-p INTEGER RANGE           Minimum value of p for which to call\r\n",
      "                                  p-mutations. This is scaled up by 100 (i.e.\r\n",
      "                                  the default of 50 corresponds to 50 / 100 =\r\n",
      "                                  0.5%) in order to bypass floating-point\r\n",
      "                                  precision issues.  [default: 50; 0<x<=5000]\r\n",
      "  --min-alt-pos INTEGER RANGE     In order for us to call a p-mutation at a\r\n",
      "                                  position, this position's alternate\r\n",
      "                                  nucleotide must be supported by at least\r\n",
      "                                  this many reads.  [default: 2; x>=1]\r\n",
      "  --div-index-p-list TEXT         List of values of p for which we'll compute\r\n",
      "                                  diversity indices. These should all be\r\n",
      "                                  separated by commas; and, as with --min-p,\r\n",
      "                                  these are scaled up by 100. Please don't use\r\n",
      "                                  commas as thousands separators.  [default:\r\n",
      "                                  50,100,200,500,1000,2500,5000]\r\n",
      "  -m, --min-read-number INTEGER RANGE\r\n",
      "                                  Parameter that impacts the minimum\r\n",
      "                                  (mis)match coverage needed in order to\r\n",
      "                                  consider \"counting\" a position / mutation\r\n",
      "                                  towards the diversity index. Given a value\r\n",
      "                                  of p (converted to the range [0, 0.5)), a\r\n",
      "                                  position must have a coverage of at least\r\n",
      "                                  (--min-read-number / p) in order to be\r\n",
      "                                  \"sufficiently covered\" and thus counted\r\n",
      "                                  towards the diversity index.  [default: 5;\r\n",
      "                                  x>=1]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which an output BCF file\r\n",
      "                                  (describing the called mutations), BCF index\r\n",
      "                                  file, and diversity index TSV file will be\r\n",
      "                                  written. Some temporary files will also be\r\n",
      "                                  written to this directory.  [required]\r\n",
      "  --verbose / --no-verbose        Display extra details for each contig while\r\n",
      "                                  running.  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye call p-mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fde95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye call p-mutation \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sftests/tutorial-output/alignment/final.bam \\\n",
    "    --min-p 15 \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/call-p15 \\\n",
    "    --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce21462",
   "metadata": {},
   "source": [
    "### 2.4. Analyzing diversity indices: the search for a decoy contig\n",
    "\n",
    "We now have both our initial mutation calls (which, as we've discussed, probably have a high FDR) and information about our contigs' diversity indices. We will use the __target-decoy approach__ to attempt to estimate and thus control the FDR of our mutation calls. This is done by the `strainFlye fdr estimate` and `strainFlye fdr fix` commands.\n",
    "\n",
    "As discussed in our paper, we can select—out of one of our $C$ contigs—a __decoy contig__ (a.k.a. a decoy genome), and compute a mutation rate for it ($\\text{rate}_{\\text{decoy}}$). For each of the other $C - 1$ __target contigs__, we can estimate the FDR of identified mutations in this contig as $\\dfrac{\\text{rate}_{\\text{decoy}}}{\\text{rate}_{\\text{target}}}$.\n",
    "\n",
    "If you'd like, we could go through the diversity indices produced by `strainFlye call p-mutation` ourselves, in an attempt to select a reasonable-seeming decoy contig. **[This notebook](https://nbviewer.org/github/fedarko/strainFlye/blob/main/docs/AnalyzingDiversityIndices.ipynb)** demonstrates this sort of process. However, `strainFlye fdr estimate` can also do this sort of thing automatically; so, in order to not make this tutorial longer than it already is, we'll move on to FDR estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176733d5",
   "metadata": {},
   "source": [
    "### 2.5. Estimating FDRs using the target-decoy approach\n",
    "\n",
    "The optional notebook discussed above shows that `edge_6104` is probably a good decoy contig, so we could if desired just pass it to `strainFlye fdr estimate` using that command's `-dc` or `--decoy-contig` option. However, to illustrate another option, we'll instead pass our diversity index TSV file to `strainFlye fdr estimate` and let it do the job of selecting a decoy contig. (Spoiler alert: it'll select `edge_6104` anyway.)\n",
    "\n",
    "#### 2.5.1. Sidenote: strainFlye's algorithm for automatically selecting a decoy contig\n",
    "\n",
    "If `strainFlye fdr estimate` is provided a diversity index file, it will automatically select a decoy contig using the following _ad hoc_ algorithm:\n",
    "\n",
    "1\\. Filter to all contigs whose lengths and average coverages meet the `--decoy-min-length` and `--decoy-min-average-coverage` thresholds, respectively. Define $C$ as the set of all contigs that meet these thresholds (so, $|C|$ indicates the number of contigs in $C$).\n",
    "\n",
    "  - If $|C| = 0$, raise an error (the length and coverage thresholds should probably be lowered for this dataset).\n",
    "  - If $|C| = 1$, select the lone contig in $C$ as the decoy.\n",
    "  - If $|C| = 2$, move on to the next steps.\n",
    "\n",
    "\n",
    "2\\. Define $D$ as the set of all diversity index columns in the input file (representing computed diversity indices at different values of $p$ or $r$), where at least two of the $C$ passing contigs have a diversity index defined for this column.\n",
    "\n",
    "  - If $|D| = 0$, raise an error.\n",
    "  - Otherwise, move on to the next steps.\n",
    "\n",
    "\n",
    "3\\. For each column in $D$:\n",
    "\n",
    "  - Compute the minimum ($\\text{min}$) and maximum ($\\text{max}$) diversity index in this column, only considering contigs in $C$.\n",
    "  - In the strange case where $\\text{min} = \\text{max}$, ignore this column and move on to the next. (If all columns in $D$ have this problem, raise an error.)\n",
    "  - Otherwise, assign each contig in $C$ a score for this column.\n",
    "    - For each contig with a defined diversity index in this column, assign a score using [linear interpolation](https://en.wikipedia.org/wiki/Linear_interpolation). Higher scores indicate that a contig seems \"more\" diverse. If the diversity index of this contig in this column is defined as $x$, then this contig's score for this column, $\\text{score}(x)$, is defined as $\\text{score}(x) = \\dfrac{x - \\text{min}}{\\text{max} - \\text{min}}$.\n",
    "    - For each contig with an undefined diversity index in this column, penalize this contig by assigning it a score of 1.\n",
    "    \n",
    "    \n",
    "4\\. Sum scores across all columns in $D$ for each contig in $C$. **Select the contig with the lowest score sum as the decoy contig**, breaking ties arbitrarily.\n",
    "\n",
    "\n",
    "For more details about how this works, please see the source code for the [`autoselect_decoy()` function](https://github.com/fedarko/strainFlye/blob/main/strainflye/fdr_utils.py#L100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5253166f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Estimate and fix FDRs for contigs' naïve mutation calls.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  estimate  Estimate the FDRs of contigs' naïve mutation calls.\r\n",
      "  fix       Fix contigs' naïve mutation calls' FDRs to an upper limit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "001dbf01",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr estimate [OPTIONS]\r\n",
      "\r\n",
      "  Estimate the FDRs of contigs' naïve mutation calls.\r\n",
      "\r\n",
      "  We do this using the target-decoy approach (TDA). Given a set of C contigs,\r\n",
      "  we select a \"decoy contig\" with relatively few called mutations. We then\r\n",
      "  compute a mutation rate for this decoy contig, and use this mutation rate\r\n",
      "  (along with the mutation rates of the other C - 1 \"target\" contigs) to\r\n",
      "  estimate the FDRs of all of these target contigs' mutation calls.\r\n",
      "\r\n",
      "  We can produce multiple FDR estimates for a single target contig's calls by\r\n",
      "  varying the p or r threshold used (from the --min-p or --min-r threshold\r\n",
      "  used to generate the input BCF file, up to the --high-p or --high-r\r\n",
      "  threshold given here). Using this information (and information about the\r\n",
      "  numbers of mutations called per megabase), we can plot an FDR curve for a\r\n",
      "  given target contig's mutation calls.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs.  [required]\r\n",
      "  --bam PATH                      Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --bcf PATH                      Indexed BCF file describing naïvely called\r\n",
      "                                  p- or r-mutations in the FASTA file's\r\n",
      "                                  contigs.  [required]\r\n",
      "  -di, --diversity-indices PATH   TSV file describing the diversity indices of\r\n",
      "                                  a set of contigs. Used to automatically\r\n",
      "                                  select a decoy contig. This option is\r\n",
      "                                  mutually exclusive with --decoy-contig.\r\n",
      "                                  [default: (nothing)]\r\n",
      "  -dc, --decoy-contig TEXT        Name of a specific contig to use as the\r\n",
      "                                  decoy contig for FDR estimation. This option\r\n",
      "                                  is mutually exclusive with --diversity-\r\n",
      "                                  indices.  [default: (nothing)]\r\n",
      "  -dctx, --decoy-contexts [Full|CP2|Tv|Nonsyn|Nonsense|CP2Tv|CP2Nonsyn|CP2Nonsense|TvNonsyn|TvNonsense|CP2TvNonsense|Everything]\r\n",
      "                                  \"Context-dependent\" types of positions\r\n",
      "                                  and/or mutations to which the computation of\r\n",
      "                                  mutation rates in the decoy contig will be\r\n",
      "                                  limited. The \"Full\" option will consider the\r\n",
      "                                  entire decoy contig; all other options will\r\n",
      "                                  limit the computation to certain types of\r\n",
      "                                  positions and/or potential mutations. (CP2\r\n",
      "                                  will focus on positions in the second codon\r\n",
      "                                  position of genes predicted in the decoy\r\n",
      "                                  contig using Prodigal; Nonsyn will focus on\r\n",
      "                                  potential nonsynonymous mutations in these\r\n",
      "                                  genes; Nonsense will focus on potential\r\n",
      "                                  nonsense mutations in these genes; and Tv\r\n",
      "                                  will focus on potential transversion\r\n",
      "                                  mutations.) You can specify this option\r\n",
      "                                  multiple times to generate multiple sets of\r\n",
      "                                  FDR estimates. (You can also specify\r\n",
      "                                  \"Everything\" to use all available contexts.)\r\n",
      "                                  [default: CP2; required]\r\n",
      "  -hp, --high-p INTEGER RANGE     (Only applies if the input BCF file\r\n",
      "                                  describes p-mutations.) p-mutations with a\r\n",
      "                                  mutation rate (freq(pos)) greater than or\r\n",
      "                                  equal to this are considered \"indisputable,\"\r\n",
      "                                  and will not be included in FDR estimation.\r\n",
      "                                  Like the values of p used as parameters to\r\n",
      "                                  \"strainFlye call p-mutation\", this is in the\r\n",
      "                                  range (0, 5000], such that h = N corresponds\r\n",
      "                                  to (N / 100)%. Corresponds to the\r\n",
      "                                  \"highFrequency\" threshold mentioned in the\r\n",
      "                                  paper.  [default: 500; 0<x<=5000]\r\n",
      "  -hr, --high-r INTEGER RANGE     (Only applies if the input BCF file\r\n",
      "                                  describes r-mutations.) r-mutations with an\r\n",
      "                                  alternate nucleotide read coverage greater\r\n",
      "                                  than or equal to this are considered\r\n",
      "                                  indisputable, and will not be included in\r\n",
      "                                  FDR estimation.  [default: 100; x>0]\r\n",
      "  -dml, --decoy-min-length INTEGER RANGE\r\n",
      "                                  Minimum length of a potential decoy contig.\r\n",
      "                                  Only used if --diversity-indices is\r\n",
      "                                  specified.  [default: 1000000; x>0]\r\n",
      "  -dmac, --decoy-min-average-coverage FLOAT RANGE\r\n",
      "                                  Minimum average (mis)match coverage of a\r\n",
      "                                  potential decoy contig. Only used if\r\n",
      "                                  --diversity-indices is specified.  [default:\r\n",
      "                                  500; x>0]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which TSV files describing the\r\n",
      "                                  estimated FDRs and numbers of naïvely called\r\n",
      "                                  mutations per megabase will be written. In\r\n",
      "                                  all TSV files, rows correspond to target\r\n",
      "                                  contigs and columns correspond to p or r\r\n",
      "                                  values. We will generate one estimated FDR\r\n",
      "                                  TSV file for every time --decoy-context is\r\n",
      "                                  specified, and just one number-of-naïvely-\r\n",
      "                                  called-mutations-per-megabase file.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a481c482",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye fdr estimate @ 0.00 sec: Starting...\n",
      "Input contig file: /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta\n",
      "Input BAM file: /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf\n",
      "Input diversity indices file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv\n",
      "Input manually-set decoy contig: None\n",
      "Input decoy contig context-dependent position / mutation type(s): ('Full', 'CP2', 'Tv', 'Nonsyn', 'Nonsense', 'CP2Tv', 'CP2Nonsyn', 'CP2Nonsense', 'TvNonsyn', 'TvNonsense', 'CP2TvNonsense')\n",
      "Input high p threshold (only used if the BCF describes p-mutations): 500\n",
      "Input high r threshold (only used if the BCF describes r-mutations): 100\n",
      "Input min length of a potential decoy contig (only used if diversity indices are specified): 1000000\n",
      "Input min average coverage of a potential decoy contig (only used if diversity indices are specified): 500.0\n",
      "Output directory: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info\n",
      "--------\n",
      "strainFlye fdr estimate @ 0.00 sec: Loading and checking FASTA, BAM, and BCF files...\n",
      "strainFlye fdr estimate @ 4.80 sec: The FASTA file describes 468 contig(s).\n",
      "strainFlye fdr estimate @ 4.88 sec: All FASTA contig(s) are included in the BAM file (this BAM file has 78,793 reference(s)).\n",
      "strainFlye fdr estimate @ 19.59 sec: The FASTA file's contig(s) and BCF file's contig(s) match.\n",
      "strainFlye fdr estimate @ 19.59 sec: Also, the input BCF file describes p-mutations (minimum p = 15).\n",
      "strainFlye fdr estimate @ 19.60 sec: The lengths of all contig(s) in the FASTA file match the corresponding lengths in the BAM and BCF files.\n",
      "strainFlye fdr estimate @ 19.60 sec: So far, these files seem good.\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.60 sec: Selecting a decoy contig based on the diversity indices...\n",
      "strainFlye fdr estimate @ 19.61 sec: Selected edge_6104 as the decoy contig.\n",
      "strainFlye fdr estimate @ 19.61 sec: Verified that this decoy contig is present in the FASTA, BAM, and BCF files.\n",
      "strainFlye fdr estimate @ 19.61 sec: (Sorry for doubting you.)\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.61 sec: Determining range of value(s) of p to consider...\n",
      "strainFlye fdr estimate @ 19.61 sec: We'll consider 485 value(s) of p: from 15 to 499.\n",
      "strainFlye fdr estimate @ 19.61 sec: p-mutations for p ≥ 500 will be considered \"indisputable.\"\n",
      "strainFlye fdr estimate @ 19.61 sec: These \"indisputable\" mutations won't be included in the FDR estimation results.\n",
      "--------\n",
      "strainFlye fdr estimate @ 19.61 sec: Computing mutation rates for edge_6104 at these threshold values, for each of the 11 decoy context(s)...\n",
      "strainFlye fdr estimate @ 21.45 sec: At least one of the decoy context(s) requires us to have gene predictions for edge_6104; running Prodigal...\n",
      "-------------------------------------\n",
      "PRODIGAL v2.6.3 [February, 2016]         \n",
      "Univ of Tenn / Oak Ridge National Lab\n",
      "Doug Hyatt, Loren Hauser, et al.     \n",
      "-------------------------------------\n",
      "Request:  Single Genome, Phase:  Training\n",
      "Reading in the sequence(s) to train...1289244 bp seq created, 32.65 pct GC\n",
      "Locating all potential starts and stops...30910 nodes\n",
      "Looking for GC bias in different frames...frame bias scores: 2.68 0.19 0.12\n",
      "Building initial set of genes to train from...done!\n",
      "Creating coding model and scoring nodes...done!\n",
      "Examining upstream regions and training starts...done!\n",
      "-------------------------------------\n",
      "Request:  Single Genome, Phase:  Gene Finding\n",
      "Finding genes in sequence #1 (1289244 bp)...done!\n",
      "strainFlye fdr estimate @ 26.66 sec: Finished running Prodigal! It predicted 1,297 gene(s) in edge_6104.\n",
      "strainFlye fdr estimate @ 27.41 sec: At least one of the decoy context(s) requires us to know \"unreasonable\" positions (where reference and consensus disagree) in edge_6104; going through alignment...\n",
      "strainFlye fdr estimate @ 27.66 sec: Done: identified 0 unreasonable position(s) in edge_6104.\n",
      "strainFlye fdr estimate @ 27.66 sec: Computing mutation rates for decoy context \"CP2\" (1 / 11)...\n",
      "strainFlye fdr estimate @ 27.67 sec: Done computing \"CP2\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 27.67 sec: Computing mutation rates for decoy context \"CP2Nonsense\" (2 / 11)...\n",
      "strainFlye fdr estimate @ 34.47 sec: Done computing \"CP2Nonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 34.47 sec: Computing mutation rates for decoy context \"CP2Nonsyn\" (3 / 11)...\n",
      "strainFlye fdr estimate @ 41.87 sec: Done computing \"CP2Nonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 41.87 sec: Computing mutation rates for decoy context \"CP2Tv\" (4 / 11)...\n",
      "strainFlye fdr estimate @ 41.88 sec: Done computing \"CP2Tv\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 41.88 sec: Computing mutation rates for decoy context \"CP2TvNonsense\" (5 / 11)...\n",
      "strainFlye fdr estimate @ 48.67 sec: Done computing \"CP2TvNonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 48.67 sec: Computing mutation rates for decoy context \"Full\" (6 / 11)...\n",
      "strainFlye fdr estimate @ 48.69 sec: Done computing \"Full\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 48.69 sec: Computing mutation rates for decoy context \"Nonsense\" (7 / 11)...\n",
      "strainFlye fdr estimate @ 68.39 sec: Done computing \"Nonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 68.39 sec: Computing mutation rates for decoy context \"Nonsyn\" (8 / 11)...\n",
      "strainFlye fdr estimate @ 89.12 sec: Done computing \"Nonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 89.12 sec: Computing mutation rates for decoy context \"Tv\" (9 / 11)...\n",
      "strainFlye fdr estimate @ 89.24 sec: Done computing \"Tv\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 89.24 sec: Computing mutation rates for decoy context \"TvNonsense\" (10 / 11)...\n",
      "strainFlye fdr estimate @ 108.39 sec: Done computing \"TvNonsense\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 108.39 sec: Computing mutation rates for decoy context \"TvNonsyn\" (11 / 11)...\n",
      "strainFlye fdr estimate @ 128.86 sec: Done computing \"TvNonsyn\" mutation rates for edge_6104.\n",
      "strainFlye fdr estimate @ 128.89 sec: Done computing mutation rates for all decoy context(s) for edge_6104.\n",
      "--------\n",
      "strainFlye fdr estimate @ 128.89 sec: Computing mutation rates and FDR estimates for the 467 target contig(s)...\n",
      "strainFlye fdr estimate @ 161.04 sec: Done.\n",
      "--------\n",
      "strainFlye fdr estimate @ 161.09 sec: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr estimate \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf \\\n",
    "    --diversity-indices /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv \\\n",
    "    --decoy-contexts Everything\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02706f7e",
   "metadata": {},
   "source": [
    "Let's check on the TSV files that got written to the output directory. We should see one file for every decoy context, indicating the FDR estimates for each target contig for this context; and one lone \"number of mutations per Mb\" file, indicating the number of mutations per megabase for each target contig.\n",
    "\n",
    "In general, we can plot these as FDR curves by using the FDR estimates as x-axis values and the \"number of mutations per Mb\" values as y-axis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24598a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fdr-CP2Nonsense.tsv    fdr-CP2Tv.tsv\t fdr-TvNonsense.tsv\r\n",
      "fdr-CP2Nonsyn.tsv      fdr-Full.tsv\t fdr-TvNonsyn.tsv\r\n",
      "fdr-CP2.tsv\t       fdr-Nonsense.tsv  fdr-Tv.tsv\r\n",
      "fdr-CP2TvNonsense.tsv  fdr-Nonsyn.tsv\t num-mutations-per-mb.tsv\r\n"
     ]
    }
   ],
   "source": [
    "!ls /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597e9bd",
   "metadata": {},
   "source": [
    "### 2.6. Plotting FDR curves\n",
    "\n",
    "**[This notebook (in the analysis code repository)](https://nbviewer.org/github/fedarko/sheepgut/blob/main/sf-analyses/sheep/3-PlotFDRCurves.ipynb)** demonstrates how we can plot some or all of these FDR estimates for our target contigs. (I put a lot of work into making those plots look fancy, but it doesn't need to be that complicated!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbee72",
   "metadata": {},
   "source": [
    "### 2.7. Fixing mutation calls' FDRs to an upper limit of $1\\%$\n",
    "\n",
    "FDR estimates are nice, but the main thing we want is the ability to _fix_ these FDRs for each target contig's mutation calls to a specified upper limit.\n",
    "\n",
    "Since we already have FDR curves showing how, as $p$ varies, the estimated FDR for each target contig varies, fixing the estimated FDR to an upper limit $F$ amounts to choosing a value of $p$ that yields a FDR ≤ $F$. The `strainFlye fdr fix` command takes care of this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c92390b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye fdr fix [OPTIONS]\r\n",
      "\r\n",
      "  Fix contigs' naïve mutation calls' FDRs to an upper limit.\r\n",
      "\r\n",
      "  This takes as input the estimated FDRs from \"strainFlye fdr estimate\" (if\r\n",
      "  you used multiple decoy contexts, then you will need to choose which set of\r\n",
      "  FDR estimates to use here) to guide us on how to fix the FDR for each\r\n",
      "  contig. Note that mutations that passed the \"high\" p or r threshold\r\n",
      "  specified for \"strainFlye fdr estimate\", and thus were not used for FDR\r\n",
      "  estimation, will all be included in the output BCF file from this command;\r\n",
      "  these mutations are considered \"indisputable.\"\r\n",
      "\r\n",
      "  We include indisputable mutations from the decoy contig and from all target\r\n",
      "  contigs in our output BCF file. We will only consider including non-\r\n",
      "  indisputable mutations from the target contigs: the decision of which non-\r\n",
      "  indisputable mutations will be included is based on the lowest p or r\r\n",
      "  parameter for a target contig that yields an estimated FDR ≤ the fixed FDR\r\n",
      "  given here.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH            Indexed BCF file describing naïvely called p- or\r\n",
      "                            r-mutations.  [required]\r\n",
      "  -fi, --fdr-info FILE      One of the estimated FDR TSV files produced by\r\n",
      "                            \"strainFlye fdr estimate\".  [required]\r\n",
      "  --fdr FLOAT RANGE         False discovery rate at which identified mutations\r\n",
      "                            will be fixed. This is interpreted as a\r\n",
      "                            percentage: the default of 1 corresponds to an FDR\r\n",
      "                            of 1%. We do not restrict this to an upper limit,\r\n",
      "                            since estimated FDRs can technically exceed 100%.\r\n",
      "                            [default: 1; x>0]\r\n",
      "  -o, --output-bcf FILE     Filepath to which an output indexed BCF file\r\n",
      "                            (describing the called mutations at the optimal p\r\n",
      "                            or r value for each contig, along with any\r\n",
      "                            \"indisputable\" mutations relative to the --high-p\r\n",
      "                            or --high-r parameter used for strainFlye fdr\r\n",
      "                            estimate) will be written.  [required]\r\n",
      "  --verbose / --no-verbose  Display extra details for each contig while\r\n",
      "                            writing the filtered BCF.  [default: no-verbose]\r\n",
      "  -h, --help                Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a0e7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------\n",
      "strainFlye fdr fix @ 0.00 sec: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf\n",
      "Input FDR estimate file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info.tsv\n",
      "Input FDR to fix mutation calls at: 1.0\n",
      "Verbose?: No\n",
      "Output BCF file with mutation calls at the fixed FDR: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "--------\n",
      "strainFlye fdr fix @ 0.00 sec: Loading and checking BCF and TSV files...\n",
      "strainFlye fdr fix @ 14.93 sec: Looks good so far; decoy contig seems to be edge_6104.\n",
      "strainFlye fdr fix @ 14.93 sec: Looks like the cutoff for \"indisputable\" mutations was p = 500.\n",
      "strainFlye fdr fix @ 14.93 sec: All mutations passing this cutoff will be included in the output BCF file.\n",
      "--------\n",
      "strainFlye fdr fix @ 14.93 sec: Based on the FDR information, finding optimal values of p for each contig...\n",
      "strainFlye fdr fix @ 14.95 sec: Done.\n",
      "strainFlye fdr fix @ 14.95 sec: For 155 / 467 contigs, there exist values of p (at least, considering the range from p = 15 to p = 499) that yield estimated FDRs ≤ 1.0%.\n",
      "strainFlye fdr fix @ 14.95 sec: These values range from p = 42 (edge_1300) to p = 496 (edge_58801).\n",
      "strainFlye fdr fix @ 14.95 sec: The mean of these values is p = 220.91.\n",
      "--------\n",
      "strainFlye fdr fix @ 14.95 sec: Writing a filtered BCF file (to a temporary location, for now) including both (1) indisputable mutations from all contigs and (2) non-indisputable mutations from the target contigs that result in a FDR ≤ 1.0%...\n",
      "strainFlye fdr fix @ 30.59 sec: Done.\n",
      "--------\n",
      "strainFlye fdr fix @ 30.59 sec: Updating the filtered BCF file's header to indicate that FDR fixing was done...\n",
      "strainFlye fdr fix @ 34.12 sec: Done.\n",
      "--------\n",
      "strainFlye fdr fix @ 34.12 sec: Indexing the BCF file...\n",
      "strainFlye fdr fix @ 35.04 sec: Done indexing the BCF file.\n",
      "--------\n",
      "strainFlye fdr fix @ 35.05 sec: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye fdr fix \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/call-p15/naive-calls.bcf \\\n",
    "    --fdr-info /Poppy/mfedarko/sftests/tutorial-output/p15-fdr-info.tsv \\\n",
    "    --fdr 1 \\\n",
    "    --output-bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278b5d1",
   "metadata": {},
   "source": [
    "It took us a few steps, but we have now generated a file (`p15-fdr1pct.bcf`) of $p$-mutation calls at a fixed (estimated) FDR of 1%.\n",
    "\n",
    "Although our methodology has a few limitations (e.g. we don't support calling multi-allelic mutations yet), this BCF file can be used downstream for many types of analyses. In the next sections of the tutorial we'll demonstrate the additional commands supported by strainFlye, most of which make use of these mutation calls in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68353631",
   "metadata": {},
   "source": [
    "## 3. Identifying hotspots and coldspots\n",
    "\n",
    "We've called mutations and estimated these calls' FDRs. Now we can get to the fun part: what's going on with these mutations?\n",
    "\n",
    "Often, we're interested in analyzing mutations' locations in the contigs. Are there any particular \"hotspot\" regions where there are surprisingly many mutations? Are there any \"coldspot\" regions where there are, surprisingly, no or few mutations?\n",
    "\n",
    "We've kept strainFlye's functionality for identifying these types of regions fairly minimal at the moment. Here we'll demonstrate identifying very basic hotspots and coldspots using `strainFlye spot`'s commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf5923a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Identify putative mutational hotspots or coldspots in contigs.\r\n",
      "\r\n",
      "  Many methods exist for identifying these sorts of hotspots or coldspots; so,\r\n",
      "  strainFlye's implementations of these methods are intended mostly as a quick\r\n",
      "  proof-of-concept for replicating the results shown in our paper, and are not\r\n",
      "  extremely \"feature-rich\" quite yet.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  hot-features  Identify hotspot features (for example, genes).\r\n",
      "  cold-gaps     Identify long coldspot \"gaps\" without any mutations.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8f4b9",
   "metadata": {},
   "source": [
    "### 3.1. Identifying hotspot features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d78739dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot hot-features [OPTIONS]\r\n",
      "\r\n",
      "  Identify hotspot features (for example, genes).\r\n",
      "\r\n",
      "  By \"feature\", we refer to a single continuous region within a contig, as\r\n",
      "  described in the file given for --features. These regions could describe\r\n",
      "  anything: predicted protein-coding genes, introns or exons, intergenic\r\n",
      "  regions of interest, etc. For now, we treat each feature independently (e.g.\r\n",
      "  we don't lump together exons from the same \"Parent\" gene; each feature is\r\n",
      "  considered separately as a potential \"hotspot\").\r\n",
      "\r\n",
      "  You can configure whether or not we classify a feature as a hotspot by\r\n",
      "  adjusting the --min-num-mutations and --min-perc-mutations parameters; at\r\n",
      "  least one of these parameters must be specified. If both parameters are\r\n",
      "  specified, then both checks (number of mutations in a feature, and\r\n",
      "  percentage of mutations in a feature) will need to pass in order for us to\r\n",
      "  label a feature as a hotspot.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH                  Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -f, --features PATH             Generic Feature Format version 3 (GFF3) file\r\n",
      "                                  describing \"features\" (e.g. predicted\r\n",
      "                                  protein-coding genes) in the contigs. We\r\n",
      "                                  will ignore features located on contigs that\r\n",
      "                                  are not described in the BCF file's header.\r\n",
      "                                  [required]\r\n",
      "  -mn, --min-num-mutations INTEGER RANGE\r\n",
      "                                  Label a feature as a \"hotspot\" if it\r\n",
      "                                  contains at least this many mutations.\r\n",
      "                                  [default: (no check); x>0]\r\n",
      "  -mp, --min-perc-mutations FLOAT RANGE\r\n",
      "                                  Label a feature as a \"hotspot\" if its\r\n",
      "                                  percentage of mutations ((# mutations /\r\n",
      "                                  feature length) × 100) is at least this\r\n",
      "                                  value.  [default: (no check); 0<x<=100]\r\n",
      "  -o, --output-hotspots FILE      Filepath to which an output tab-separated\r\n",
      "                                  values (TSV) file describing hotspot\r\n",
      "                                  features across all contigs will be written.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot hot-features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf53d31",
   "metadata": {},
   "source": [
    "#### 3.1.1. A note about \"features\"\n",
    "\n",
    "Although we should be familiar with the FASTA and BCF input files by this point, the `-f` / `--features` input (a GFF3 file) may be surprising. strainFlye leaves the task of creating this file up to the user.\n",
    "\n",
    "Predicted genes' coordinates are probably the most obvious type of \"feature\" for which we could look for hotspots. If you don't have gene predictions for your contigs yet, [Prodigal](https://github.com/hyattpd/Prodigal) is good (and should have been installed along with strainFlye, since other parts of strainFlye make use of it internally). Here, we'll use it to predict protein-coding genes across all contigs.\n",
    "\n",
    "It's important to note that Prodigal does not predict eukaryotic genes (i.e. genes that are split up into introns and exons). These genes will thus not be a perfect representation of all protein-coding genes in all contigs in the dataset, since we know that this sample does contain at least some eukaryotic genomes. (However, if you use another tool for predicting eukaryotic genes that produces GFF3 output, then these should also be usable as \"features\" for this command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a9a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See https://github.com/hyattpd/Prodigal/wiki/cheat-sheet for details about these options.\n",
    "#\n",
    "# Note that, for the paper, I ran Prodigal in \"normal\" mode on certain contigs individually\n",
    "# (https://github.com/fedarko/sheepgut/blob/main/inspect-seqs/prodigal.py), but here we just\n",
    "# run Prodigal in \"anonymous\" mode on all contigs at once. The results should be fairly similar,\n",
    "# although there'll probably be some differences.\n",
    "!prodigal \\\n",
    "    -i /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    -f gff \\\n",
    "    -c \\\n",
    "    -p meta \\\n",
    "    -o /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287432e8",
   "metadata": {},
   "source": [
    "#### 3.1.2. Running the command to identify hotspot features (hotspot predicted genes)\n",
    "\n",
    "Now that we have our gene predictions, let's move see if any of them have a lot of mutations. (Based on our findings in the paper, we know that these sorts of hotspots do exist in this dataset.)\n",
    "\n",
    "`strainFlye spot hot-features` supports two types of basic thresholds for labelling a feature as a hotspot, `--min-num-mutations` and `--min-perc-mutations`. We'll use both here, and label a feature a \"hotspot\" if it meets both of the following criteria:\n",
    "\n",
    "1. it contains at least 5 mutations, and\n",
    "2. at least 2% of its positions have mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "901b5606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "spot hot-features @ 0.00s: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "Input feature file: /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff\n",
      "Input minimum number of mutations needed to call a feature a hotspot: 5\n",
      "Input minimum % of mutations needed to call a feature a hotspot: 2.0\n",
      "Output file describing hotspot features: /Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv\n",
      "--------\n",
      "spot hot-features @ 0.00s: Loading and checking the BCF file...\n",
      "spot hot-features @ 12.20s: Looks good so far.\n",
      "--------\n",
      "spot hot-features @ 12.20s: Going through features in the GFF3 file and identifying hotspot features...\n",
      "spot hot-features @ 100.13s: Identified 57,188 hotspot feature(s) across all 468 contigs in the BCF file.\n",
      "--------\n",
      "spot hot-features @ 100.13s: Writing out this information to a TSV file...\n",
      "spot hot-features @ 100.29s: Done.\n",
      "--------\n",
      "spot hot-features @ 100.30s: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot hot-features \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --features /Poppy/mfedarko/sftests/tutorial-output/prodigal_anonymous.gff \\\n",
    "    --min-num-mutations 5 \\\n",
    "    --min-perc-mutations 2 \\\n",
    "    --output-hotspots /Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5a443",
   "metadata": {},
   "source": [
    "The output of this command isn't anything special: it's a TSV file in which each row describes an identified hotspot feature, defining \"hotspots\" based on the `--min-num-mutations` and `--min-perc-mutations` options we set earlier. Let's load this file using `pandas.read_csv()` and get a brief sense of what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e01d9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>FeatureStart_1IndexedInclusive</th>\n",
       "      <th>FeatureEnd_1IndexedInclusive</th>\n",
       "      <th>NumberMutatedPositions</th>\n",
       "      <th>PercentMutatedPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_765</td>\n",
       "      <td>865350</td>\n",
       "      <td>866369</td>\n",
       "      <td>32</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_781</td>\n",
       "      <td>873414</td>\n",
       "      <td>873626</td>\n",
       "      <td>5</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_787</td>\n",
       "      <td>878293</td>\n",
       "      <td>879429</td>\n",
       "      <td>48</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_788</td>\n",
       "      <td>879444</td>\n",
       "      <td>881552</td>\n",
       "      <td>101</td>\n",
       "      <td>4.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>8_789</td>\n",
       "      <td>881718</td>\n",
       "      <td>882956</td>\n",
       "      <td>42</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contig FeatureID  FeatureStart_1IndexedInclusive  \\\n",
       "0  edge_8     8_765                          865350   \n",
       "1  edge_8     8_781                          873414   \n",
       "2  edge_8     8_787                          878293   \n",
       "3  edge_8     8_788                          879444   \n",
       "4  edge_8     8_789                          881718   \n",
       "\n",
       "   FeatureEnd_1IndexedInclusive  NumberMutatedPositions  \\\n",
       "0                        866369                      32   \n",
       "1                        873626                       5   \n",
       "2                        879429                      48   \n",
       "3                        881552                     101   \n",
       "4                        882956                      42   \n",
       "\n",
       "   PercentMutatedPositions  \n",
       "0                     3.14  \n",
       "1                     2.35  \n",
       "2                     4.22  \n",
       "3                     4.79  \n",
       "4                     3.39  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotspots = pd.read_csv(\"/Poppy/mfedarko/sftests/tutorial-output/hotspot-features-n5p2.tsv\", sep=\"\\t\")\n",
    "hotspots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6d03c",
   "metadata": {},
   "source": [
    "Depending on your goals, we could focus on—for example—the hotspot genes with the highest mutation rates in a contig. We can compute this for `edge_1671` (\"BACT1\", as we name it in our paper) by filtering and then sorting the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc09e97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>FeatureStart_1IndexedInclusive</th>\n",
       "      <th>FeatureEnd_1IndexedInclusive</th>\n",
       "      <th>NumberMutatedPositions</th>\n",
       "      <th>PercentMutatedPositions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12437</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_860</td>\n",
       "      <td>1041656</td>\n",
       "      <td>1042084</td>\n",
       "      <td>86</td>\n",
       "      <td>20.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1217</td>\n",
       "      <td>1460034</td>\n",
       "      <td>1460204</td>\n",
       "      <td>34</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12373</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_183</td>\n",
       "      <td>206606</td>\n",
       "      <td>207304</td>\n",
       "      <td>131</td>\n",
       "      <td>18.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12467</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1168</td>\n",
       "      <td>1402353</td>\n",
       "      <td>1402718</td>\n",
       "      <td>61</td>\n",
       "      <td>16.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12456</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1102</td>\n",
       "      <td>1326288</td>\n",
       "      <td>1327073</td>\n",
       "      <td>120</td>\n",
       "      <td>15.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12422</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_751</td>\n",
       "      <td>916664</td>\n",
       "      <td>918493</td>\n",
       "      <td>37</td>\n",
       "      <td>2.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12375</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_248</td>\n",
       "      <td>272253</td>\n",
       "      <td>273047</td>\n",
       "      <td>16</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12461</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_1131</td>\n",
       "      <td>1361175</td>\n",
       "      <td>1361672</td>\n",
       "      <td>10</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12421</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_750</td>\n",
       "      <td>914486</td>\n",
       "      <td>916576</td>\n",
       "      <td>42</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12405</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1671_585</td>\n",
       "      <td>727563</td>\n",
       "      <td>728657</td>\n",
       "      <td>22</td>\n",
       "      <td>2.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Contig  FeatureID  FeatureStart_1IndexedInclusive  \\\n",
       "12437  edge_1671   1671_860                         1041656   \n",
       "12473  edge_1671  1671_1217                         1460034   \n",
       "12373  edge_1671   1671_183                          206606   \n",
       "12467  edge_1671  1671_1168                         1402353   \n",
       "12456  edge_1671  1671_1102                         1326288   \n",
       "...          ...        ...                             ...   \n",
       "12422  edge_1671   1671_751                          916664   \n",
       "12375  edge_1671   1671_248                          272253   \n",
       "12461  edge_1671  1671_1131                         1361175   \n",
       "12421  edge_1671   1671_750                          914486   \n",
       "12405  edge_1671   1671_585                          727563   \n",
       "\n",
       "       FeatureEnd_1IndexedInclusive  NumberMutatedPositions  \\\n",
       "12437                       1042084                      86   \n",
       "12473                       1460204                      34   \n",
       "12373                        207304                     131   \n",
       "12467                       1402718                      61   \n",
       "12456                       1327073                     120   \n",
       "...                             ...                     ...   \n",
       "12422                        918493                      37   \n",
       "12375                        273047                      16   \n",
       "12461                       1361672                      10   \n",
       "12421                        916576                      42   \n",
       "12405                        728657                      22   \n",
       "\n",
       "       PercentMutatedPositions  \n",
       "12437                    20.05  \n",
       "12473                    19.88  \n",
       "12373                    18.74  \n",
       "12467                    16.67  \n",
       "12456                    15.27  \n",
       "...                        ...  \n",
       "12422                     2.02  \n",
       "12375                     2.01  \n",
       "12461                     2.01  \n",
       "12421                     2.01  \n",
       "12405                     2.01  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bact1_hotspots = hotspots[hotspots[\"Contig\"] == \"edge_1671\"]\n",
    "\n",
    "# Sort all the \"hotspot genes\" in BACT1 from high to low mutation rates (% of positions mutated).\n",
    "# This is similar to the table of highly-mutated genes in the Supplemental Material of our paper,\n",
    "# although unlike that table this uses FDR-fixed mutations (and it also uses different gene\n",
    "# predictions, as discussed above).\n",
    "bact1_hotspots.sort_values([\"PercentMutatedPositions\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b73a9",
   "metadata": {},
   "source": [
    "### 3.2. Identifying coldspot gaps\n",
    "\n",
    "Similarly, strainFlye supports the identification of basic \"coldspots\"—here, defined as long gaps without any mutations. The main parameter is the minimum length needed to define a gap as a \"coldspot.\" Let's test this out on the SheepGut dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cd7c1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye spot cold-gaps [OPTIONS]\r\n",
      "\r\n",
      "  Identify long coldspot \"gaps\" without any mutations.\r\n",
      "\r\n",
      "  To clarify, we define a \"gap\" of length L on a contig as a collection of\r\n",
      "  continuous positions [N, N + 1, ... N + L - 2, N + L - 1] in which no\r\n",
      "  positions are mutations (based on the input BCF file).\r\n",
      "\r\n",
      "  If the --circular flag is specified, then we can loop around the contig from\r\n",
      "  right to left; otherwise, the left and right sides of the contig are hard\r\n",
      "  boundaries. To give an example of this, consider a 9-nucleotide contig that\r\n",
      "  has mutations at positions 4 and 6:\r\n",
      "\r\n",
      "                             Mut.    Mut.\r\n",
      "                  1   2   3   4   5   6   7   8   9\r\n",
      "\r\n",
      "  If --circular is specified, then this contig has two gaps: one gap of length\r\n",
      "  1 (covering just position 5, between the two mutations), and another gap of\r\n",
      "  length 6 (starting at position 7 and looping around to position 3: [7, 8, 9,\r\n",
      "  1, 2, 3]).\r\n",
      "\r\n",
      "  If --circular is not specified, then this contig has three gaps: [1, 2, 3],\r\n",
      "  [5], and [7, 8, 9].\r\n",
      "\r\n",
      "Options:\r\n",
      "  -b, --bcf PATH                  Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -l, --min-length INTEGER RANGE  Label a gap between mutations in a contig as\r\n",
      "                                  a \"coldspot\" if the gap is at least this\r\n",
      "                                  long.  [default: 5000; x>0; required]\r\n",
      "  --circular / --no-circular      If --circular is specified, we'll assume\r\n",
      "                                  that all contigs are circular: we'll\r\n",
      "                                  consider the gap \"looping around\" from the\r\n",
      "                                  rightmost mutation in each contig to the\r\n",
      "                                  leftmost mutation in the contig as a\r\n",
      "                                  potential coldspot. Otherwise, we will\r\n",
      "                                  assume all contigs are linear.  [default:\r\n",
      "                                  no-circular]\r\n",
      "  --exact-pvals / --no-exact-pvals\r\n",
      "                                  If --exact-pvals is specified, we'll use the\r\n",
      "                                  method for computing exact longest-gap\r\n",
      "                                  p-values given in equation (3.1) of (Naus\r\n",
      "                                  1982). We use Python's decimal library with\r\n",
      "                                  default parameters to try to deal with large\r\n",
      "                                  numbers, but we can't guarantee that this\r\n",
      "                                  won't cause the program to fail in certain\r\n",
      "                                  cases. If --exact-pvals is not specified,\r\n",
      "                                  we'll use equation (3.3) of (Naus 1982),\r\n",
      "                                  which gives an approximation of the p-value.\r\n",
      "                                  [default: exact-pvals]\r\n",
      "  -o, --output-coldspots FILE     Filepath to which an output tab-separated\r\n",
      "                                  values (TSV) file describing coldspots will\r\n",
      "                                  be written. The longest gap in each contig\r\n",
      "                                  will also be given a p-value, indicating the\r\n",
      "                                  probability of the longest gap being at\r\n",
      "                                  least this long (given the length of and\r\n",
      "                                  number of mutated positions in this contig,\r\n",
      "                                  and assuming that mutations occur with a\r\n",
      "                                  constant probability at any position in the\r\n",
      "                                  contig). See (Naus 1982) for details.\r\n",
      "                                  [required]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot cold-gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a221ba11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using strainFlye version \"0.1.0-dev\".\n",
      "--------\n",
      "spot cold-gaps @ 0.00s: Starting...\n",
      "Input BCF file: /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf\n",
      "Input minimum coldspot gap length: 5000\n",
      "Check for circular coldspot gaps?: No\n",
      "Compute exact longest-gap p-values?: Yes\n",
      "Output file describing coldspot gaps: /Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv\n",
      "--------\n",
      "spot cold-gaps @ 0.00s: Loading and checking the BCF file...\n",
      "spot cold-gaps @ 11.71s: Looks good so far.\n",
      "--------\n",
      "spot cold-gaps @ 11.71s: Going through contigs and identifying coldspot gaps...\n",
      "spot cold-gaps @ 15.33s: Identified 15,258 coldspot gap(s) across all 468 contigs in the BCF file.\n",
      "--------\n",
      "spot cold-gaps @ 15.34s: Writing out this information to a TSV file...\n",
      "spot cold-gaps @ 15.34s: Done.\n",
      "--------\n",
      "spot cold-gaps @ 15.35s: Done.\n"
     ]
    }
   ],
   "source": [
    "!strainFlye spot cold-gaps \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --output-coldspots /Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd3a8c2",
   "metadata": {},
   "source": [
    "Again, `cold-gaps` will output a simple TSV file describing its identified coldspots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0c1feb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Start_1IndexedInclusive</th>\n",
       "      <th>End_1IndexedInclusive</th>\n",
       "      <th>Length</th>\n",
       "      <th>P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>383672</td>\n",
       "      <td>681281</td>\n",
       "      <td>297610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>681283</td>\n",
       "      <td>715603</td>\n",
       "      <td>34321</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>717621</td>\n",
       "      <td>865477</td>\n",
       "      <td>147857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>885778</td>\n",
       "      <td>906394</td>\n",
       "      <td>20617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>edge_8</td>\n",
       "      <td>913216</td>\n",
       "      <td>920714</td>\n",
       "      <td>7499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Contig  Start_1IndexedInclusive  End_1IndexedInclusive  Length  P_Value\n",
       "0  edge_8                   383672                 681281  297610      NaN\n",
       "1  edge_8                   681283                 715603   34321      NaN\n",
       "2  edge_8                   717621                 865477  147857      NaN\n",
       "3  edge_8                   885778                 906394   20617      NaN\n",
       "4  edge_8                   913216                 920714    7499      NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldspots = pd.read_csv(\"/Poppy/mfedarko/sftests/tutorial-output/coldspot-gaps-minlen5000-nocircular.tsv\", sep=\"\\t\")\n",
    "coldspots.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b28dcf",
   "metadata": {},
   "source": [
    "There are many ways we could make use of this information—similarly to the hotspot example, we could try sorting these gaps from longest to shortest for the BACT1 contig. This is shown below. (The longest gap in a coldspot is assigned a p-value; please see the Supplemental Material of our paper for details on how we compute this, and the assumptions made.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62a1e8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contig</th>\n",
       "      <th>Start_1IndexedInclusive</th>\n",
       "      <th>End_1IndexedInclusive</th>\n",
       "      <th>Length</th>\n",
       "      <th>P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1216892</td>\n",
       "      <td>1239536</td>\n",
       "      <td>22645</td>\n",
       "      <td>1.168921e-103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1618448</td>\n",
       "      <td>1637614</td>\n",
       "      <td>19167</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1797824</td>\n",
       "      <td>1813581</td>\n",
       "      <td>15758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2385</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1194740</td>\n",
       "      <td>1207381</td>\n",
       "      <td>12642</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>2140896</td>\n",
       "      <td>2153394</td>\n",
       "      <td>12499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>979572</td>\n",
       "      <td>990495</td>\n",
       "      <td>10924</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>740701</td>\n",
       "      <td>750399</td>\n",
       "      <td>9699</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1207881</td>\n",
       "      <td>1216890</td>\n",
       "      <td>9010</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2384</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>1183003</td>\n",
       "      <td>1191716</td>\n",
       "      <td>8714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>972772</td>\n",
       "      <td>979570</td>\n",
       "      <td>6799</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2378</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>332394</td>\n",
       "      <td>338967</td>\n",
       "      <td>6574</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>541117</td>\n",
       "      <td>546507</td>\n",
       "      <td>5391</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2381</th>\n",
       "      <td>edge_1671</td>\n",
       "      <td>941510</td>\n",
       "      <td>946720</td>\n",
       "      <td>5211</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Contig  Start_1IndexedInclusive  End_1IndexedInclusive  Length  \\\n",
       "2387  edge_1671                  1216892                1239536   22645   \n",
       "2388  edge_1671                  1618448                1637614   19167   \n",
       "2389  edge_1671                  1797824                1813581   15758   \n",
       "2385  edge_1671                  1194740                1207381   12642   \n",
       "2390  edge_1671                  2140896                2153394   12499   \n",
       "2383  edge_1671                   979572                 990495   10924   \n",
       "2380  edge_1671                   740701                 750399    9699   \n",
       "2386  edge_1671                  1207881                1216890    9010   \n",
       "2384  edge_1671                  1183003                1191716    8714   \n",
       "2382  edge_1671                   972772                 979570    6799   \n",
       "2378  edge_1671                   332394                 338967    6574   \n",
       "2379  edge_1671                   541117                 546507    5391   \n",
       "2381  edge_1671                   941510                 946720    5211   \n",
       "\n",
       "            P_Value  \n",
       "2387  1.168921e-103  \n",
       "2388            NaN  \n",
       "2389            NaN  \n",
       "2385            NaN  \n",
       "2390            NaN  \n",
       "2383            NaN  \n",
       "2380            NaN  \n",
       "2386            NaN  \n",
       "2384            NaN  \n",
       "2382            NaN  \n",
       "2378            NaN  \n",
       "2379            NaN  \n",
       "2381            NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coldspots[coldspots[\"Contig\"] == \"edge_1671\"].sort_values([\"Length\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60dad6b",
   "metadata": {},
   "source": [
    "## 4. Phasing analyses\n",
    "\n",
    "### 4.1. Generating \"smoothed haplotypes\"\n",
    "\n",
    "Given our called mutations, we can attempt to generate haplotypes that respect these mutations using strainFlye's `smooth` module.\n",
    "\n",
    "The details and motivation for this are explained in depth in our paper. To briefly summarize, we will convert the reads aligned to each contig into \"smoothed reads,\" which only contain our called mutations with no other variations. We will then (optionally, depending on the `--virtual-reads` parameter) construct \"virtual reads\" to fill in low-coverage regions. We will then assemble these reads using [LJA](https://github.com/AntonBankevich/LJA/) to construct \"smoothed haplotypes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "591b2872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  [+] Create and assemble smoothed and virtual reads.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -h, --help  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  create    Create smoothed and virtual reads for each contig.\r\n",
      "  assemble  Assemble contigs' reads using LJA.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdadda6",
   "metadata": {},
   "source": [
    "#### 4.1.1. Create smoothed and virtual reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c81a60e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth create [OPTIONS]\r\n",
      "\r\n",
      "  Create smoothed and virtual reads for each contig.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -c, --contigs PATH              FASTA file of contigs.  [required]\r\n",
      "  --bam PATH                      Sorted and indexed BAM file representing an\r\n",
      "                                  alignment of reads to contigs.  [required]\r\n",
      "  --bcf PATH                      Indexed BCF file describing single-\r\n",
      "                                  nucleotide mutations in a set of contigs.\r\n",
      "                                  [required]\r\n",
      "  -di, --diversity-indices PATH   TSV file describing the diversity indices of\r\n",
      "                                  a set of contigs, produced by one of the\r\n",
      "                                  \"strainFlye call\" commands. Only used if\r\n",
      "                                  --virtual-reads is specified. Along with\r\n",
      "                                  diversity indices, these files list contigs'\r\n",
      "                                  average coverages. If --virtual-reads is\r\n",
      "                                  specified, we will need to know contigs'\r\n",
      "                                  average coverages. So, if a diversity\r\n",
      "                                  indices file is provided here, then we can\r\n",
      "                                  avoid re-computing average coverages.\r\n",
      "                                  (Otherwise, if --virtual-reads is specified\r\n",
      "                                  but no diversity indices file is provided,\r\n",
      "                                  we'll need to compute average coverages;\r\n",
      "                                  this will take some extra time.)  [default:\r\n",
      "                                  (nothing)]\r\n",
      "  --virtual-reads / --no-virtual-reads\r\n",
      "                                  If --virtual-reads is specified, we'll\r\n",
      "                                  create virtual reads covering \"low-coverage\"\r\n",
      "                                  regions in contigs.  [default: virtual-\r\n",
      "                                  reads]\r\n",
      "  -vrp, --virtual-read-well-covered-perc FLOAT RANGE\r\n",
      "                                  Only used if --virtual-reads is specified.\r\n",
      "                                  In a contig with average coverage (based on\r\n",
      "                                  the BAM file, and only considering match +\r\n",
      "                                  mismatch counts) C, we will define a\r\n",
      "                                  position in this contig (with coverage P,\r\n",
      "                                  based only on the smoothed reads) as low-\r\n",
      "                                  coverage if ((P / C) × 100) is less than\r\n",
      "                                  this percentage.  [default: 95; 0<=x<=100;\r\n",
      "                                  required]\r\n",
      "  -vrf, --virtual-read-flank INTEGER RANGE\r\n",
      "                                  Only used if --virtual-reads is specified.\r\n",
      "                                  When we add virtual reads spanning a single\r\n",
      "                                  continuous low-coverage region, these reads\r\n",
      "                                  will start and end this many positions\r\n",
      "                                  before and after the region. (For example,\r\n",
      "                                  the default of 100 means that the virtual\r\n",
      "                                  reads created for a low-coverage region of\r\n",
      "                                  5,000 bp will all be 5,200 bp.)  [default:\r\n",
      "                                  100; x>=0; required]\r\n",
      "  -o, --output-dir DIRECTORY      Directory to which smoothed reads (and\r\n",
      "                                  virtual reads, if --virtual-reads is\r\n",
      "                                  specified) will be written. Each contig's\r\n",
      "                                  reads will be written to a gzipped FASTA\r\n",
      "                                  file in this directory named\r\n",
      "                                  [contig].fasta.gz.  [required]\r\n",
      "  --verbose / --no-verbose        Display extra details for each contig while\r\n",
      "                                  generating reads.  [default: no-verbose]\r\n",
      "  -h, --help                      Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye smooth create \\\n",
    "    --contigs /Poppy/mfedarko/sftests/tutorial-output/sheepgut_contigs_atleast_1Mbp.fasta \\\n",
    "    --bam /Poppy/mfedarko/sheepgut/main-workflow/output/fully-filtered-and-sorted-aln.bam \\\n",
    "    --bcf /Poppy/mfedarko/sftests/tutorial-output/p15-fdr1pct.bcf \\\n",
    "    --diversity-indices /Poppy/mfedarko/sftests/tutorial-output/call-p15/diversity-indices.tsv \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/reads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24302a1b",
   "metadata": {},
   "source": [
    "#### 4.1.2. Assemble these reads using LJA\n",
    "\n",
    "This step assumes that we have already installed [LJA](https://github.com/AntonBankevich/LJA/), in particular the `simple_ec` branch of it. Please see [LJA's manual](https://github.com/AntonBankevich/LJA/blob/main/docs/lja_manual.md) for installation instructions.\n",
    "\n",
    "I have installed LJA into a specific location on our cluster. So that strainFlye can easily run LJA for each contig's reads files, we pass the location of LJA's binary executable to strainFlye below using the `--lja-bin` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89064151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: strainFlye smooth assemble [OPTIONS]\r\n",
      "\r\n",
      "  Assemble contigs' reads using LJA.\r\n",
      "\r\n",
      "  Please note that this command relies on the \"simple_ec\" branch of LJA being\r\n",
      "  installed on your system. See strainFlye's README (and/or LJA's manual) for\r\n",
      "  details on installing LJA.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -r, --reads-dir DIRECTORY   Directory produced by \"strainFlye smooth create\"\r\n",
      "                              containing smoothed (and optionally virtual)\r\n",
      "                              reads. We will use LJA to assemble each\r\n",
      "                              *.fasta.gz file in this directory (representing\r\n",
      "                              reads from different contigs) independently.\r\n",
      "                              [required]\r\n",
      "  -p, --lja-params TEXT       Additional parameters to pass to LJA, besides\r\n",
      "                              the --reads and --output-dir parameters. To\r\n",
      "                              explain our defaults: the --simpleec flag is\r\n",
      "                              currently only available on the simple_ec branch\r\n",
      "                              of LJA. This flag tells LJA to perform \"simple\"\r\n",
      "                              error correction by removing all edges in the de\r\n",
      "                              Bruijn graph with k-mer coverage less than\r\n",
      "                              --Cov-threshold (10), as well as reads passing\r\n",
      "                              through these edges. This \"simple\" error\r\n",
      "                              correction is done instead of running the\r\n",
      "                              default LJA error correction module, mowerDBG.\r\n",
      "                              Please note that we do not perform any\r\n",
      "                              validation on this string before passing it to\r\n",
      "                              LJA (so if you are allowing users to run\r\n",
      "                              strainFlye through a web server, be careful\r\n",
      "                              about shell injection).  [default: --simpleec\r\n",
      "                              --Cov-threshold 10]\r\n",
      "  -b, --lja-bin FILE          Location of LJA's \"lja\" binary file, which can\r\n",
      "                              be used to run LJA. This should be located in\r\n",
      "                              the bin/ folder constructed when you compiled\r\n",
      "                              LJA. If this is not provided, we will check to\r\n",
      "                              see if LJA is available in your $PATH.\r\n",
      "                              [default: (Look for LJA's bin in the $PATH\r\n",
      "                              environment variable)]\r\n",
      "  -o, --output-dir DIRECTORY  Directory to which output LJA assemblies (one\r\n",
      "                              top-level folder per *.fasta.gz file in the\r\n",
      "                              input --reads-dir) will be written.  [required]\r\n",
      "  --verbose / --no-verbose    Display extra details for each contig during the\r\n",
      "                              assembly process.  [default: no-verbose]\r\n",
      "  -h, --help                  Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!strainFlye smooth assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7424ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "!strainFlye smooth assemble \\\n",
    "    --reads-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/reads \\\n",
    "    --lja-bin /home/mfedarko/software/LJA-branch/bin/lja \\\n",
    "    --output-dir /Poppy/mfedarko/sftests/tutorial-output/smooth/assemblies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfb60a",
   "metadata": {},
   "source": [
    "### 4.2. Constructing link graphs\n",
    "\n",
    "_(This part of the pipeline is under construction right now, sorry.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5fbe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
